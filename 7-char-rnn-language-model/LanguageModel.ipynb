{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QaJN9rqQBQlk"
      },
      "source": [
        "Name: Mehran Sarmadi\n",
        "\n",
        "Student ID :"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NREc5PRBBUIq"
      },
      "source": [
        "In this exercise, you should develop a character-level RNN language model.\n",
        "\n",
        "You are free to choose the architecture, but you must use GRUs and not LSTMs. A linear embedding layer (hidden size 64), a 2-layer GRU (hidden size 128, dropout 0.1), and a linear classifier head is an example architecture.\n",
        "\n",
        "You should generate some example outputs using beam search.\n",
        "\n",
        "Some parts of the code has been done for you. You need to implement the parts that raise `NotImplementedError`.\n",
        "\n",
        "The index zero has been reserved for the padding token/character. By subtracting one from the token indices, the indices will become ASCII indices. (And the padding index will become `-1`.)\n",
        "\n",
        "The model's classification head should directly predict ASCII characters (256 possibilities). It should not predict any special tokens, such as padding, start or end."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wlQemG3WM9uc"
      },
      "source": [
        "# Bootstrap"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cQu2ZQgpN8fK"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjzJdHsqN9Y3",
        "outputId": "9db9d67b-32e8-456e-d675-db6175ba2aa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.24.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install -U torch datasets numpy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Slipo3ggNC1I"
      },
      "source": [
        "# Download the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhGFkv0UNFVi",
        "outputId": "c483991c-378b-4a77-eb18-ed760f4a93ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-09 18:48:34--  https://files.lilf.ir/Black%20Luminary.txt\n",
            "Resolving files.lilf.ir (files.lilf.ir)... 82.102.11.148\n",
            "Connecting to files.lilf.ir (files.lilf.ir)|82.102.11.148|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3148450 (3.0M) [text/plain]\n",
            "Saving to: ‘Black Luminary.txt.1’\n",
            "\n",
            "Black Luminary.txt. 100%[===================>]   3.00M  1.86MB/s    in 1.6s    \n",
            "\n",
            "2023-05-09 18:48:37 (1.86 MB/s) - ‘Black Luminary.txt.1’ saved [3148450/3148450]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://files.lilf.ir/Black%20Luminary.txt\n",
        "# ! ls -lh\n",
        "# ! realpath *.txt\n",
        "\n",
        "data_paths = [\n",
        "    # '/content/Black Luminary.txt',\n",
        "    \"./Black Luminary.txt\"\n",
        "    ]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7Olgn0qCM9ug"
      },
      "source": [
        "## imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T0kGW6XM9ug",
        "outputId": "444a54b7-546e-4417-c559-f2427a5dbbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import datasets as D\n",
        "import numpy as np\n",
        "import statistics\n",
        "from pprint import pprint\n",
        "import jax\n",
        "import time\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "device = torch.device(\"cpu\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fuFMb2_pM9ui"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ugsrq8zUM9ui"
      },
      "outputs": [],
      "source": [
        "class NumpyPrintOptions:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.options = kwargs\n",
        "        self.original_options = np.get_printoptions()\n",
        "\n",
        "    def __enter__(self):\n",
        "        np.set_printoptions(**self.options)\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        np.set_printoptions(**self.original_options)\n",
        "\n",
        "class NoTruncationNumpyPrintOptions(NumpyPrintOptions):\n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            threshold=np.inf, \n",
        "            linewidth=200, \n",
        "            suppress=True, \n",
        "            precision=4\n",
        "        )\n",
        "\n",
        "def torch_shape_get(input):\n",
        "    def h_shape_get(x):\n",
        "        return x.dtype, x.shape\n",
        "\n",
        "    return jax.tree_map(h_shape_get, input)\n",
        "\n",
        "\n",
        "def has_nan(tensor):\n",
        "    return torch.any(torch.isnan(tensor))\n",
        "\n",
        "\n",
        "class ModelEvalMode:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.model.eval()\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        self.model.train()\n",
        "\n",
        "\n",
        "def str_to_np(s, dtype=np.int8):\n",
        "    s = s.encode('ascii', errors='ignore')\n",
        "    return np.frombuffer(s, dtype=dtype)\n",
        "\n",
        "def str_to_onehot(s):\n",
        "    return np.eye(256)[str_to_np(s)]\n",
        "\n",
        "\n",
        "def p(message, length=80, symbol=\"=\", newline=True):\n",
        "    length = 80\n",
        "    num_equals = (length - len(message) - 2) // 2\n",
        "    output = symbol * num_equals + \" \" + message + \" \" + symbol * num_equals\n",
        "    if len(output) < length:\n",
        "        output += symbol \n",
        "    if newline:\n",
        "        output += \"\\n\"\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DohSw_PMuUik",
        "outputId": "d990c93c-a937-4d91-c9c9-7bff835e425a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[104 101 108 108 111]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print(str_to_np(\"hello\"))\n",
        "print(str_to_onehot(\"hello\"))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BeoLLv_9M9ui"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326,
          "referenced_widgets": [
            "e65584e961c24c0b9248c1342dd21b1e",
            "f453c761a8a8474c8d23dc36a99b823e",
            "ce6f1bd69c844223b942467b9700beeb",
            "75eeb7679c7d447bbeded9c744ff770e",
            "6e170546441d489a81ba23ab7d296165",
            "ee0528adca244e31827c4b23b310432d",
            "d2e0657ceced4de689a644651f30baf4",
            "d62e1177f2444f9c9b1c23c04ee50e13",
            "6d5b4a2e36284638836c8edba5cb3b47",
            "de0a7ce1638d4518a15758f5f24979e1",
            "6c5116ffec5a423cb1bc620f8c4cf54f"
          ]
        },
        "id": "q44PnV-HM9uj",
        "outputId": "1d5430e5-a226-4f37-e60c-4b84e13fc263"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset text (/root/.cache/huggingface/datasets/text/default-751f099585d07f63/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e65584e961c24c0b9248c1342dd21b1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================== Loaded dataset using Datasets =========================\n",
            " DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 18423\n",
            "    })\n",
            "})\n",
            "============================ Train part of dataset =============================\n",
            " Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 18423\n",
            "})\n",
            "================================= sample text ==================================\n",
            " {'text': 'Professor Snape threw him backwards, and Harry stumbled, but just managed to keep standing.'}\n"
          ]
        }
      ],
      "source": [
        "d = D.load_dataset(\"text\", data_files=data_paths, sample_by=\"paragraph\")\n",
        "print(p(\"Loaded dataset using Datasets\") , d)\n",
        "\n",
        "d = d['train']\n",
        "print(p(\"Train part of dataset\"), d)\n",
        "print(p(\"sample text\"), d[1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6Z9332lM9ul",
        "outputId": "98375a68-a7a3-4afb-8921-4ab66d06b19d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-751f099585d07f63/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-6c2fa5772a7c3468.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-751f099585d07f63/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-c08083be4637b64c.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================== Add 'input' column (numerical) ========================\n",
            " Dataset({\n",
            "    features: ['text', 'input'],\n",
            "    num_rows: 18423\n",
            "})\n",
            "================================ Single sample =================================\n",
            " {'text': 'Black Luminary', 'input': [67, 109, 98, 100, 108, 33, 77, 118, 110, 106, 111, 98, 115, 122]}\n",
            "============================ Remove short sentences ============================\n",
            " Dataset({\n",
            "    features: ['text', 'input'],\n",
            "    num_rows: 16371\n",
            "})\n",
            "======================== Split train to train and test =========================\n",
            " DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'input'],\n",
            "        num_rows: 13096\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'input'],\n",
            "        num_rows: 3275\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "dc = d.map(lambda batch: {'input': [str_to_np(t).astype(np.int32) + 1 for t in batch['text']]}, batched=True) #: added one to the char indices to make zero available for the pad token\n",
        "print(p(\"Add 'input' column (numerical)\"), dc)\n",
        "print(p(\"Single sample\"), dc[0])\n",
        "\n",
        "dc = dc.filter(lambda x: (len(x['input']) > 30 and len(x['text'].split()) > 4), batched=False)\n",
        "dc.set_format(\"torch\", columns=[\"input\",])\n",
        "print(p(\"Remove short sentences\"), dc)\n",
        "\n",
        "dc = dc.shuffle()\n",
        "dcs = dc.train_test_split(test_size=0.2)\n",
        "print(p(\"Split train to train and test\"), dcs)\n",
        "\n",
        "dt = dcs['train']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BvXAwGmgM9um"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JXpLKcRnM9um"
      },
      "source": [
        "- [GRU --- PyTorch 2.0 documentation](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html)\n",
        "\n",
        "- [torch.nn.utils.rnn.pack_sequence --- PyTorch 2.0 documentation](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_sequence.html#torch.nn.utils.rnn.pack_sequence) (not necessarily needed)\n",
        "\n",
        "- [Embedding --- PyTorch 2.0 documentation](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
        "\n",
        "- [torch.nn.utils.rnn.pad_sequence --- PyTorch 2.0 documentation](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lPmMQacFtVOt"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(num_embeddings=257, embedding_dim=64)\n",
        "        self.GRU = nn.GRU(input_size=64, hidden_size=128, num_layers=2, batch_first=True)\n",
        "        self.Classifier = nn.Linear(in_features=128, out_features=257)\n",
        "        \n",
        "        \n",
        "    def forward(self, x, hidden=None):\n",
        "        if isinstance(x, list):\n",
        "          x = nn.utils.rnn.pad_sequence(x, padding_value=0, batch_first=True) \n",
        "          \n",
        "        x = self.embed(x)           \n",
        "        x, hidden = self.GRU(x, hidden) \n",
        "        x = self.Classifier(x)          \n",
        "        return x, hidden.detach()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn3SvgBJM9um",
        "outputId": "3bb51ab5-bb6d-4ac8-b94c-7a775c99fe99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Ids:\n",
            "[tensor([1, 2, 3, 4]), tensor([5, 6, 7, 8])]\n",
            "Shifted Left (Target Ids):\n",
            "[tensor([2, 3, 4, 0]), tensor([6, 7, 8, 0])]\n"
          ]
        }
      ],
      "source": [
        "def shift_left(tensor_list, pad_value=0.0):\n",
        "    shifted_tensors = []\n",
        "    for tensor in tensor_list:\n",
        "      tensor1 = tensor[1:].to(device)\n",
        "      tensor2 = torch.tensor([0]).to(device)\n",
        "      shifted = torch.cat([tensor1, tensor2])\n",
        "      shifted_tensors.append(shifted)\n",
        "    \n",
        "    return shifted_tensors\n",
        "\n",
        "# Example usage:\n",
        "input_ids = [torch.tensor([1, 2, 3, 4]), torch.tensor([5, 6, 7, 8])]\n",
        "print(\"Input Ids:\")\n",
        "print(input_ids)\n",
        "\n",
        "target_ids = shift_left(input_ids)\n",
        "print(\"Shifted Left (Target Ids):\")\n",
        "print(target_ids)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2CnBxRPREInk"
      },
      "source": [
        "# Beam Search Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "V4SbAc1JM9um"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import heapq\n",
        "\n",
        "def tensor_to_string(tensor):\n",
        "    chars = [chr(c) for c in tensor]\n",
        "    return ''.join(chars)\n",
        "\n",
        "def tensor_append_scalar(tensor, scalar):\n",
        "    scalar_tensor = torch.tensor(scalar).view(1)  \n",
        "    scalar_tensor = scalar_tensor.to(device)\n",
        "\n",
        "    # Append the scalar to the original tensor\n",
        "    result = torch.cat((tensor, scalar_tensor), dim=0)\n",
        "    return result\n",
        "\n",
        "\n",
        "def generate_next_top_k(model, input_sequence, k):\n",
        "    logits, _ = model.forward([input_sequence])\n",
        "    logits = logits[0, -1, :]\n",
        "    # ic(torch_shape_get(logits))\n",
        "    \n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "    # ic(torch_shape_get(probabilities))\n",
        "\n",
        "    top_k_values, top_k_indices = torch.topk(probabilities, k)\n",
        "\n",
        "    # return [(tensor_append_scalar(input_sequence, idx.item() + 1), log_prob.item()) for idx, log_prob in zip(top_k_indices, top_k_values.log())]\n",
        "    return [(tensor_append_scalar(input_sequence, idx.item()), log_prob.item()) for idx, log_prob in zip(top_k_indices, top_k_values.log())]\n",
        "\n",
        "def beam_search(model, desired_length, starting_string, k=5):\n",
        "    with ModelEvalMode(model), torch.no_grad():\n",
        "      input_sequence = torch.tensor(str_to_np(starting_string).astype(np.int32) + 1, dtype=torch.long)\n",
        "      input_sequence = input_sequence.to(device)\n",
        "      # ic(torch_shape_get(input_sequence))\n",
        "      \n",
        "      log_prob = 0.0\n",
        "\n",
        "      beam = [(input_sequence, log_prob)]\n",
        "\n",
        "      while len(beam[0][0]) < desired_length:\n",
        "          new_beam = []\n",
        "          for seq, log_prob in beam:\n",
        "              next_top_k = generate_next_top_k(model, seq, k)\n",
        "              new_beam.extend([(new_seq, new_log_prob + log_prob) for new_seq, new_log_prob in next_top_k])\n",
        "\n",
        "          beam = heapq.nlargest(k, new_beam, key=lambda x: x[1])\n",
        "\n",
        "      return [tensor_to_string(seq - 1) for seq, _ in beam]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YZFXxwtM9un",
        "outputId": "8b0778b4-c1ca-44cf-e331-015661daf011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 73  98 115 115 122  33]\n",
            "Harry  |\n"
          ]
        }
      ],
      "source": [
        "harry_int = str_to_np(\"Harry \").astype(np.int32) + 1\n",
        "harry_str = tensor_to_string(harry_int - 1)\n",
        "print(harry_int)\n",
        "print(harry_str, \"|\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sf6P5sQZM9un"
      },
      "outputs": [],
      "source": [
        "def eval_gen(*args, display=999999, **kwargs):\n",
        "    generated_texts = beam_search(\n",
        "        *args, **kwargs,\n",
        "    )\n",
        "\n",
        "    for idx, text in enumerate(generated_texts):\n",
        "        if idx >= display:\n",
        "            break\n",
        "        \n",
        "        print(f\"Generated text {idx + 1}: {text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "a3IA5SHoDIoQ"
      },
      "outputs": [],
      "source": [
        "len_dataset = len(dt)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SekVnAUcOuiU"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YSVRWabM9un",
        "outputId": "9b3b1ff1-85da-4b05-e4dc-28c41a1db500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch_loss: 1044.320143 [    0, epoch=0]\n",
            "batch_loss: 945.257664 [    1, epoch=0]\n",
            "batch_loss: 698.152567 [    2, epoch=0]\n",
            "batch_loss: 598.620288 [    3, epoch=0]\n",
            "Loss: 877.567868  [    3, epoch=0 finished!]\n",
            "Generated text 1: Harry t t t t t t t t t t t t t t t t t  t  t t t t t t  t t  t t  t  t  t  t  t  t  t  t  t  t  t  \n",
            "Generated text 2: Harry t t t t t t t t t t t t t t t t t  t  t t t t t t t  t t  t  t  t  t  t  t  t  t  t  t  t  t  \n",
            "Generated text 3: Harry t t t t t t t t t t t t t t t t t  t  t t t t t t  t t  t t  t  t  t  t t  t  t  t t  t  t  t \n",
            "batch_loss: 576.735583 [    4, epoch=1]\n",
            "batch_loss: 578.073069 [    5, epoch=1]\n",
            "batch_loss: 588.726189 [    6, epoch=1]\n",
            "batch_loss: 555.000443 [    7, epoch=1]\n",
            "Loss: 579.563154  [    7, epoch=1 finished!]\n",
            "batch_loss: 553.358115 [    8, epoch=2]\n",
            "batch_loss: 547.890641 [    9, epoch=2]\n",
            "batch_loss: 543.056475 [   10, epoch=2]\n",
            "batch_loss: 537.080819 [   11, epoch=2]\n",
            "Loss: 547.421772  [   11, epoch=2 finished!]\n",
            "batch_loss: 537.181513 [   12, epoch=3]\n",
            "batch_loss: 515.671357 [   13, epoch=3]\n",
            "batch_loss: 519.135940 [   14, epoch=3]\n",
            "batch_loss: 521.877303 [   15, epoch=3]\n",
            "Loss: 523.865533  [   15, epoch=3 finished!]\n",
            "batch_loss: 496.422697 [   16, epoch=4]\n",
            "batch_loss: 505.856976 [   17, epoch=4]\n",
            "batch_loss: 498.601298 [   18, epoch=4]\n",
            "batch_loss: 517.942129 [   19, epoch=4]\n",
            "Loss: 501.382536  [   19, epoch=4 finished!]\n",
            "batch_loss: 492.244600 [   20, epoch=5]\n",
            "batch_loss: 491.146385 [   21, epoch=5]\n",
            "batch_loss: 470.898474 [   22, epoch=5]\n",
            "batch_loss: 488.355302 [   23, epoch=5]\n",
            "Loss: 484.984782  [   23, epoch=5 finished!]\n",
            "batch_loss: 467.754105 [   24, epoch=6]\n",
            "batch_loss: 474.819641 [   25, epoch=6]\n",
            "batch_loss: 472.328878 [   26, epoch=6]\n",
            "batch_loss: 479.234146 [   27, epoch=6]\n",
            "Loss: 472.103111  [   27, epoch=6 finished!]\n",
            "batch_loss: 467.051253 [   28, epoch=7]\n",
            "batch_loss: 457.048941 [   29, epoch=7]\n",
            "batch_loss: 469.754538 [   30, epoch=7]\n",
            "batch_loss: 432.330143 [   31, epoch=7]\n",
            "Loss: 462.626125  [   31, epoch=7 finished!]\n",
            "batch_loss: 464.926062 [   32, epoch=8]\n",
            "batch_loss: 445.820602 [   33, epoch=8]\n",
            "batch_loss: 450.845878 [   34, epoch=8]\n",
            "batch_loss: 442.678788 [   35, epoch=8]\n",
            "Loss: 453.174062  [   35, epoch=8 finished!]\n",
            "batch_loss: 461.059384 [   36, epoch=9]\n",
            "batch_loss: 435.400528 [   37, epoch=9]\n",
            "batch_loss: 447.509108 [   38, epoch=9]\n",
            "batch_loss: 419.773779 [   39, epoch=9]\n",
            "Loss: 446.248803  [   39, epoch=9 finished!]\n",
            "batch_loss: 434.100060 [   40, epoch=10]\n",
            "batch_loss: 439.847481 [   41, epoch=10]\n",
            "batch_loss: 441.429081 [   42, epoch=10]\n",
            "batch_loss: 428.285865 [   43, epoch=10]\n",
            "Loss: 437.831218  [   43, epoch=10 finished!]\n",
            "batch_loss: 435.240784 [   44, epoch=11]\n",
            "batch_loss: 428.210832 [   45, epoch=11]\n",
            "batch_loss: 434.555228 [   46, epoch=11]\n",
            "batch_loss: 418.231782 [   47, epoch=11]\n",
            "Loss: 431.778200  [   47, epoch=11 finished!]\n",
            "batch_loss: 432.070916 [   48, epoch=12]\n",
            "batch_loss: 430.685746 [   49, epoch=12]\n",
            "batch_loss: 416.543089 [   50, epoch=12]\n",
            "batch_loss: 405.197775 [   51, epoch=12]\n",
            "Loss: 425.123059  [   51, epoch=12 finished!]\n",
            "batch_loss: 426.420783 [   52, epoch=13]\n",
            "batch_loss: 416.314311 [   53, epoch=13]\n",
            "batch_loss: 417.152808 [   54, epoch=13]\n",
            "batch_loss: 414.615467 [   55, epoch=13]\n",
            "Loss: 419.632723  [   55, epoch=13 finished!]\n",
            "batch_loss: 419.793273 [   56, epoch=14]\n",
            "batch_loss: 410.621858 [   57, epoch=14]\n",
            "batch_loss: 414.775937 [   58, epoch=14]\n",
            "batch_loss: 422.557354 [   59, epoch=14]\n",
            "Loss: 415.526035  [   59, epoch=14 finished!]\n",
            "batch_loss: 424.223633 [   60, epoch=15]\n",
            "batch_loss: 408.847745 [   61, epoch=15]\n",
            "batch_loss: 412.850915 [   62, epoch=15]\n",
            "batch_loss: 391.444425 [   63, epoch=15]\n",
            "Loss: 413.835126  [   63, epoch=15 finished!]\n",
            "Generated text 1: Harry the the the the the the the the the the the the the the the the the the the the the the the th\n",
            "Generated text 2: Harry the the the the the the the the the the the the the the the the the the the the the the the an\n",
            "Generated text 3: Harry the the the the the the the the the the the the the the the the the the the the the the anded \n",
            "batch_loss: 418.509141 [   64, epoch=16]\n",
            "batch_loss: 403.275404 [   65, epoch=16]\n",
            "batch_loss: 412.844619 [   66, epoch=16]\n",
            "batch_loss: 397.213873 [   67, epoch=16]\n",
            "Loss: 410.658969  [   67, epoch=16 finished!]\n",
            "batch_loss: 408.182588 [   68, epoch=17]\n",
            "batch_loss: 405.335132 [   69, epoch=17]\n",
            "batch_loss: 395.756939 [   70, epoch=17]\n",
            "batch_loss: 396.919489 [   71, epoch=17]\n",
            "Loss: 402.710747  [   71, epoch=17 finished!]\n",
            "batch_loss: 399.038530 [   72, epoch=18]\n",
            "batch_loss: 395.120838 [   73, epoch=18]\n",
            "batch_loss: 402.425920 [   74, epoch=18]\n",
            "batch_loss: 392.923686 [   75, epoch=18]\n",
            "Loss: 398.495394  [   75, epoch=18 finished!]\n",
            "batch_loss: 398.472021 [   76, epoch=19]\n",
            "batch_loss: 394.635551 [   77, epoch=19]\n",
            "batch_loss: 390.167803 [   78, epoch=19]\n",
            "batch_loss: 379.561251 [   79, epoch=19]\n",
            "Loss: 393.508050  [   79, epoch=19 finished!]\n",
            "batch_loss: 396.506322 [   80, epoch=20]\n",
            "batch_loss: 385.955717 [   81, epoch=20]\n",
            "batch_loss: 388.052669 [   82, epoch=20]\n",
            "batch_loss: 377.995807 [   83, epoch=20]\n",
            "Loss: 389.420347  [   83, epoch=20 finished!]\n",
            "batch_loss: 394.190983 [   84, epoch=21]\n",
            "batch_loss: 385.288033 [   85, epoch=21]\n",
            "batch_loss: 377.717066 [   86, epoch=21]\n",
            "batch_loss: 380.241018 [   87, epoch=21]\n",
            "Loss: 385.393242  [   87, epoch=21 finished!]\n",
            "batch_loss: 387.448742 [   88, epoch=22]\n",
            "batch_loss: 382.484292 [   89, epoch=22]\n",
            "batch_loss: 378.245909 [   90, epoch=22]\n",
            "batch_loss: 372.280588 [   91, epoch=22]\n",
            "Loss: 382.081832  [   91, epoch=22 finished!]\n",
            "batch_loss: 374.609500 [   92, epoch=23]\n",
            "batch_loss: 383.346125 [   93, epoch=23]\n",
            "batch_loss: 383.555208 [   94, epoch=23]\n",
            "batch_loss: 365.298453 [   95, epoch=23]\n",
            "Loss: 379.565480  [   95, epoch=23 finished!]\n",
            "batch_loss: 387.950040 [   96, epoch=24]\n",
            "batch_loss: 371.372417 [   97, epoch=24]\n",
            "batch_loss: 373.422734 [   98, epoch=24]\n",
            "batch_loss: 365.354478 [   99, epoch=24]\n",
            "Loss: 376.827331  [   99, epoch=24 finished!]\n",
            "batch_loss: 380.444259 [  100, epoch=25]\n",
            "batch_loss: 378.109919 [  101, epoch=25]\n",
            "batch_loss: 372.580742 [  102, epoch=25]\n",
            "batch_loss: 347.750962 [  103, epoch=25]\n",
            "Loss: 375.237585  [  103, epoch=25 finished!]\n",
            "batch_loss: 384.509913 [  104, epoch=26]\n",
            "batch_loss: 372.285421 [  105, epoch=26]\n",
            "batch_loss: 365.448532 [  106, epoch=26]\n",
            "batch_loss: 371.417879 [  107, epoch=26]\n",
            "Loss: 373.916961  [  107, epoch=26 finished!]\n",
            "batch_loss: 373.467307 [  108, epoch=27]\n",
            "batch_loss: 371.104220 [  109, epoch=27]\n",
            "batch_loss: 373.308454 [  110, epoch=27]\n",
            "batch_loss: 357.816269 [  111, epoch=27]\n",
            "Loss: 371.712885  [  111, epoch=27 finished!]\n",
            "batch_loss: 371.608517 [  112, epoch=28]\n",
            "batch_loss: 365.691701 [  113, epoch=28]\n",
            "batch_loss: 361.109205 [  114, epoch=28]\n",
            "batch_loss: 380.539019 [  115, epoch=28]\n",
            "Loss: 367.025086  [  115, epoch=28 finished!]\n",
            "batch_loss: 372.150649 [  116, epoch=29]\n",
            "batch_loss: 365.679856 [  117, epoch=29]\n",
            "batch_loss: 358.510093 [  118, epoch=29]\n",
            "batch_loss: 333.913502 [  119, epoch=29]\n",
            "Loss: 363.501313  [  119, epoch=29 finished!]\n",
            "batch_loss: 360.893720 [  120, epoch=30]\n",
            "batch_loss: 365.519066 [  121, epoch=30]\n",
            "batch_loss: 352.743877 [  122, epoch=30]\n",
            "batch_loss: 357.405291 [  123, epoch=30]\n",
            "Loss: 359.576143  [  123, epoch=30 finished!]\n",
            "Generated text 1: Harry something to the with the with the with the with the with the with the with the to the to the \n",
            "Generated text 2: Harry something to the with the with the with the with the with the with the with the with the with \n",
            "Generated text 3: Harry something to the with the with the with the with the with the with the with the to the his the\n",
            "batch_loss: 365.569196 [  124, epoch=31]\n",
            "batch_loss: 347.107637 [  125, epoch=31]\n",
            "batch_loss: 357.745770 [  126, epoch=31]\n",
            "batch_loss: 343.736097 [  127, epoch=31]\n",
            "Loss: 356.001050  [  127, epoch=31 finished!]\n",
            "batch_loss: 361.498142 [  128, epoch=32]\n",
            "batch_loss: 355.195482 [  129, epoch=32]\n",
            "batch_loss: 344.331481 [  130, epoch=32]\n",
            "batch_loss: 339.259339 [  131, epoch=32]\n",
            "Loss: 352.785612  [  131, epoch=32 finished!]\n",
            "batch_loss: 350.684191 [  132, epoch=33]\n",
            "batch_loss: 352.360176 [  133, epoch=33]\n",
            "batch_loss: 348.323971 [  134, epoch=33]\n",
            "batch_loss: 340.381440 [  135, epoch=33]\n",
            "Loss: 349.834523  [  135, epoch=33 finished!]\n",
            "batch_loss: 345.057635 [  136, epoch=34]\n",
            "batch_loss: 356.092798 [  137, epoch=34]\n",
            "batch_loss: 344.627516 [  138, epoch=34]\n",
            "batch_loss: 330.865137 [  139, epoch=34]\n",
            "Loss: 347.498893  [  139, epoch=34 finished!]\n",
            "batch_loss: 358.848724 [  140, epoch=35]\n",
            "batch_loss: 338.580047 [  141, epoch=35]\n",
            "batch_loss: 337.907668 [  142, epoch=35]\n",
            "batch_loss: 349.099798 [  143, epoch=35]\n",
            "Loss: 345.358177  [  143, epoch=35 finished!]\n",
            "batch_loss: 349.011659 [  144, epoch=36]\n",
            "batch_loss: 344.230562 [  145, epoch=36]\n",
            "batch_loss: 339.551904 [  146, epoch=36]\n",
            "batch_loss: 341.093859 [  147, epoch=36]\n",
            "Loss: 344.069073  [  147, epoch=36 finished!]\n",
            "batch_loss: 346.190428 [  148, epoch=37]\n",
            "batch_loss: 346.908486 [  149, epoch=37]\n",
            "batch_loss: 335.924869 [  150, epoch=37]\n",
            "batch_loss: 330.516020 [  151, epoch=37]\n",
            "Loss: 342.237199  [  151, epoch=37 finished!]\n",
            "batch_loss: 344.448637 [  152, epoch=38]\n",
            "batch_loss: 341.582043 [  153, epoch=38]\n",
            "batch_loss: 338.759487 [  154, epoch=38]\n",
            "batch_loss: 324.722751 [  155, epoch=38]\n",
            "Loss: 340.555628  [  155, epoch=38 finished!]\n",
            "batch_loss: 343.659830 [  156, epoch=39]\n",
            "batch_loss: 335.942549 [  157, epoch=39]\n",
            "batch_loss: 340.755071 [  158, epoch=39]\n",
            "batch_loss: 329.443760 [  159, epoch=39]\n",
            "Loss: 339.460497  [  159, epoch=39 finished!]\n",
            "batch_loss: 339.832948 [  160, epoch=40]\n",
            "batch_loss: 343.130580 [  161, epoch=40]\n",
            "batch_loss: 330.320498 [  162, epoch=40]\n",
            "batch_loss: 332.825728 [  163, epoch=40]\n",
            "Loss: 337.456824  [  163, epoch=40 finished!]\n",
            "batch_loss: 336.212818 [  164, epoch=41]\n",
            "batch_loss: 336.958711 [  165, epoch=41]\n",
            "batch_loss: 337.937537 [  166, epoch=41]\n",
            "batch_loss: 316.820162 [  167, epoch=41]\n",
            "Loss: 335.789052  [  167, epoch=41 finished!]\n",
            "batch_loss: 331.173405 [  168, epoch=42]\n",
            "batch_loss: 340.510358 [  169, epoch=42]\n",
            "batch_loss: 337.495355 [  170, epoch=42]\n",
            "batch_loss: 322.603903 [  171, epoch=42]\n",
            "Loss: 335.542274  [  171, epoch=42 finished!]\n",
            "batch_loss: 347.406168 [  172, epoch=43]\n",
            "batch_loss: 322.327740 [  173, epoch=43]\n",
            "batch_loss: 339.248649 [  174, epoch=43]\n",
            "batch_loss: 326.034840 [  175, epoch=43]\n",
            "Loss: 335.692479  [  175, epoch=43 finished!]\n",
            "batch_loss: 343.377636 [  176, epoch=44]\n",
            "batch_loss: 332.395120 [  177, epoch=44]\n",
            "batch_loss: 333.617533 [  178, epoch=44]\n",
            "batch_loss: 330.497040 [  179, epoch=44]\n",
            "Loss: 336.095314  [  179, epoch=44 finished!]\n",
            "batch_loss: 331.177505 [  180, epoch=45]\n",
            "batch_loss: 332.738505 [  181, epoch=45]\n",
            "batch_loss: 328.718770 [  182, epoch=45]\n",
            "batch_loss: 330.027807 [  183, epoch=45]\n",
            "Loss: 330.825789  [  183, epoch=45 finished!]\n",
            "Generated text 1: Harry something that the really and and and and and and and and and and and and and and and and and \n",
            "Generated text 2: Harry something the had and and and and and and and and and and and and and and and and and and and \n",
            "Generated text 3: Harry something that the really of the really of the really and and and and and and and and and and \n",
            "batch_loss: 336.241391 [  184, epoch=46]\n",
            "batch_loss: 325.821638 [  185, epoch=46]\n",
            "batch_loss: 325.832888 [  186, epoch=46]\n",
            "batch_loss: 320.486405 [  187, epoch=46]\n",
            "Loss: 328.754940  [  187, epoch=46 finished!]\n",
            "batch_loss: 333.906318 [  188, epoch=47]\n",
            "batch_loss: 320.378630 [  189, epoch=47]\n",
            "batch_loss: 326.138629 [  190, epoch=47]\n",
            "batch_loss: 318.008635 [  191, epoch=47]\n",
            "Loss: 326.264963  [  191, epoch=47 finished!]\n",
            "batch_loss: 320.101690 [  192, epoch=48]\n",
            "batch_loss: 330.556504 [  193, epoch=48]\n",
            "batch_loss: 323.244568 [  194, epoch=48]\n",
            "batch_loss: 315.915007 [  195, epoch=48]\n",
            "Loss: 324.096292  [  195, epoch=48 finished!]\n",
            "batch_loss: 329.871574 [  196, epoch=49]\n",
            "batch_loss: 324.793501 [  197, epoch=49]\n",
            "batch_loss: 312.896496 [  198, epoch=49]\n",
            "batch_loss: 323.054011 [  199, epoch=49]\n",
            "Loss: 322.553439  [  199, epoch=49 finished!]\n",
            "batch_loss: 330.340072 [  200, epoch=50]\n",
            "batch_loss: 317.377364 [  201, epoch=50]\n",
            "batch_loss: 320.817762 [  202, epoch=50]\n",
            "batch_loss: 293.003847 [  203, epoch=50]\n",
            "Loss: 321.003916  [  203, epoch=50 finished!]\n",
            "batch_loss: 322.176167 [  204, epoch=51]\n",
            "batch_loss: 320.706919 [  205, epoch=51]\n",
            "batch_loss: 319.827247 [  206, epoch=51]\n",
            "batch_loss: 301.454532 [  207, epoch=51]\n",
            "Loss: 319.703481  [  207, epoch=51 finished!]\n",
            "batch_loss: 318.733588 [  208, epoch=52]\n",
            "batch_loss: 322.522489 [  209, epoch=52]\n",
            "batch_loss: 315.175497 [  210, epoch=52]\n",
            "batch_loss: 321.310948 [  211, epoch=52]\n",
            "Loss: 318.964796  [  211, epoch=52 finished!]\n",
            "batch_loss: 322.163575 [  212, epoch=53]\n",
            "batch_loss: 314.969309 [  213, epoch=53]\n",
            "batch_loss: 321.166430 [  214, epoch=53]\n",
            "batch_loss: 298.241053 [  215, epoch=53]\n",
            "Loss: 318.125593  [  215, epoch=53 finished!]\n",
            "batch_loss: 320.192916 [  216, epoch=54]\n",
            "batch_loss: 322.725444 [  217, epoch=54]\n",
            "batch_loss: 313.166669 [  218, epoch=54]\n",
            "batch_loss: 305.591782 [  219, epoch=54]\n",
            "Loss: 317.886564  [  219, epoch=54 finished!]\n",
            "batch_loss: 321.416005 [  220, epoch=55]\n",
            "batch_loss: 314.907865 [  221, epoch=55]\n",
            "batch_loss: 314.925790 [  222, epoch=55]\n",
            "batch_loss: 323.497389 [  223, epoch=55]\n",
            "Loss: 317.478963  [  223, epoch=55 finished!]\n",
            "batch_loss: 322.125049 [  224, epoch=56]\n",
            "batch_loss: 313.947262 [  225, epoch=56]\n",
            "batch_loss: 316.938130 [  226, epoch=56]\n",
            "batch_loss: 309.977260 [  227, epoch=56]\n",
            "Loss: 317.195510  [  227, epoch=56 finished!]\n",
            "batch_loss: 315.825881 [  228, epoch=57]\n",
            "batch_loss: 320.066722 [  229, epoch=57]\n",
            "batch_loss: 310.084805 [  230, epoch=57]\n",
            "batch_loss: 323.235071 [  231, epoch=57]\n",
            "Loss: 315.813791  [  231, epoch=57 finished!]\n",
            "batch_loss: 318.788822 [  232, epoch=58]\n",
            "batch_loss: 318.382615 [  233, epoch=58]\n",
            "batch_loss: 306.846343 [  234, epoch=58]\n",
            "batch_loss: 307.961825 [  235, epoch=58]\n",
            "Loss: 314.258551  [  235, epoch=58 finished!]\n",
            "batch_loss: 313.000999 [  236, epoch=59]\n",
            "batch_loss: 310.957419 [  237, epoch=59]\n",
            "batch_loss: 313.824882 [  238, epoch=59]\n",
            "batch_loss: 320.903951 [  239, epoch=59]\n",
            "Loss: 313.107116  [  239, epoch=59 finished!]\n",
            "batch_loss: 314.508841 [  240, epoch=60]\n",
            "batch_loss: 315.927059 [  241, epoch=60]\n",
            "batch_loss: 307.901806 [  242, epoch=60]\n",
            "batch_loss: 309.969719 [  243, epoch=60]\n",
            "Loss: 312.605893  [  243, epoch=60 finished!]\n",
            "Generated text 1: Harry something with the couldn't shouldn't wouldn't wouldn't wouldn't wouldn't shouldn't shouldn't \n",
            "Generated text 2: Harry something with the couldn't shouldn't wouldn't wouldn't wouldn't shouldn't wouldn't shouldn't \n",
            "Generated text 3: Harry something with the couldn't shouldn't wouldn't wouldn't wouldn't would should with the really \n",
            "batch_loss: 311.851893 [  244, epoch=61]\n",
            "batch_loss: 317.687168 [  245, epoch=61]\n",
            "batch_loss: 303.030521 [  246, epoch=61]\n",
            "batch_loss: 309.886196 [  247, epoch=61]\n",
            "Loss: 310.796659  [  247, epoch=61 finished!]\n",
            "batch_loss: 309.095644 [  248, epoch=62]\n",
            "batch_loss: 314.894459 [  249, epoch=62]\n",
            "batch_loss: 305.927793 [  250, epoch=62]\n",
            "batch_loss: 296.792691 [  251, epoch=62]\n",
            "Loss: 309.159453  [  251, epoch=62 finished!]\n",
            "batch_loss: 299.290440 [  252, epoch=63]\n",
            "batch_loss: 315.518441 [  253, epoch=63]\n",
            "batch_loss: 306.527940 [  254, epoch=63]\n",
            "batch_loss: 317.794649 [  255, epoch=63]\n",
            "Loss: 307.771357  [  255, epoch=63 finished!]\n",
            "batch_loss: 312.248046 [  256, epoch=64]\n",
            "batch_loss: 298.580701 [  257, epoch=64]\n",
            "batch_loss: 314.070693 [  258, epoch=64]\n",
            "batch_loss: 282.400450 [  259, epoch=64]\n",
            "Loss: 306.701869  [  259, epoch=64 finished!]\n",
            "batch_loss: 302.536747 [  260, epoch=65]\n",
            "batch_loss: 306.369979 [  261, epoch=65]\n",
            "batch_loss: 306.074687 [  262, epoch=65]\n",
            "batch_loss: 317.284907 [  263, epoch=65]\n",
            "Loss: 305.752144  [  263, epoch=65 finished!]\n",
            "batch_loss: 307.639096 [  264, epoch=66]\n",
            "batch_loss: 307.552721 [  265, epoch=66]\n",
            "batch_loss: 301.756275 [  266, epoch=66]\n",
            "batch_loss: 298.120576 [  267, epoch=66]\n",
            "Loss: 305.184851  [  267, epoch=66 finished!]\n",
            "batch_loss: 297.013217 [  268, epoch=67]\n",
            "batch_loss: 306.337254 [  269, epoch=67]\n",
            "batch_loss: 308.847943 [  270, epoch=67]\n",
            "batch_loss: 307.790070 [  271, epoch=67]\n",
            "Loss: 304.295898  [  271, epoch=67 finished!]\n",
            "batch_loss: 304.764454 [  272, epoch=68]\n",
            "batch_loss: 302.823222 [  273, epoch=68]\n",
            "batch_loss: 301.473014 [  274, epoch=68]\n",
            "batch_loss: 306.154399 [  275, epoch=68]\n",
            "Loss: 303.213603  [  275, epoch=68 finished!]\n",
            "batch_loss: 305.925047 [  276, epoch=69]\n",
            "batch_loss: 308.722780 [  277, epoch=69]\n",
            "batch_loss: 298.066754 [  278, epoch=69]\n",
            "batch_loss: 288.888695 [  279, epoch=69]\n",
            "Loss: 303.291157  [  279, epoch=69 finished!]\n",
            "batch_loss: 305.895104 [  280, epoch=70]\n",
            "batch_loss: 304.640953 [  281, epoch=70]\n",
            "batch_loss: 303.605031 [  282, epoch=70]\n",
            "batch_loss: 295.683008 [  283, epoch=70]\n",
            "Loss: 304.156519  [  283, epoch=70 finished!]\n",
            "batch_loss: 311.322233 [  284, epoch=71]\n",
            "batch_loss: 295.989886 [  285, epoch=71]\n",
            "batch_loss: 309.070767 [  286, epoch=71]\n",
            "batch_loss: 287.498714 [  287, epoch=71]\n",
            "Loss: 304.352723  [  287, epoch=71 finished!]\n",
            "batch_loss: 308.002839 [  288, epoch=72]\n",
            "batch_loss: 301.352169 [  289, epoch=72]\n",
            "batch_loss: 299.341718 [  290, epoch=72]\n",
            "batch_loss: 312.752686 [  291, epoch=72]\n",
            "Loss: 303.506870  [  291, epoch=72 finished!]\n",
            "batch_loss: 308.283122 [  292, epoch=73]\n",
            "batch_loss: 299.066109 [  293, epoch=73]\n",
            "batch_loss: 303.883255 [  294, epoch=73]\n",
            "batch_loss: 292.918209 [  295, epoch=73]\n",
            "Loss: 303.076220  [  295, epoch=73 finished!]\n",
            "batch_loss: 312.616903 [  296, epoch=74]\n",
            "batch_loss: 294.592406 [  297, epoch=74]\n",
            "batch_loss: 303.198345 [  298, epoch=74]\n",
            "batch_loss: 296.038581 [  299, epoch=74]\n",
            "Loss: 303.010761  [  299, epoch=74 finished!]\n",
            "batch_loss: 302.602817 [  300, epoch=75]\n",
            "batch_loss: 301.728115 [  301, epoch=75]\n",
            "batch_loss: 297.687558 [  302, epoch=75]\n",
            "batch_loss: 299.610124 [  303, epoch=75]\n",
            "Loss: 300.607263  [  303, epoch=75 finished!]\n",
            "Generated text 1: Harry couldn't shouldn't shouldn't shouldn't shouldn't shouldn't shouldn't shouldn't shouldn't have \n",
            "Generated text 2: Harry couldn't shouldn't shouldn't shouldn't shouldn't shouldn't shouldn't shouldn't shouldn't that \n",
            "Generated text 3: Harry couldn't shouldn't shouldn't shouldn't shouldn't shouldn't should shouldn't shouldn't have to \n",
            "batch_loss: 296.696367 [  304, epoch=76]\n",
            "batch_loss: 295.264281 [  305, epoch=76]\n",
            "batch_loss: 302.769230 [  306, epoch=76]\n",
            "batch_loss: 298.564995 [  307, epoch=76]\n",
            "Loss: 298.263141  [  307, epoch=76 finished!]\n",
            "batch_loss: 300.112620 [  308, epoch=77]\n",
            "batch_loss: 305.486571 [  309, epoch=77]\n",
            "batch_loss: 289.814227 [  310, epoch=77]\n",
            "batch_loss: 283.468516 [  311, epoch=77]\n",
            "Loss: 297.545504  [  311, epoch=77 finished!]\n",
            "batch_loss: 300.269302 [  312, epoch=78]\n",
            "batch_loss: 296.942865 [  313, epoch=78]\n",
            "batch_loss: 293.799794 [  314, epoch=78]\n",
            "batch_loss: 278.492663 [  315, epoch=78]\n",
            "Loss: 295.861871  [  315, epoch=78 finished!]\n",
            "batch_loss: 301.495987 [  316, epoch=79]\n",
            "batch_loss: 293.747126 [  317, epoch=79]\n",
            "batch_loss: 291.766558 [  318, epoch=79]\n",
            "batch_loss: 281.858722 [  319, epoch=79]\n",
            "Loss: 294.817765  [  319, epoch=79 finished!]\n",
            "batch_loss: 296.199457 [  320, epoch=80]\n",
            "batch_loss: 288.859291 [  321, epoch=80]\n",
            "batch_loss: 296.112149 [  322, epoch=80]\n",
            "batch_loss: 297.270776 [  323, epoch=80]\n",
            "Loss: 293.942485  [  323, epoch=80 finished!]\n",
            "batch_loss: 297.689779 [  324, epoch=81]\n",
            "batch_loss: 289.250024 [  325, epoch=81]\n",
            "batch_loss: 292.510973 [  326, epoch=81]\n",
            "batch_loss: 296.630699 [  327, epoch=81]\n",
            "Loss: 293.364996  [  327, epoch=81 finished!]\n",
            "batch_loss: 295.841680 [  328, epoch=82]\n",
            "batch_loss: 294.863233 [  329, epoch=82]\n",
            "batch_loss: 287.127498 [  330, epoch=82]\n",
            "batch_loss: 290.680753 [  331, epoch=82]\n",
            "Loss: 292.491723  [  331, epoch=82 finished!]\n",
            "batch_loss: 291.356788 [  332, epoch=83]\n",
            "batch_loss: 291.892893 [  333, epoch=83]\n",
            "batch_loss: 291.442480 [  334, epoch=83]\n",
            "batch_loss: 301.259248 [  335, epoch=83]\n",
            "Loss: 292.162230  [  335, epoch=83 finished!]\n",
            "batch_loss: 296.460880 [  336, epoch=84]\n",
            "batch_loss: 292.156854 [  337, epoch=84]\n",
            "batch_loss: 286.646787 [  338, epoch=84]\n",
            "batch_loss: 292.321272 [  339, epoch=84]\n",
            "Loss: 291.789788  [  339, epoch=84 finished!]\n",
            "batch_loss: 297.196588 [  340, epoch=85]\n",
            "batch_loss: 292.864369 [  341, epoch=85]\n",
            "batch_loss: 288.294924 [  342, epoch=85]\n",
            "batch_loss: 273.244026 [  343, epoch=85]\n",
            "Loss: 291.579632  [  343, epoch=85 finished!]\n",
            "batch_loss: 291.688646 [  344, epoch=86]\n",
            "batch_loss: 291.308852 [  345, epoch=86]\n",
            "batch_loss: 293.165693 [  346, epoch=86]\n",
            "batch_loss: 280.027674 [  347, epoch=86]\n",
            "Loss: 291.312370  [  347, epoch=86 finished!]\n",
            "batch_loss: 295.948389 [  348, epoch=87]\n",
            "batch_loss: 289.878038 [  349, epoch=87]\n",
            "batch_loss: 292.688522 [  350, epoch=87]\n",
            "batch_loss: 278.444212 [  351, epoch=87]\n",
            "Loss: 291.950226  [  351, epoch=87 finished!]\n",
            "batch_loss: 297.520754 [  352, epoch=88]\n",
            "batch_loss: 288.494539 [  353, epoch=88]\n",
            "batch_loss: 294.007672 [  354, epoch=88]\n",
            "batch_loss: 288.468575 [  355, epoch=88]\n",
            "Loss: 293.040369  [  355, epoch=88 finished!]\n",
            "batch_loss: 302.871610 [  356, epoch=89]\n",
            "batch_loss: 290.017842 [  357, epoch=89]\n",
            "batch_loss: 287.362915 [  358, epoch=89]\n",
            "batch_loss: 286.212667 [  359, epoch=89]\n",
            "Loss: 292.972933  [  359, epoch=89 finished!]\n",
            "batch_loss: 302.219188 [  360, epoch=90]\n",
            "batch_loss: 288.955309 [  361, epoch=90]\n",
            "batch_loss: 288.894273 [  362, epoch=90]\n",
            "batch_loss: 284.034279 [  363, epoch=90]\n",
            "Loss: 292.781107  [  363, epoch=90 finished!]\n",
            "Generated text 1: Harry shouldn't shouldn't should shouldn't shouldn't should shouldn't shouldn't shouldn't shouldn't \n",
            "Generated text 2: Harry shouldn't shouldn't shouldn't should shouldn't should shouldn't shouldn't shouldn't shouldn't \n",
            "Generated text 3: Harry shouldn't shouldn't should shouldn't shouldn't should shouldn't should shouldn't should should\n",
            "batch_loss: 297.443266 [  364, epoch=91]\n",
            "batch_loss: 288.150707 [  365, epoch=91]\n",
            "batch_loss: 298.233044 [  366, epoch=91]\n",
            "batch_loss: 291.530313 [  367, epoch=91]\n",
            "Loss: 294.419056  [  367, epoch=91 finished!]\n",
            "batch_loss: 295.949806 [  368, epoch=92]\n",
            "batch_loss: 290.269519 [  369, epoch=92]\n",
            "batch_loss: 293.436018 [  370, epoch=92]\n",
            "batch_loss: 297.108192 [  371, epoch=92]\n",
            "Loss: 293.458438  [  371, epoch=92 finished!]\n",
            "batch_loss: 286.128030 [  372, epoch=93]\n",
            "batch_loss: 295.477454 [  373, epoch=93]\n",
            "batch_loss: 289.134602 [  374, epoch=93]\n",
            "batch_loss: 286.181121 [  375, epoch=93]\n",
            "Loss: 289.995857  [  375, epoch=93 finished!]\n",
            "batch_loss: 298.756711 [  376, epoch=94]\n",
            "batch_loss: 283.589076 [  377, epoch=94]\n",
            "batch_loss: 288.568973 [  378, epoch=94]\n",
            "batch_loss: 270.717063 [  379, epoch=94]\n",
            "Loss: 289.096384  [  379, epoch=94 finished!]\n",
            "batch_loss: 288.491280 [  380, epoch=95]\n",
            "batch_loss: 286.382393 [  381, epoch=95]\n",
            "batch_loss: 284.130080 [  382, epoch=95]\n",
            "batch_loss: 297.952666 [  383, epoch=95]\n",
            "Loss: 287.051399  [  383, epoch=95 finished!]\n",
            "batch_loss: 292.816810 [  384, epoch=96]\n",
            "batch_loss: 285.821593 [  385, epoch=96]\n",
            "batch_loss: 283.389259 [  386, epoch=96]\n",
            "batch_loss: 275.249460 [  387, epoch=96]\n",
            "Loss: 286.596431  [  387, epoch=96 finished!]\n",
            "batch_loss: 286.306245 [  388, epoch=97]\n",
            "batch_loss: 288.426792 [  389, epoch=97]\n",
            "batch_loss: 281.601532 [  390, epoch=97]\n",
            "batch_loss: 291.045936 [  391, epoch=97]\n",
            "Loss: 285.790433  [  391, epoch=97 finished!]\n",
            "batch_loss: 286.971960 [  392, epoch=98]\n",
            "batch_loss: 284.384397 [  393, epoch=98]\n",
            "batch_loss: 283.832424 [  394, epoch=98]\n",
            "batch_loss: 281.029399 [  395, epoch=98]\n",
            "Loss: 284.814065  [  395, epoch=98 finished!]\n",
            "batch_loss: 291.318984 [  396, epoch=99]\n",
            "batch_loss: 278.439815 [  397, epoch=99]\n",
            "batch_loss: 286.729520 [  398, epoch=99]\n",
            "batch_loss: 276.354181 [  399, epoch=99]\n",
            "Loss: 284.932066  [  399, epoch=99 finished!]\n",
            "batch_loss: 289.269504 [  400, epoch=100]\n",
            "batch_loss: 288.481397 [  401, epoch=100]\n",
            "batch_loss: 275.589696 [  402, epoch=100]\n",
            "batch_loss: 289.325880 [  403, epoch=100]\n",
            "Loss: 284.747892  [  403, epoch=100 finished!]\n",
            "batch_loss: 294.161277 [  404, epoch=101]\n",
            "batch_loss: 275.488761 [  405, epoch=101]\n",
            "batch_loss: 282.659380 [  406, epoch=101]\n",
            "batch_loss: 294.123236 [  407, epoch=101]\n",
            "Loss: 284.721361  [  407, epoch=101 finished!]\n",
            "batch_loss: 291.552648 [  408, epoch=102]\n",
            "batch_loss: 285.054371 [  409, epoch=102]\n",
            "batch_loss: 279.636423 [  410, epoch=102]\n",
            "batch_loss: 276.504509 [  411, epoch=102]\n",
            "Loss: 284.864751  [  411, epoch=102 finished!]\n",
            "batch_loss: 285.401779 [  412, epoch=103]\n",
            "batch_loss: 282.109880 [  413, epoch=103]\n",
            "batch_loss: 286.553839 [  414, epoch=103]\n",
            "batch_loss: 274.906813 [  415, epoch=103]\n",
            "Loss: 284.084987  [  415, epoch=103 finished!]\n",
            "batch_loss: 283.481234 [  416, epoch=104]\n",
            "batch_loss: 284.907351 [  417, epoch=104]\n",
            "batch_loss: 280.637522 [  418, epoch=104]\n",
            "batch_loss: 278.903076 [  419, epoch=104]\n",
            "Loss: 282.755393  [  419, epoch=104 finished!]\n",
            "batch_loss: 285.706186 [  420, epoch=105]\n",
            "batch_loss: 282.392464 [  421, epoch=105]\n",
            "batch_loss: 278.429481 [  422, epoch=105]\n",
            "batch_loss: 284.211130 [  423, epoch=105]\n",
            "Loss: 282.301605  [  423, epoch=105 finished!]\n",
            "Generated text 1: Harry couldn't have with Harry with the couldn't have that he couldn't have that he couldn't have th\n",
            "Generated text 2: Harry couldn't have with Harry with the couldn't have that he couldn't have that he couldn't have a \n",
            "Generated text 3: Harry couldn't have with Harry with the couldn't have that he couldn't have that he couldn't have to\n",
            "batch_loss: 273.858689 [  424, epoch=106]\n",
            "batch_loss: 290.306454 [  425, epoch=106]\n",
            "batch_loss: 283.373604 [  426, epoch=106]\n",
            "batch_loss: 273.080058 [  427, epoch=106]\n",
            "Loss: 281.930925  [  427, epoch=106 finished!]\n",
            "batch_loss: 287.880232 [  428, epoch=107]\n",
            "batch_loss: 278.042254 [  429, epoch=107]\n",
            "batch_loss: 279.938796 [  430, epoch=107]\n",
            "batch_loss: 275.946629 [  431, epoch=107]\n",
            "Loss: 281.583131  [  431, epoch=107 finished!]\n",
            "batch_loss: 283.874018 [  432, epoch=108]\n",
            "batch_loss: 280.423974 [  433, epoch=108]\n",
            "batch_loss: 281.937400 [  434, epoch=108]\n",
            "batch_loss: 261.061997 [  435, epoch=108]\n",
            "Loss: 280.781785  [  435, epoch=108 finished!]\n",
            "batch_loss: 287.074142 [  436, epoch=109]\n",
            "batch_loss: 279.834252 [  437, epoch=109]\n",
            "batch_loss: 275.754690 [  438, epoch=109]\n",
            "batch_loss: 274.141515 [  439, epoch=109]\n",
            "Loss: 280.471467  [  439, epoch=109 finished!]\n",
            "batch_loss: 279.920187 [  440, epoch=110]\n",
            "batch_loss: 281.490880 [  441, epoch=110]\n",
            "batch_loss: 280.342357 [  442, epoch=110]\n",
            "batch_loss: 273.137452 [  443, epoch=110]\n",
            "Loss: 280.125007  [  443, epoch=110 finished!]\n",
            "batch_loss: 283.806944 [  444, epoch=111]\n",
            "batch_loss: 279.672138 [  445, epoch=111]\n",
            "batch_loss: 278.516850 [  446, epoch=111]\n",
            "batch_loss: 272.134232 [  447, epoch=111]\n",
            "Loss: 280.138958  [  447, epoch=111 finished!]\n",
            "batch_loss: 286.037928 [  448, epoch=112]\n",
            "batch_loss: 273.655638 [  449, epoch=112]\n",
            "batch_loss: 282.016035 [  450, epoch=112]\n",
            "batch_loss: 277.100008 [  451, epoch=112]\n",
            "Loss: 280.355783  [  451, epoch=112 finished!]\n",
            "batch_loss: 284.439057 [  452, epoch=113]\n",
            "batch_loss: 280.623457 [  453, epoch=113]\n",
            "batch_loss: 276.970346 [  454, epoch=113]\n",
            "batch_loss: 269.496547 [  455, epoch=113]\n",
            "Loss: 279.987768  [  455, epoch=113 finished!]\n",
            "batch_loss: 279.229841 [  456, epoch=114]\n",
            "batch_loss: 282.389261 [  457, epoch=114]\n",
            "batch_loss: 278.463499 [  458, epoch=114]\n",
            "batch_loss: 261.675462 [  459, epoch=114]\n",
            "Loss: 278.895243  [  459, epoch=114 finished!]\n",
            "batch_loss: 279.632646 [  460, epoch=115]\n",
            "batch_loss: 283.267373 [  461, epoch=115]\n",
            "batch_loss: 272.223509 [  462, epoch=115]\n",
            "batch_loss: 262.322110 [  463, epoch=115]\n",
            "Loss: 277.384105  [  463, epoch=115 finished!]\n",
            "batch_loss: 270.624129 [  464, epoch=116]\n",
            "batch_loss: 276.739278 [  465, epoch=116]\n",
            "batch_loss: 281.936340 [  466, epoch=116]\n",
            "batch_loss: 286.775780 [  467, epoch=116]\n",
            "Loss: 277.071365  [  467, epoch=116 finished!]\n",
            "batch_loss: 277.586726 [  468, epoch=117]\n",
            "batch_loss: 276.792849 [  469, epoch=117]\n",
            "batch_loss: 280.646622 [  470, epoch=117]\n",
            "batch_loss: 260.216914 [  471, epoch=117]\n",
            "Loss: 277.223776  [  471, epoch=117 finished!]\n",
            "batch_loss: 283.009922 [  472, epoch=118]\n",
            "batch_loss: 276.802275 [  473, epoch=118]\n",
            "batch_loss: 273.059325 [  474, epoch=118]\n",
            "batch_loss: 271.033577 [  475, epoch=118]\n",
            "Loss: 277.217233  [  475, epoch=118 finished!]\n",
            "batch_loss: 277.728905 [  476, epoch=119]\n",
            "batch_loss: 280.444132 [  477, epoch=119]\n",
            "batch_loss: 273.459426 [  478, epoch=119]\n",
            "batch_loss: 269.137984 [  479, epoch=119]\n",
            "Loss: 276.712741  [  479, epoch=119 finished!]\n",
            "batch_loss: 281.967520 [  480, epoch=120]\n",
            "batch_loss: 273.220692 [  481, epoch=120]\n",
            "batch_loss: 272.604817 [  482, epoch=120]\n",
            "batch_loss: 284.637389 [  483, epoch=120]\n",
            "Loss: 276.468178  [  483, epoch=120 finished!]\n",
            "Generated text 1: Harry grandfather with the couldn't seemed the couldn't seemed the couldn't have that she seemed the\n",
            "Generated text 2: Harry grandfather with the couldn't seemed the couldn't seemed the couldn't seemed the couldn't have\n",
            "Generated text 3: Harry grandfather with the couldn't seemed the couldn't seemed the couldn't have that she seemed to \n",
            "batch_loss: 281.654136 [  484, epoch=121]\n",
            "batch_loss: 274.763538 [  485, epoch=121]\n",
            "batch_loss: 272.986170 [  486, epoch=121]\n",
            "batch_loss: 278.481154 [  487, epoch=121]\n",
            "Loss: 276.592160  [  487, epoch=121 finished!]\n",
            "batch_loss: 274.072468 [  488, epoch=122]\n",
            "batch_loss: 273.343727 [  489, epoch=122]\n",
            "batch_loss: 284.570906 [  490, epoch=122]\n",
            "batch_loss: 275.010626 [  491, epoch=122]\n",
            "Loss: 277.185992  [  491, epoch=122 finished!]\n",
            "batch_loss: 278.743953 [  492, epoch=123]\n",
            "batch_loss: 278.439950 [  493, epoch=123]\n",
            "batch_loss: 277.229416 [  494, epoch=123]\n",
            "batch_loss: 265.395494 [  495, epoch=123]\n",
            "Loss: 277.351597  [  495, epoch=123 finished!]\n",
            "batch_loss: 279.977527 [  496, epoch=124]\n",
            "batch_loss: 265.865231 [  497, epoch=124]\n",
            "batch_loss: 281.790512 [  498, epoch=124]\n",
            "batch_loss: 275.067065 [  499, epoch=124]\n",
            "Loss: 275.827738  [  499, epoch=124 finished!]\n",
            "batch_loss: 272.979432 [  500, epoch=125]\n",
            "batch_loss: 277.209532 [  501, epoch=125]\n",
            "batch_loss: 275.528995 [  502, epoch=125]\n",
            "batch_loss: 276.631025 [  503, epoch=125]\n",
            "Loss: 275.325185  [  503, epoch=125 finished!]\n",
            "batch_loss: 281.019288 [  504, epoch=126]\n",
            "batch_loss: 271.806754 [  505, epoch=126]\n",
            "batch_loss: 276.472919 [  506, epoch=126]\n",
            "batch_loss: 264.735163 [  507, epoch=126]\n",
            "Loss: 275.711252  [  507, epoch=126 finished!]\n",
            "batch_loss: 282.817618 [  508, epoch=127]\n",
            "batch_loss: 269.782354 [  509, epoch=127]\n",
            "batch_loss: 276.049951 [  510, epoch=127]\n",
            "batch_loss: 269.586323 [  511, epoch=127]\n",
            "Loss: 275.807562  [  511, epoch=127 finished!]\n",
            "batch_loss: 282.959972 [  512, epoch=128]\n",
            "batch_loss: 271.991992 [  513, epoch=128]\n",
            "batch_loss: 271.131252 [  514, epoch=128]\n",
            "batch_loss: 266.079208 [  515, epoch=128]\n",
            "Loss: 274.788398  [  515, epoch=128 finished!]\n",
            "batch_loss: 279.653303 [  516, epoch=129]\n",
            "batch_loss: 270.143243 [  517, epoch=129]\n",
            "batch_loss: 273.068546 [  518, epoch=129]\n",
            "batch_loss: 271.895010 [  519, epoch=129]\n",
            "Loss: 274.140698  [  519, epoch=129 finished!]\n",
            "batch_loss: 281.024967 [  520, epoch=130]\n",
            "batch_loss: 268.891221 [  521, epoch=130]\n",
            "batch_loss: 272.989095 [  522, epoch=130]\n",
            "batch_loss: 271.684087 [  523, epoch=130]\n",
            "Loss: 274.140255  [  523, epoch=130 finished!]\n",
            "batch_loss: 269.612340 [  524, epoch=131]\n",
            "batch_loss: 271.381119 [  525, epoch=131]\n",
            "batch_loss: 277.618587 [  526, epoch=131]\n",
            "batch_loss: 281.959828 [  527, epoch=131]\n",
            "Loss: 273.431466  [  527, epoch=131 finished!]\n",
            "batch_loss: 274.737477 [  528, epoch=132]\n",
            "batch_loss: 272.252771 [  529, epoch=132]\n",
            "batch_loss: 272.516433 [  530, epoch=132]\n",
            "batch_loss: 268.393717 [  531, epoch=132]\n",
            "Loss: 272.874274  [  531, epoch=132 finished!]\n",
            "batch_loss: 278.573409 [  532, epoch=133]\n",
            "batch_loss: 266.338660 [  533, epoch=133]\n",
            "batch_loss: 274.311763 [  534, epoch=133]\n",
            "batch_loss: 259.743654 [  535, epoch=133]\n",
            "Loss: 272.252114  [  535, epoch=133 finished!]\n",
            "batch_loss: 274.949141 [  536, epoch=134]\n",
            "batch_loss: 272.842097 [  537, epoch=134]\n",
            "batch_loss: 267.320783 [  538, epoch=134]\n",
            "batch_loss: 267.415247 [  539, epoch=134]\n",
            "Loss: 271.439398  [  539, epoch=134 finished!]\n",
            "batch_loss: 269.561555 [  540, epoch=135]\n",
            "batch_loss: 279.323233 [  541, epoch=135]\n",
            "batch_loss: 266.254282 [  542, epoch=135]\n",
            "batch_loss: 264.932341 [  543, epoch=135]\n",
            "Loss: 271.294667  [  543, epoch=135 finished!]\n",
            "Generated text 1: Harry couldn't couldn't have to the couldn't couldn't have to the couldn't have to the couldn't have\n",
            "Generated text 2: Harry couldn't couldn't have to the couldn't couldn't have to the couldn't couldn't have something t\n",
            "Generated text 3: Harry couldn't couldn't have to the couldn't couldn't have to the couldn't have to the couldn't help\n",
            "batch_loss: 276.084525 [  544, epoch=136]\n",
            "batch_loss: 272.787500 [  545, epoch=136]\n",
            "batch_loss: 267.212093 [  546, epoch=136]\n",
            "batch_loss: 262.275231 [  547, epoch=136]\n",
            "Loss: 271.426308  [  547, epoch=136 finished!]\n",
            "batch_loss: 271.436316 [  548, epoch=137]\n",
            "batch_loss: 273.277569 [  549, epoch=137]\n",
            "batch_loss: 270.998167 [  550, epoch=137]\n",
            "batch_loss: 261.239811 [  551, epoch=137]\n",
            "Loss: 271.246055  [  551, epoch=137 finished!]\n",
            "batch_loss: 270.544106 [  552, epoch=138]\n",
            "batch_loss: 266.394724 [  553, epoch=138]\n",
            "batch_loss: 276.903355 [  554, epoch=138]\n",
            "batch_loss: 273.087469 [  555, epoch=138]\n",
            "Loss: 271.392201  [  555, epoch=138 finished!]\n",
            "batch_loss: 276.112947 [  556, epoch=139]\n",
            "batch_loss: 273.663679 [  557, epoch=139]\n",
            "batch_loss: 269.461086 [  558, epoch=139]\n",
            "batch_loss: 256.641128 [  559, epoch=139]\n",
            "Loss: 272.065035  [  559, epoch=139 finished!]\n",
            "batch_loss: 276.512936 [  560, epoch=140]\n",
            "batch_loss: 267.770786 [  561, epoch=140]\n",
            "batch_loss: 272.213696 [  562, epoch=140]\n",
            "batch_loss: 275.230241 [  563, epoch=140]\n",
            "Loss: 272.354876  [  563, epoch=140 finished!]\n",
            "batch_loss: 277.997483 [  564, epoch=141]\n",
            "batch_loss: 266.464563 [  565, epoch=141]\n",
            "batch_loss: 270.657868 [  566, epoch=141]\n",
            "batch_loss: 275.997805 [  567, epoch=141]\n",
            "Loss: 271.971395  [  567, epoch=141 finished!]\n",
            "batch_loss: 271.954111 [  568, epoch=142]\n",
            "batch_loss: 269.699790 [  569, epoch=142]\n",
            "batch_loss: 271.240757 [  570, epoch=142]\n",
            "batch_loss: 264.334940 [  571, epoch=142]\n",
            "Loss: 270.555830  [  571, epoch=142 finished!]\n",
            "batch_loss: 267.963616 [  572, epoch=143]\n",
            "batch_loss: 274.778503 [  573, epoch=143]\n",
            "batch_loss: 266.273661 [  574, epoch=143]\n",
            "batch_loss: 268.960637 [  575, epoch=143]\n",
            "Loss: 269.628042  [  575, epoch=143 finished!]\n",
            "batch_loss: 273.653585 [  576, epoch=144]\n",
            "batch_loss: 271.007493 [  577, epoch=144]\n",
            "batch_loss: 264.411687 [  578, epoch=144]\n",
            "batch_loss: 265.655192 [  579, epoch=144]\n",
            "Loss: 269.441924  [  579, epoch=144 finished!]\n",
            "batch_loss: 269.562901 [  580, epoch=145]\n",
            "batch_loss: 269.830216 [  581, epoch=145]\n",
            "batch_loss: 267.888908 [  582, epoch=145]\n",
            "batch_loss: 271.217505 [  583, epoch=145]\n",
            "Loss: 269.225024  [  583, epoch=145 finished!]\n",
            "batch_loss: 271.756908 [  584, epoch=146]\n",
            "batch_loss: 268.697795 [  585, epoch=146]\n",
            "batch_loss: 267.286537 [  586, epoch=146]\n",
            "batch_loss: 256.082982 [  587, epoch=146]\n",
            "Loss: 268.434879  [  587, epoch=146 finished!]\n",
            "batch_loss: 273.731068 [  588, epoch=147]\n",
            "batch_loss: 265.918797 [  589, epoch=147]\n",
            "batch_loss: 268.113749 [  590, epoch=147]\n",
            "batch_loss: 250.359469 [  591, epoch=147]\n",
            "Loss: 268.088746  [  591, epoch=147 finished!]\n",
            "batch_loss: 272.496438 [  592, epoch=148]\n",
            "batch_loss: 269.170214 [  593, epoch=148]\n",
            "batch_loss: 263.919027 [  594, epoch=148]\n",
            "batch_loss: 253.047867 [  595, epoch=148]\n",
            "Loss: 267.573429  [  595, epoch=148 finished!]\n",
            "batch_loss: 274.884527 [  596, epoch=149]\n",
            "batch_loss: 262.387176 [  597, epoch=149]\n",
            "batch_loss: 261.878033 [  598, epoch=149]\n",
            "batch_loss: 284.579632 [  599, epoch=149]\n",
            "Loss: 267.505930  [  599, epoch=149 finished!]\n",
            "batch_loss: 269.902977 [  600, epoch=150]\n",
            "batch_loss: 270.642179 [  601, epoch=150]\n",
            "batch_loss: 266.428791 [  602, epoch=150]\n",
            "batch_loss: 254.153947 [  603, epoch=150]\n",
            "Loss: 268.075876  [  603, epoch=150 finished!]\n",
            "Generated text 1: Harry couldn't have to the couldn't have to the couldn't have to the couldn't have to the couldn't h\n",
            "Generated text 2: Harry couldn't have that had been couldn't have to the couldn't have to the couldn't have you could \n",
            "Generated text 3: Harry couldn't have to the couldn't have to the couldn't have to the couldn't have to the couldn't w\n",
            "batch_loss: 275.666518 [  604, epoch=151]\n",
            "batch_loss: 265.274992 [  605, epoch=151]\n",
            "batch_loss: 265.740575 [  606, epoch=151]\n",
            "batch_loss: 264.308226 [  607, epoch=151]\n",
            "Loss: 268.611093  [  607, epoch=151 finished!]\n",
            "batch_loss: 275.265859 [  608, epoch=152]\n",
            "batch_loss: 267.145512 [  609, epoch=152]\n",
            "batch_loss: 265.737631 [  610, epoch=152]\n",
            "batch_loss: 258.490186 [  611, epoch=152]\n",
            "Loss: 268.710933  [  611, epoch=152 finished!]\n",
            "batch_loss: 268.553246 [  612, epoch=153]\n",
            "batch_loss: 264.097329 [  613, epoch=153]\n",
            "batch_loss: 271.755629 [  614, epoch=153]\n",
            "batch_loss: 273.328133 [  615, epoch=153]\n",
            "Loss: 268.455783  [  615, epoch=153 finished!]\n",
            "batch_loss: 269.671180 [  616, epoch=154]\n",
            "batch_loss: 278.090287 [  617, epoch=154]\n",
            "batch_loss: 258.615571 [  618, epoch=154]\n",
            "batch_loss: 260.113166 [  619, epoch=154]\n",
            "Loss: 268.256856  [  619, epoch=154 finished!]\n",
            "batch_loss: 274.035993 [  620, epoch=155]\n",
            "batch_loss: 260.155256 [  621, epoch=155]\n",
            "batch_loss: 266.381045 [  622, epoch=155]\n",
            "batch_loss: 282.556185 [  623, epoch=155]\n",
            "Loss: 267.826016  [  623, epoch=155 finished!]\n",
            "batch_loss: 270.022563 [  624, epoch=156]\n",
            "batch_loss: 266.670798 [  625, epoch=156]\n",
            "batch_loss: 264.793347 [  626, epoch=156]\n",
            "batch_loss: 267.442498 [  627, epoch=156]\n",
            "Loss: 267.179528  [  627, epoch=156 finished!]\n",
            "batch_loss: 270.191977 [  628, epoch=157]\n",
            "batch_loss: 260.262464 [  629, epoch=157]\n",
            "batch_loss: 267.854754 [  630, epoch=157]\n",
            "batch_loss: 268.934738 [  631, epoch=157]\n",
            "Loss: 266.277774  [  631, epoch=157 finished!]\n",
            "batch_loss: 262.276879 [  632, epoch=158]\n",
            "batch_loss: 270.575533 [  633, epoch=158]\n",
            "batch_loss: 266.784563 [  634, epoch=158]\n",
            "batch_loss: 251.754426 [  635, epoch=158]\n",
            "Loss: 265.633066  [  635, epoch=158 finished!]\n",
            "batch_loss: 271.231040 [  636, epoch=159]\n",
            "batch_loss: 260.856085 [  637, epoch=159]\n",
            "batch_loss: 264.472557 [  638, epoch=159]\n",
            "batch_loss: 262.269531 [  639, epoch=159]\n",
            "Loss: 265.319352  [  639, epoch=159 finished!]\n",
            "batch_loss: 270.806289 [  640, epoch=160]\n",
            "batch_loss: 263.205991 [  641, epoch=160]\n",
            "batch_loss: 260.916282 [  642, epoch=160]\n",
            "batch_loss: 266.868316 [  643, epoch=160]\n",
            "Loss: 265.092928  [  643, epoch=160 finished!]\n",
            "batch_loss: 266.138165 [  644, epoch=161]\n",
            "batch_loss: 261.025879 [  645, epoch=161]\n",
            "batch_loss: 267.880269 [  646, epoch=161]\n",
            "batch_loss: 262.732968 [  647, epoch=161]\n",
            "Loss: 264.873988  [  647, epoch=161 finished!]\n",
            "batch_loss: 268.875062 [  648, epoch=162]\n",
            "batch_loss: 264.694255 [  649, epoch=162]\n",
            "batch_loss: 262.125887 [  650, epoch=162]\n",
            "batch_loss: 256.246715 [  651, epoch=162]\n",
            "Loss: 264.677375  [  651, epoch=162 finished!]\n",
            "batch_loss: 268.815726 [  652, epoch=163]\n",
            "batch_loss: 264.011278 [  653, epoch=163]\n",
            "batch_loss: 261.573734 [  654, epoch=163]\n",
            "batch_loss: 261.369544 [  655, epoch=163]\n",
            "Loss: 264.588578  [  655, epoch=163 finished!]\n",
            "batch_loss: 264.601574 [  656, epoch=164]\n",
            "batch_loss: 264.940206 [  657, epoch=164]\n",
            "batch_loss: 265.326079 [  658, epoch=164]\n",
            "batch_loss: 262.946050 [  659, epoch=164]\n",
            "Loss: 264.831945  [  659, epoch=164 finished!]\n",
            "batch_loss: 267.461581 [  660, epoch=165]\n",
            "batch_loss: 263.439746 [  661, epoch=165]\n",
            "batch_loss: 262.743645 [  662, epoch=165]\n",
            "batch_loss: 266.292582 [  663, epoch=165]\n",
            "Loss: 264.655942  [  663, epoch=165 finished!]\n",
            "Generated text 1: Harry couldn't help with the couldn't have the couldn't have that she had been couldn't help with a \n",
            "Generated text 2: Harry couldn't help with the couldn't have asked with the couldn't have the couldn't have asked the \n",
            "Generated text 3: Harry couldn't help with the couldn't have the couldn't have that she had been couldn't help of the \n",
            "batch_loss: 266.727808 [  664, epoch=166]\n",
            "batch_loss: 270.515663 [  665, epoch=166]\n",
            "batch_loss: 258.301091 [  666, epoch=166]\n",
            "batch_loss: 256.188871 [  667, epoch=166]\n",
            "Loss: 264.626690  [  667, epoch=166 finished!]\n",
            "batch_loss: 269.209268 [  668, epoch=167]\n",
            "batch_loss: 260.801037 [  669, epoch=167]\n",
            "batch_loss: 263.936037 [  670, epoch=167]\n",
            "batch_loss: 258.758592 [  671, epoch=167]\n",
            "Loss: 264.285366  [  671, epoch=167 finished!]\n",
            "batch_loss: 265.482724 [  672, epoch=168]\n",
            "batch_loss: 272.972143 [  673, epoch=168]\n",
            "batch_loss: 258.756592 [  674, epoch=168]\n",
            "batch_loss: 253.655415 [  675, epoch=168]\n",
            "Loss: 264.991731  [  675, epoch=168 finished!]\n",
            "batch_loss: 263.823148 [  676, epoch=169]\n",
            "batch_loss: 264.214543 [  677, epoch=169]\n",
            "batch_loss: 266.694188 [  678, epoch=169]\n",
            "batch_loss: 273.367955 [  679, epoch=169]\n",
            "Loss: 265.432429  [  679, epoch=169 finished!]\n",
            "batch_loss: 263.055183 [  680, epoch=170]\n",
            "batch_loss: 263.821088 [  681, epoch=170]\n",
            "batch_loss: 269.615596 [  682, epoch=170]\n",
            "batch_loss: 276.069070 [  683, epoch=170]\n",
            "Loss: 266.149549  [  683, epoch=170 finished!]\n",
            "batch_loss: 271.115371 [  684, epoch=171]\n",
            "batch_loss: 264.584743 [  685, epoch=171]\n",
            "batch_loss: 268.351523 [  686, epoch=171]\n",
            "batch_loss: 243.660204 [  687, epoch=171]\n",
            "Loss: 266.514428  [  687, epoch=171 finished!]\n",
            "batch_loss: 268.109028 [  688, epoch=172]\n",
            "batch_loss: 266.682368 [  689, epoch=172]\n",
            "batch_loss: 265.240420 [  690, epoch=172]\n",
            "batch_loss: 257.196947 [  691, epoch=172]\n",
            "Loss: 266.092353  [  691, epoch=172 finished!]\n",
            "batch_loss: 266.929359 [  692, epoch=173]\n",
            "batch_loss: 262.336846 [  693, epoch=173]\n",
            "batch_loss: 266.725938 [  694, epoch=173]\n",
            "batch_loss: 248.915419 [  695, epoch=173]\n",
            "Loss: 264.317920  [  695, epoch=173 finished!]\n",
            "batch_loss: 264.769837 [  696, epoch=174]\n",
            "batch_loss: 261.151327 [  697, epoch=174]\n",
            "batch_loss: 264.891950 [  698, epoch=174]\n",
            "batch_loss: 267.256700 [  699, epoch=174]\n",
            "Loss: 263.829714  [  699, epoch=174 finished!]\n",
            "batch_loss: 264.973122 [  700, epoch=175]\n",
            "batch_loss: 264.799504 [  701, epoch=175]\n",
            "batch_loss: 261.217499 [  702, epoch=175]\n",
            "batch_loss: 255.981076 [  703, epoch=175]\n",
            "Loss: 263.189391  [  703, epoch=175 finished!]\n",
            "batch_loss: 268.218205 [  704, epoch=176]\n",
            "batch_loss: 259.155303 [  705, epoch=176]\n",
            "batch_loss: 258.016475 [  706, epoch=176]\n",
            "batch_loss: 270.235573 [  707, epoch=176]\n",
            "Loss: 262.317327  [  707, epoch=176 finished!]\n",
            "batch_loss: 263.446508 [  708, epoch=177]\n",
            "batch_loss: 266.463215 [  709, epoch=177]\n",
            "batch_loss: 257.148630 [  710, epoch=177]\n",
            "batch_loss: 256.732740 [  711, epoch=177]\n",
            "Loss: 262.006038  [  711, epoch=177 finished!]\n",
            "batch_loss: 265.490383 [  712, epoch=178]\n",
            "batch_loss: 259.144641 [  713, epoch=178]\n",
            "batch_loss: 263.834654 [  714, epoch=178]\n",
            "batch_loss: 251.820110 [  715, epoch=178]\n",
            "Loss: 262.144353  [  715, epoch=178 finished!]\n",
            "batch_loss: 263.337269 [  716, epoch=179]\n",
            "batch_loss: 261.676127 [  717, epoch=179]\n",
            "batch_loss: 263.365491 [  718, epoch=179]\n",
            "batch_loss: 253.255896 [  719, epoch=179]\n",
            "Loss: 262.204543  [  719, epoch=179 finished!]\n",
            "batch_loss: 263.541120 [  720, epoch=180]\n",
            "batch_loss: 262.737820 [  721, epoch=180]\n",
            "batch_loss: 262.770712 [  722, epoch=180]\n",
            "batch_loss: 249.895110 [  723, epoch=180]\n",
            "Loss: 262.206981  [  723, epoch=180 finished!]\n",
            "Generated text 1: Harry couldn't help that he couldn't help that he couldn't have that she couldn't have that he could\n",
            "Generated text 2: Harry couldn't help that he couldn't have that he couldn't have that she couldn't have that he could\n",
            "Generated text 3: Harry couldn't help that he couldn't have that she couldn't have that he couldn't have that he could\n",
            "batch_loss: 267.429997 [  724, epoch=181]\n",
            "batch_loss: 261.124322 [  725, epoch=181]\n",
            "batch_loss: 256.379034 [  726, epoch=181]\n",
            "batch_loss: 266.367755 [  727, epoch=181]\n",
            "Loss: 261.935871  [  727, epoch=181 finished!]\n",
            "batch_loss: 267.350740 [  728, epoch=182]\n",
            "batch_loss: 261.735356 [  729, epoch=182]\n",
            "batch_loss: 255.304999 [  730, epoch=182]\n",
            "batch_loss: 260.677234 [  731, epoch=182]\n",
            "Loss: 261.415175  [  731, epoch=182 finished!]\n",
            "batch_loss: 264.835561 [  732, epoch=183]\n",
            "batch_loss: 256.781420 [  733, epoch=183]\n",
            "batch_loss: 261.004257 [  734, epoch=183]\n",
            "batch_loss: 268.153580 [  735, epoch=183]\n",
            "Loss: 261.322899  [  735, epoch=183 finished!]\n",
            "batch_loss: 263.630101 [  736, epoch=184]\n",
            "batch_loss: 258.046069 [  737, epoch=184]\n",
            "batch_loss: 264.699445 [  738, epoch=184]\n",
            "batch_loss: 246.219341 [  739, epoch=184]\n",
            "Loss: 261.143842  [  739, epoch=184 finished!]\n",
            "batch_loss: 261.079633 [  740, epoch=185]\n",
            "batch_loss: 260.561723 [  741, epoch=185]\n",
            "batch_loss: 261.207270 [  742, epoch=185]\n",
            "batch_loss: 262.856722 [  743, epoch=185]\n",
            "Loss: 261.067212  [  743, epoch=185 finished!]\n",
            "batch_loss: 263.999164 [  744, epoch=186]\n",
            "batch_loss: 266.629890 [  745, epoch=186]\n",
            "batch_loss: 257.282655 [  746, epoch=186]\n",
            "batch_loss: 245.639619 [  747, epoch=186]\n",
            "Loss: 261.588514  [  747, epoch=186 finished!]\n",
            "batch_loss: 267.135907 [  748, epoch=187]\n",
            "batch_loss: 262.162219 [  749, epoch=187]\n",
            "batch_loss: 257.576249 [  750, epoch=187]\n",
            "batch_loss: 256.866386 [  751, epoch=187]\n",
            "Loss: 261.956741  [  751, epoch=187 finished!]\n",
            "batch_loss: 267.368661 [  752, epoch=188]\n",
            "batch_loss: 258.897220 [  753, epoch=188]\n",
            "batch_loss: 259.784697 [  754, epoch=188]\n",
            "batch_loss: 266.539772 [  755, epoch=188]\n",
            "Loss: 262.295915  [  755, epoch=188 finished!]\n",
            "batch_loss: 264.217248 [  756, epoch=189]\n",
            "batch_loss: 263.985160 [  757, epoch=189]\n",
            "batch_loss: 258.842586 [  758, epoch=189]\n",
            "batch_loss: 262.874550 [  759, epoch=189]\n",
            "Loss: 262.380798  [  759, epoch=189 finished!]\n",
            "batch_loss: 264.302343 [  760, epoch=190]\n",
            "batch_loss: 261.213595 [  761, epoch=190]\n",
            "batch_loss: 259.745958 [  762, epoch=190]\n",
            "batch_loss: 259.385741 [  763, epoch=190]\n",
            "Loss: 261.607850  [  763, epoch=190 finished!]\n",
            "batch_loss: 266.628063 [  764, epoch=191]\n",
            "batch_loss: 263.757753 [  765, epoch=191]\n",
            "batch_loss: 252.411618 [  766, epoch=191]\n",
            "batch_loss: 258.443445 [  767, epoch=191]\n",
            "Loss: 260.778909  [  767, epoch=191 finished!]\n",
            "batch_loss: 268.623045 [  768, epoch=192]\n",
            "batch_loss: 255.625670 [  769, epoch=192]\n",
            "batch_loss: 258.980559 [  770, epoch=192]\n",
            "batch_loss: 254.446837 [  771, epoch=192]\n",
            "Loss: 260.667391  [  771, epoch=192 finished!]\n",
            "batch_loss: 262.893543 [  772, epoch=193]\n",
            "batch_loss: 263.384944 [  773, epoch=193]\n",
            "batch_loss: 257.572165 [  774, epoch=193]\n",
            "batch_loss: 256.683983 [  775, epoch=193]\n",
            "Loss: 260.999766  [  775, epoch=193 finished!]\n",
            "batch_loss: 261.680569 [  776, epoch=194]\n",
            "batch_loss: 260.447003 [  777, epoch=194]\n",
            "batch_loss: 261.765108 [  778, epoch=194]\n",
            "batch_loss: 246.439988 [  779, epoch=194]\n",
            "Loss: 260.380874  [  779, epoch=194 finished!]\n",
            "batch_loss: 268.199101 [  780, epoch=195]\n",
            "batch_loss: 260.641810 [  781, epoch=195]\n",
            "batch_loss: 253.156028 [  782, epoch=195]\n",
            "batch_loss: 253.458706 [  783, epoch=195]\n",
            "Loss: 260.220991  [  783, epoch=195 finished!]\n",
            "Generated text 1: Harry grandfather grandfather grandfather grandfather grandfather grandfather grandfather grandfathe\n",
            "Generated text 2: Harry grandfather grandfather grandfather grandfather grandfather grandfather grandfather. 'What was\n",
            "Generated text 3: Harry grandfather grandfather grandfather grandfather grandfather grandfather grandfather had been t\n",
            "batch_loss: 269.352372 [  784, epoch=196]\n",
            "batch_loss: 256.589453 [  785, epoch=196]\n",
            "batch_loss: 253.920891 [  786, epoch=196]\n",
            "batch_loss: 259.572805 [  787, epoch=196]\n",
            "Loss: 259.930705  [  787, epoch=196 finished!]\n",
            "batch_loss: 257.358600 [  788, epoch=197]\n",
            "batch_loss: 254.111820 [  789, epoch=197]\n",
            "batch_loss: 266.988811 [  790, epoch=197]\n",
            "batch_loss: 261.445600 [  791, epoch=197]\n",
            "Loss: 259.607289  [  791, epoch=197 finished!]\n",
            "batch_loss: 260.361533 [  792, epoch=198]\n",
            "batch_loss: 257.785397 [  793, epoch=198]\n",
            "batch_loss: 260.228223 [  794, epoch=198]\n",
            "batch_loss: 261.813555 [  795, epoch=198]\n",
            "Loss: 259.603694  [  795, epoch=198 finished!]\n",
            "batch_loss: 264.027070 [  796, epoch=199]\n",
            "batch_loss: 260.422527 [  797, epoch=199]\n",
            "batch_loss: 256.042238 [  798, epoch=199]\n",
            "batch_loss: 248.987539 [  799, epoch=199]\n",
            "Loss: 259.474381  [  799, epoch=199 finished!]\n",
            "batch_loss: 259.487223 [  800, epoch=200]\n",
            "batch_loss: 260.390114 [  801, epoch=200]\n",
            "batch_loss: 256.040551 [  802, epoch=200]\n",
            "batch_loss: 264.879334 [  803, epoch=200]\n",
            "Loss: 259.024295  [  803, epoch=200 finished!]\n",
            "batch_loss: 266.029405 [  804, epoch=201]\n",
            "batch_loss: 257.359489 [  805, epoch=201]\n",
            "batch_loss: 256.454853 [  806, epoch=201]\n",
            "batch_loss: 252.444703 [  807, epoch=201]\n",
            "Loss: 259.484981  [  807, epoch=201 finished!]\n",
            "batch_loss: 263.739261 [  808, epoch=202]\n",
            "batch_loss: 260.728416 [  809, epoch=202]\n",
            "batch_loss: 257.994008 [  810, epoch=202]\n",
            "batch_loss: 261.633291 [  811, epoch=202]\n",
            "Loss: 260.870706  [  811, epoch=202 finished!]\n",
            "batch_loss: 266.428698 [  812, epoch=203]\n",
            "batch_loss: 259.371789 [  813, epoch=203]\n",
            "batch_loss: 260.852419 [  814, epoch=203]\n",
            "batch_loss: 255.223889 [  815, epoch=203]\n",
            "Loss: 261.786133  [  815, epoch=203 finished!]\n",
            "batch_loss: 263.741560 [  816, epoch=204]\n",
            "batch_loss: 261.470147 [  817, epoch=204]\n",
            "batch_loss: 256.810966 [  818, epoch=204]\n",
            "batch_loss: 268.608428 [  819, epoch=204]\n",
            "Loss: 261.163751  [  819, epoch=204 finished!]\n",
            "batch_loss: 264.317607 [  820, epoch=205]\n",
            "batch_loss: 263.408806 [  821, epoch=205]\n",
            "batch_loss: 253.337157 [  822, epoch=205]\n",
            "batch_loss: 241.891020 [  823, epoch=205]\n",
            "Loss: 259.215358  [  823, epoch=205 finished!]\n",
            "batch_loss: 266.648010 [  824, epoch=206]\n",
            "batch_loss: 257.396229 [  825, epoch=206]\n",
            "batch_loss: 255.542977 [  826, epoch=206]\n",
            "batch_loss: 240.102026 [  827, epoch=206]\n",
            "Loss: 258.643225  [  827, epoch=206 finished!]\n",
            "batch_loss: 261.911678 [  828, epoch=207]\n",
            "batch_loss: 254.262003 [  829, epoch=207]\n",
            "batch_loss: 259.375535 [  830, epoch=207]\n",
            "batch_loss: 257.785071 [  831, epoch=207]\n",
            "Loss: 258.471284  [  831, epoch=207 finished!]\n",
            "batch_loss: 260.501229 [  832, epoch=208]\n",
            "batch_loss: 257.578796 [  833, epoch=208]\n",
            "batch_loss: 256.361134 [  834, epoch=208]\n",
            "batch_loss: 253.145648 [  835, epoch=208]\n",
            "Loss: 257.838475  [  835, epoch=208 finished!]\n",
            "batch_loss: 257.944401 [  836, epoch=209]\n",
            "batch_loss: 254.152413 [  837, epoch=209]\n",
            "batch_loss: 256.573667 [  838, epoch=209]\n",
            "batch_loss: 271.830251 [  839, epoch=209]\n",
            "Loss: 257.186403  [  839, epoch=209 finished!]\n",
            "batch_loss: 258.122901 [  840, epoch=210]\n",
            "batch_loss: 249.830169 [  841, epoch=210]\n",
            "batch_loss: 264.067589 [  842, epoch=210]\n",
            "batch_loss: 248.076484 [  843, epoch=210]\n",
            "Loss: 256.768664  [  843, epoch=210 finished!]\n",
            "Generated text 1: Harry couldn't help at Hogwarts, Harry couldn't help that Harry couldn't help into the couldn't have\n",
            "Generated text 2: Harry couldn't help at Hogwarts, Harry couldn't help that Harry couldn't help with the couldn't have\n",
            "Generated text 3: Harry couldn't help at Hogwarts, Harry couldn't help that Harry couldn't help into the couldn't help\n",
            "batch_loss: 257.866657 [  844, epoch=211]\n",
            "batch_loss: 258.061946 [  845, epoch=211]\n",
            "batch_loss: 257.063754 [  846, epoch=211]\n",
            "batch_loss: 238.861921 [  847, epoch=211]\n",
            "Loss: 256.504057  [  847, epoch=211 finished!]\n",
            "batch_loss: 260.046636 [  848, epoch=212]\n",
            "batch_loss: 256.724261 [  849, epoch=212]\n",
            "batch_loss: 253.318965 [  850, epoch=212]\n",
            "batch_loss: 251.047256 [  851, epoch=212]\n",
            "Loss: 256.348065  [  851, epoch=212 finished!]\n",
            "batch_loss: 257.779338 [  852, epoch=213]\n",
            "batch_loss: 256.592963 [  853, epoch=213]\n",
            "batch_loss: 258.495262 [  854, epoch=213]\n",
            "batch_loss: 238.007954 [  855, epoch=213]\n",
            "Loss: 256.412337  [  855, epoch=213 finished!]\n",
            "batch_loss: 261.923079 [  856, epoch=214]\n",
            "batch_loss: 257.552963 [  857, epoch=214]\n",
            "batch_loss: 251.417514 [  858, epoch=214]\n",
            "batch_loss: 248.797711 [  859, epoch=214]\n",
            "Loss: 256.460641  [  859, epoch=214 finished!]\n",
            "batch_loss: 254.847568 [  860, epoch=215]\n",
            "batch_loss: 256.980850 [  861, epoch=215]\n",
            "batch_loss: 257.411678 [  862, epoch=215]\n",
            "batch_loss: 255.523205 [  863, epoch=215]\n",
            "Loss: 256.358444  [  863, epoch=215 finished!]\n",
            "batch_loss: 256.148863 [  864, epoch=216]\n",
            "batch_loss: 256.301911 [  865, epoch=216]\n",
            "batch_loss: 258.803500 [  866, epoch=216]\n",
            "batch_loss: 249.180283 [  867, epoch=216]\n",
            "Loss: 256.597066  [  867, epoch=216 finished!]\n",
            "batch_loss: 263.045631 [  868, epoch=217]\n",
            "batch_loss: 255.095414 [  869, epoch=217]\n",
            "batch_loss: 254.336597 [  870, epoch=217]\n",
            "batch_loss: 244.661099 [  871, epoch=217]\n",
            "Loss: 256.700870  [  871, epoch=217 finished!]\n",
            "batch_loss: 258.175863 [  872, epoch=218]\n",
            "batch_loss: 261.017526 [  873, epoch=218]\n",
            "batch_loss: 255.278419 [  874, epoch=218]\n",
            "batch_loss: 239.660931 [  875, epoch=218]\n",
            "Loss: 257.016078  [  875, epoch=218 finished!]\n",
            "batch_loss: 257.918146 [  876, epoch=219]\n",
            "batch_loss: 258.620439 [  877, epoch=219]\n",
            "batch_loss: 256.148982 [  878, epoch=219]\n",
            "batch_loss: 249.083673 [  879, epoch=219]\n",
            "Loss: 257.039393  [  879, epoch=219 finished!]\n",
            "batch_loss: 257.927108 [  880, epoch=220]\n",
            "batch_loss: 259.156185 [  881, epoch=220]\n",
            "batch_loss: 253.834848 [  882, epoch=220]\n",
            "batch_loss: 254.934150 [  883, epoch=220]\n",
            "Loss: 256.846938  [  883, epoch=220 finished!]\n",
            "batch_loss: 260.421210 [  884, epoch=221]\n",
            "batch_loss: 248.454732 [  885, epoch=221]\n",
            "batch_loss: 259.734648 [  886, epoch=221]\n",
            "batch_loss: 257.214866 [  887, epoch=221]\n",
            "Loss: 256.265928  [  887, epoch=221 finished!]\n",
            "batch_loss: 260.162831 [  888, epoch=222]\n",
            "batch_loss: 257.797070 [  889, epoch=222]\n",
            "batch_loss: 251.860721 [  890, epoch=222]\n",
            "batch_loss: 242.449640 [  891, epoch=222]\n",
            "Loss: 255.733398  [  891, epoch=222 finished!]\n",
            "batch_loss: 256.080083 [  892, epoch=223]\n",
            "batch_loss: 256.337150 [  893, epoch=223]\n",
            "batch_loss: 252.672946 [  894, epoch=223]\n",
            "batch_loss: 258.964588 [  895, epoch=223]\n",
            "Loss: 255.272813  [  895, epoch=223 finished!]\n",
            "batch_loss: 250.599904 [  896, epoch=224]\n",
            "batch_loss: 257.610856 [  897, epoch=224]\n",
            "batch_loss: 256.174451 [  898, epoch=224]\n",
            "batch_loss: 254.951672 [  899, epoch=224]\n",
            "Loss: 254.804732  [  899, epoch=224 finished!]\n",
            "batch_loss: 254.692787 [  900, epoch=225]\n",
            "batch_loss: 252.072414 [  901, epoch=225]\n",
            "batch_loss: 259.495178 [  902, epoch=225]\n",
            "batch_loss: 245.286410 [  903, epoch=225]\n",
            "Loss: 254.794894  [  903, epoch=225 finished!]\n",
            "Generated text 1: Harry looked his grandfather and Harry didn't even though Harry didn't even though Harry's grandfath\n",
            "Generated text 2: Harry looked his grandfather and Harry didn't even though Harry didn't even though the directed the \n",
            "Generated text 3: Harry looked his grandfather and Harry didn't even though Harry didn't even though Harry had been th\n",
            "batch_loss: 260.196979 [  904, epoch=226]\n",
            "batch_loss: 253.089203 [  905, epoch=226]\n",
            "batch_loss: 252.444970 [  906, epoch=226]\n",
            "batch_loss: 250.630313 [  907, epoch=226]\n",
            "Loss: 254.959079  [  907, epoch=226 finished!]\n",
            "batch_loss: 252.849172 [  908, epoch=227]\n",
            "batch_loss: 257.906104 [  909, epoch=227]\n",
            "batch_loss: 256.024813 [  910, epoch=227]\n",
            "batch_loss: 249.438890 [  911, epoch=227]\n",
            "Loss: 255.213643  [  911, epoch=227 finished!]\n",
            "batch_loss: 254.777431 [  912, epoch=228]\n",
            "batch_loss: 251.550747 [  913, epoch=228]\n",
            "batch_loss: 259.237963 [  914, epoch=228]\n",
            "batch_loss: 264.856391 [  915, epoch=228]\n",
            "Loss: 255.785192  [  915, epoch=228 finished!]\n",
            "batch_loss: 264.117064 [  916, epoch=229]\n",
            "batch_loss: 250.546869 [  917, epoch=229]\n",
            "batch_loss: 255.115553 [  918, epoch=229]\n",
            "batch_loss: 252.410644 [  919, epoch=229]\n",
            "Loss: 256.335108  [  919, epoch=229 finished!]\n",
            "batch_loss: 260.358709 [  920, epoch=230]\n",
            "batch_loss: 251.103395 [  921, epoch=230]\n",
            "batch_loss: 257.908208 [  922, epoch=230]\n",
            "batch_loss: 252.710374 [  923, epoch=230]\n",
            "Loss: 256.225625  [  923, epoch=230 finished!]\n",
            "batch_loss: 255.805690 [  924, epoch=231]\n",
            "batch_loss: 253.101760 [  925, epoch=231]\n",
            "batch_loss: 257.383612 [  926, epoch=231]\n",
            "batch_loss: 252.590811 [  927, epoch=231]\n",
            "Loss: 255.255159  [  927, epoch=231 finished!]\n",
            "batch_loss: 252.727779 [  928, epoch=232]\n",
            "batch_loss: 258.134450 [  929, epoch=232]\n",
            "batch_loss: 253.410747 [  930, epoch=232]\n",
            "batch_loss: 247.851775 [  931, epoch=232]\n",
            "Loss: 254.331578  [  931, epoch=232 finished!]\n",
            "batch_loss: 261.678765 [  932, epoch=233]\n",
            "batch_loss: 247.279365 [  933, epoch=233]\n",
            "batch_loss: 254.661947 [  934, epoch=233]\n",
            "batch_loss: 257.939848 [  935, epoch=233]\n",
            "Loss: 254.749789  [  935, epoch=233 finished!]\n",
            "batch_loss: 261.003387 [  936, epoch=234]\n",
            "batch_loss: 254.612088 [  937, epoch=234]\n",
            "batch_loss: 253.761163 [  938, epoch=234]\n",
            "batch_loss: 250.030801 [  939, epoch=234]\n",
            "Loss: 256.062278  [  939, epoch=234 finished!]\n",
            "batch_loss: 254.003594 [  940, epoch=235]\n",
            "batch_loss: 262.014841 [  941, epoch=235]\n",
            "batch_loss: 260.634905 [  942, epoch=235]\n",
            "batch_loss: 239.666010 [  943, epoch=235]\n",
            "Loss: 257.698703  [  943, epoch=235 finished!]\n",
            "batch_loss: 262.608095 [  944, epoch=236]\n",
            "batch_loss: 254.475910 [  945, epoch=236]\n",
            "batch_loss: 257.971949 [  946, epoch=236]\n",
            "batch_loss: 252.466417 [  947, epoch=236]\n",
            "Loss: 257.988855  [  947, epoch=236 finished!]\n",
            "batch_loss: 267.328577 [  948, epoch=237]\n",
            "batch_loss: 256.848929 [  949, epoch=237]\n",
            "batch_loss: 247.398342 [  950, epoch=237]\n",
            "batch_loss: 244.130133 [  951, epoch=237]\n",
            "Loss: 256.386059  [  951, epoch=237 finished!]\n",
            "batch_loss: 258.403986 [  952, epoch=238]\n",
            "batch_loss: 251.801384 [  953, epoch=238]\n",
            "batch_loss: 254.851689 [  954, epoch=238]\n",
            "batch_loss: 253.312297 [  955, epoch=238]\n",
            "Loss: 254.913718  [  955, epoch=238 finished!]\n",
            "batch_loss: 254.582167 [  956, epoch=239]\n",
            "batch_loss: 259.968924 [  957, epoch=239]\n",
            "batch_loss: 247.986439 [  958, epoch=239]\n",
            "batch_loss: 249.674875 [  959, epoch=239]\n",
            "Loss: 253.901269  [  959, epoch=239 finished!]\n",
            "batch_loss: 255.512611 [  960, epoch=240]\n",
            "batch_loss: 256.775576 [  961, epoch=240]\n",
            "batch_loss: 249.143808 [  962, epoch=240]\n",
            "batch_loss: 245.568397 [  963, epoch=240]\n",
            "Loss: 253.302132  [  963, epoch=240 finished!]\n",
            "Generated text 1: Harry looked his eyes. 'I don't think you don't think you don't think you don't think you think you \n",
            "Generated text 2: Harry looked his eyes. 'I don't think you don't think you don't think you don't think you don't you \n",
            "Generated text 3: Harry looked his eyes. 'I don't think you don't think you don't think you think you think you would \n",
            "batch_loss: 252.106482 [  964, epoch=241]\n",
            "batch_loss: 248.565276 [  965, epoch=241]\n",
            "batch_loss: 258.708265 [  966, epoch=241]\n",
            "batch_loss: 248.596449 [  967, epoch=241]\n",
            "Loss: 252.847168  [  967, epoch=241 finished!]\n",
            "batch_loss: 255.906368 [  968, epoch=242]\n",
            "batch_loss: 252.137971 [  969, epoch=242]\n",
            "batch_loss: 249.870732 [  970, epoch=242]\n",
            "batch_loss: 250.495141 [  971, epoch=242]\n",
            "Loss: 252.506124  [  971, epoch=242 finished!]\n",
            "batch_loss: 252.408027 [  972, epoch=243]\n",
            "batch_loss: 248.226498 [  973, epoch=243]\n",
            "batch_loss: 253.975036 [  974, epoch=243]\n",
            "batch_loss: 258.644154 [  975, epoch=243]\n",
            "Loss: 251.975049  [  975, epoch=243 finished!]\n",
            "batch_loss: 252.537982 [  976, epoch=244]\n",
            "batch_loss: 255.061702 [  977, epoch=244]\n",
            "batch_loss: 251.493424 [  978, epoch=244]\n",
            "batch_loss: 237.545707 [  979, epoch=244]\n",
            "Loss: 252.075618  [  979, epoch=244 finished!]\n",
            "batch_loss: 260.520934 [  980, epoch=245]\n",
            "batch_loss: 246.633273 [  981, epoch=245]\n",
            "batch_loss: 248.375963 [  982, epoch=245]\n",
            "batch_loss: 252.462391 [  983, epoch=245]\n",
            "Loss: 251.881581  [  983, epoch=245 finished!]\n",
            "batch_loss: 250.787190 [  984, epoch=246]\n",
            "batch_loss: 249.925416 [  985, epoch=246]\n",
            "batch_loss: 254.894894 [  986, epoch=246]\n",
            "batch_loss: 252.396421 [  987, epoch=246]\n",
            "Loss: 251.901697  [  987, epoch=246 finished!]\n",
            "batch_loss: 256.134192 [  988, epoch=247]\n",
            "batch_loss: 254.828271 [  989, epoch=247]\n",
            "batch_loss: 250.030543 [  990, epoch=247]\n",
            "batch_loss: 231.499220 [  991, epoch=247]\n",
            "Loss: 252.296787  [  991, epoch=247 finished!]\n",
            "batch_loss: 256.481654 [  992, epoch=248]\n",
            "batch_loss: 256.122533 [  993, epoch=248]\n",
            "batch_loss: 248.933122 [  994, epoch=248]\n",
            "batch_loss: 237.565062 [  995, epoch=248]\n",
            "Loss: 252.841279  [  995, epoch=248 finished!]\n",
            "batch_loss: 256.454808 [  996, epoch=249]\n",
            "batch_loss: 254.870994 [  997, epoch=249]\n",
            "batch_loss: 247.241028 [  998, epoch=249]\n",
            "batch_loss: 257.861728 [  999, epoch=249]\n",
            "Loss: 253.164479  [  999, epoch=249 finished!]\n",
            "batch_loss: 250.592682 [ 1000, epoch=250]\n",
            "batch_loss: 257.442411 [ 1001, epoch=250]\n",
            "batch_loss: 249.751826 [ 1002, epoch=250]\n",
            "batch_loss: 262.325518 [ 1003, epoch=250]\n",
            "Loss: 253.195956  [ 1003, epoch=250 finished!]\n",
            "batch_loss: 253.175068 [ 1004, epoch=251]\n",
            "batch_loss: 253.868077 [ 1005, epoch=251]\n",
            "batch_loss: 253.434255 [ 1006, epoch=251]\n",
            "batch_loss: 242.109700 [ 1007, epoch=251]\n",
            "Loss: 252.790170  [ 1007, epoch=251 finished!]\n",
            "batch_loss: 253.430813 [ 1008, epoch=252]\n",
            "batch_loss: 250.495820 [ 1009, epoch=252]\n",
            "batch_loss: 255.182316 [ 1010, epoch=252]\n",
            "batch_loss: 246.297099 [ 1011, epoch=252]\n",
            "Loss: 252.620519  [ 1011, epoch=252 finished!]\n",
            "batch_loss: 252.114471 [ 1012, epoch=253]\n",
            "batch_loss: 250.729250 [ 1013, epoch=253]\n",
            "batch_loss: 256.246920 [ 1014, epoch=253]\n",
            "batch_loss: 254.349113 [ 1015, epoch=253]\n",
            "Loss: 253.111587  [ 1015, epoch=253 finished!]\n",
            "batch_loss: 258.417966 [ 1016, epoch=254]\n",
            "batch_loss: 247.240514 [ 1017, epoch=254]\n",
            "batch_loss: 257.139922 [ 1018, epoch=254]\n",
            "batch_loss: 253.079399 [ 1019, epoch=254]\n",
            "Loss: 254.192915  [ 1019, epoch=254 finished!]\n",
            "batch_loss: 259.885075 [ 1020, epoch=255]\n",
            "batch_loss: 250.319905 [ 1021, epoch=255]\n",
            "batch_loss: 254.334067 [ 1022, epoch=255]\n",
            "batch_loss: 242.433306 [ 1023, epoch=255]\n",
            "Loss: 254.080486  [ 1023, epoch=255 finished!]\n",
            "Generated text 1: Harry looked his grandfather looked his grandfather looked with his eyes. 'What?' she said with the \n",
            "Generated text 2: Harry looked his grandfather looked his grandfather looked with his eyes. 'What?' she said. 'That's \n",
            "Generated text 3: Harry looked his grandfather looked his grandfather looked with his eyes. 'What?' she said with his \n",
            "batch_loss: 257.906261 [ 1024, epoch=256]\n",
            "batch_loss: 256.785724 [ 1025, epoch=256]\n",
            "batch_loss: 246.051054 [ 1026, epoch=256]\n",
            "batch_loss: 238.669989 [ 1027, epoch=256]\n",
            "Loss: 252.661029  [ 1027, epoch=256 finished!]\n",
            "batch_loss: 256.059258 [ 1028, epoch=257]\n",
            "batch_loss: 251.243769 [ 1029, epoch=257]\n",
            "batch_loss: 248.785843 [ 1030, epoch=257]\n",
            "batch_loss: 246.496864 [ 1031, epoch=257]\n",
            "Loss: 251.688262  [ 1031, epoch=257 finished!]\n",
            "batch_loss: 255.769605 [ 1032, epoch=258]\n",
            "batch_loss: 248.895512 [ 1033, epoch=258]\n",
            "batch_loss: 251.375765 [ 1034, epoch=258]\n",
            "batch_loss: 245.758426 [ 1035, epoch=258]\n",
            "Loss: 251.627692  [ 1035, epoch=258 finished!]\n",
            "batch_loss: 256.137589 [ 1036, epoch=259]\n",
            "batch_loss: 254.477084 [ 1037, epoch=259]\n",
            "batch_loss: 244.039910 [ 1038, epoch=259]\n",
            "batch_loss: 246.832847 [ 1039, epoch=259]\n",
            "Loss: 251.260394  [ 1039, epoch=259 finished!]\n",
            "batch_loss: 247.538685 [ 1040, epoch=260]\n",
            "batch_loss: 255.711630 [ 1041, epoch=260]\n",
            "batch_loss: 249.680782 [ 1042, epoch=260]\n",
            "batch_loss: 249.181544 [ 1043, epoch=260]\n",
            "Loss: 250.866254  [ 1043, epoch=260 finished!]\n",
            "batch_loss: 252.140420 [ 1044, epoch=261]\n",
            "batch_loss: 246.978602 [ 1045, epoch=261]\n",
            "batch_loss: 250.122312 [ 1046, epoch=261]\n",
            "batch_loss: 260.909646 [ 1047, epoch=261]\n",
            "Loss: 250.435820  [ 1047, epoch=261 finished!]\n",
            "batch_loss: 248.427263 [ 1048, epoch=262]\n",
            "batch_loss: 251.398763 [ 1049, epoch=262]\n",
            "batch_loss: 247.611591 [ 1050, epoch=262]\n",
            "batch_loss: 269.392479 [ 1051, epoch=262]\n",
            "Loss: 250.395052  [ 1051, epoch=262 finished!]\n",
            "batch_loss: 250.323884 [ 1052, epoch=263]\n",
            "batch_loss: 248.552063 [ 1053, epoch=263]\n",
            "batch_loss: 251.395672 [ 1054, epoch=263]\n",
            "batch_loss: 247.546143 [ 1055, epoch=263]\n",
            "Loss: 249.933555  [ 1055, epoch=263 finished!]\n",
            "batch_loss: 252.583080 [ 1056, epoch=264]\n",
            "batch_loss: 253.315478 [ 1057, epoch=264]\n",
            "batch_loss: 247.445694 [ 1058, epoch=264]\n",
            "batch_loss: 227.242442 [ 1059, epoch=264]\n",
            "Loss: 249.641872  [ 1059, epoch=264 finished!]\n",
            "batch_loss: 251.141813 [ 1060, epoch=265]\n",
            "batch_loss: 251.162219 [ 1061, epoch=265]\n",
            "batch_loss: 244.978999 [ 1062, epoch=265]\n",
            "batch_loss: 255.068764 [ 1063, epoch=265]\n",
            "Loss: 249.462955  [ 1063, epoch=265 finished!]\n",
            "batch_loss: 249.600327 [ 1064, epoch=266]\n",
            "batch_loss: 248.637347 [ 1065, epoch=266]\n",
            "batch_loss: 250.108662 [ 1066, epoch=266]\n",
            "batch_loss: 247.220757 [ 1067, epoch=266]\n",
            "Loss: 249.311314  [ 1067, epoch=266 finished!]\n",
            "batch_loss: 249.494324 [ 1068, epoch=267]\n",
            "batch_loss: 250.321480 [ 1069, epoch=267]\n",
            "batch_loss: 247.765096 [ 1070, epoch=267]\n",
            "batch_loss: 254.268953 [ 1071, epoch=267]\n",
            "Loss: 249.506772  [ 1071, epoch=267 finished!]\n",
            "batch_loss: 253.275641 [ 1072, epoch=268]\n",
            "batch_loss: 248.244949 [ 1073, epoch=268]\n",
            "batch_loss: 248.835065 [ 1074, epoch=268]\n",
            "batch_loss: 255.945950 [ 1075, epoch=268]\n",
            "Loss: 250.478092  [ 1075, epoch=268 finished!]\n",
            "batch_loss: 260.938793 [ 1076, epoch=269]\n",
            "batch_loss: 252.867501 [ 1077, epoch=269]\n",
            "batch_loss: 243.717737 [ 1078, epoch=269]\n",
            "batch_loss: 245.268838 [ 1079, epoch=269]\n",
            "Loss: 252.061366  [ 1079, epoch=269 finished!]\n",
            "batch_loss: 260.636968 [ 1080, epoch=270]\n",
            "batch_loss: 246.043592 [ 1081, epoch=270]\n",
            "batch_loss: 255.395882 [ 1082, epoch=270]\n",
            "batch_loss: 253.805237 [ 1083, epoch=270]\n",
            "Loss: 254.011892  [ 1083, epoch=270 finished!]\n",
            "Generated text 1: Harry couldn't have that Harry couldn't have that Harry couldn't have that Harry couldn't have that \n",
            "Generated text 2: Harry couldn't have that Harry couldn't have that Harry couldn't have that Harry didn't even though \n",
            "Generated text 3: Harry couldn't have that Harry couldn't have that Harry couldn't have that Harry couldn't have to th\n",
            "batch_loss: 257.782081 [ 1084, epoch=271]\n",
            "batch_loss: 250.911647 [ 1085, epoch=271]\n",
            "batch_loss: 255.050942 [ 1086, epoch=271]\n",
            "batch_loss: 240.923796 [ 1087, epoch=271]\n",
            "Loss: 253.738897  [ 1087, epoch=271 finished!]\n",
            "batch_loss: 256.296570 [ 1088, epoch=272]\n",
            "batch_loss: 253.918325 [ 1089, epoch=272]\n",
            "batch_loss: 246.651104 [ 1090, epoch=272]\n",
            "batch_loss: 239.781200 [ 1091, epoch=272]\n",
            "Loss: 251.516978  [ 1091, epoch=272 finished!]\n",
            "batch_loss: 253.560213 [ 1092, epoch=273]\n",
            "batch_loss: 247.897797 [ 1093, epoch=273]\n",
            "batch_loss: 252.145295 [ 1094, epoch=273]\n",
            "batch_loss: 244.064713 [ 1095, epoch=273]\n",
            "Loss: 250.760799  [ 1095, epoch=273 finished!]\n",
            "batch_loss: 255.004276 [ 1096, epoch=274]\n",
            "batch_loss: 249.137732 [ 1097, epoch=274]\n",
            "batch_loss: 253.440191 [ 1098, epoch=274]\n",
            "batch_loss: 236.925948 [ 1099, epoch=274]\n",
            "Loss: 251.564818  [ 1099, epoch=274 finished!]\n",
            "batch_loss: 250.265403 [ 1100, epoch=275]\n",
            "batch_loss: 249.004171 [ 1101, epoch=275]\n",
            "batch_loss: 254.026378 [ 1102, epoch=275]\n",
            "batch_loss: 249.578072 [ 1103, epoch=275]\n",
            "Loss: 251.004833  [ 1103, epoch=275 finished!]\n",
            "batch_loss: 252.562638 [ 1104, epoch=276]\n",
            "batch_loss: 250.822156 [ 1105, epoch=276]\n",
            "batch_loss: 249.729828 [ 1106, epoch=276]\n",
            "batch_loss: 231.292788 [ 1107, epoch=276]\n",
            "Loss: 249.819950  [ 1107, epoch=276 finished!]\n",
            "batch_loss: 250.398099 [ 1108, epoch=277]\n",
            "batch_loss: 254.318099 [ 1109, epoch=277]\n",
            "batch_loss: 245.935971 [ 1110, epoch=277]\n",
            "batch_loss: 239.187118 [ 1111, epoch=277]\n",
            "Loss: 249.536841  [ 1111, epoch=277 finished!]\n",
            "batch_loss: 250.028549 [ 1112, epoch=278]\n",
            "batch_loss: 246.085715 [ 1113, epoch=278]\n",
            "batch_loss: 250.166359 [ 1114, epoch=278]\n",
            "batch_loss: 255.216131 [ 1115, epoch=278]\n",
            "Loss: 249.158527  [ 1115, epoch=278 finished!]\n",
            "batch_loss: 250.055091 [ 1116, epoch=279]\n",
            "batch_loss: 245.464550 [ 1117, epoch=279]\n",
            "batch_loss: 252.575236 [ 1118, epoch=279]\n",
            "batch_loss: 240.913428 [ 1119, epoch=279]\n",
            "Loss: 248.843515  [ 1119, epoch=279 finished!]\n",
            "batch_loss: 253.020245 [ 1120, epoch=280]\n",
            "batch_loss: 249.140096 [ 1121, epoch=280]\n",
            "batch_loss: 245.538399 [ 1122, epoch=280]\n",
            "batch_loss: 239.859088 [ 1123, epoch=280]\n",
            "Loss: 248.654565  [ 1123, epoch=280 finished!]\n",
            "batch_loss: 257.542908 [ 1124, epoch=281]\n",
            "batch_loss: 244.568572 [ 1125, epoch=281]\n",
            "batch_loss: 246.090428 [ 1126, epoch=281]\n",
            "batch_loss: 240.892600 [ 1127, epoch=281]\n",
            "Loss: 248.875705  [ 1127, epoch=281 finished!]\n",
            "batch_loss: 250.392285 [ 1128, epoch=282]\n",
            "batch_loss: 247.248678 [ 1129, epoch=282]\n",
            "batch_loss: 251.014901 [ 1130, epoch=282]\n",
            "batch_loss: 241.073065 [ 1131, epoch=282]\n",
            "Loss: 249.028822  [ 1131, epoch=282 finished!]\n",
            "batch_loss: 256.539233 [ 1132, epoch=283]\n",
            "batch_loss: 247.933526 [ 1133, epoch=283]\n",
            "batch_loss: 246.627780 [ 1134, epoch=283]\n",
            "batch_loss: 238.840668 [ 1135, epoch=283]\n",
            "Loss: 249.655702  [ 1135, epoch=283 finished!]\n",
            "batch_loss: 254.945953 [ 1136, epoch=284]\n",
            "batch_loss: 247.982728 [ 1137, epoch=284]\n",
            "batch_loss: 248.084721 [ 1138, epoch=284]\n",
            "batch_loss: 239.913896 [ 1139, epoch=284]\n",
            "Loss: 249.694664  [ 1139, epoch=284 finished!]\n",
            "batch_loss: 256.794858 [ 1140, epoch=285]\n",
            "batch_loss: 246.669243 [ 1141, epoch=285]\n",
            "batch_loss: 246.468654 [ 1142, epoch=285]\n",
            "batch_loss: 242.201685 [ 1143, epoch=285]\n",
            "Loss: 249.497826  [ 1143, epoch=285 finished!]\n",
            "Generated text 1: Harry nodded, looking his expression that he had been his eyes. 'I don't think you wouldn't have to \n",
            "Generated text 2: Harry nodded, looking his expression that he had been his eyes. 'I don't think you wouldn't think th\n",
            "Generated text 3: Harry nodded, looking his expression that he had been his eyes. 'I don't think you wouldn't want to \n",
            "batch_loss: 249.143167 [ 1144, epoch=286]\n",
            "batch_loss: 251.037701 [ 1145, epoch=286]\n",
            "batch_loss: 248.139653 [ 1146, epoch=286]\n",
            "batch_loss: 243.755253 [ 1147, epoch=286]\n",
            "Loss: 249.089424  [ 1147, epoch=286 finished!]\n",
            "batch_loss: 252.633249 [ 1148, epoch=287]\n",
            "batch_loss: 252.118953 [ 1149, epoch=287]\n",
            "batch_loss: 243.578909 [ 1150, epoch=287]\n",
            "batch_loss: 238.783279 [ 1151, epoch=287]\n",
            "Loss: 248.785974  [ 1151, epoch=287 finished!]\n",
            "batch_loss: 250.662604 [ 1152, epoch=288]\n",
            "batch_loss: 248.454087 [ 1153, epoch=288]\n",
            "batch_loss: 247.048261 [ 1154, epoch=288]\n",
            "batch_loss: 243.331765 [ 1155, epoch=288]\n",
            "Loss: 248.389104  [ 1155, epoch=288 finished!]\n",
            "batch_loss: 249.777058 [ 1156, epoch=289]\n",
            "batch_loss: 249.539070 [ 1157, epoch=289]\n",
            "batch_loss: 247.590100 [ 1158, epoch=289]\n",
            "batch_loss: 242.037066 [ 1159, epoch=289]\n",
            "Loss: 248.541070  [ 1159, epoch=289 finished!]\n",
            "batch_loss: 248.957873 [ 1160, epoch=290]\n",
            "batch_loss: 249.205584 [ 1161, epoch=290]\n",
            "batch_loss: 248.516761 [ 1162, epoch=290]\n",
            "batch_loss: 249.059168 [ 1163, epoch=290]\n",
            "Loss: 248.903633  [ 1163, epoch=290 finished!]\n",
            "batch_loss: 255.595279 [ 1164, epoch=291]\n",
            "batch_loss: 249.977026 [ 1165, epoch=291]\n",
            "batch_loss: 246.678162 [ 1166, epoch=291]\n",
            "batch_loss: 237.370251 [ 1167, epoch=291]\n",
            "Loss: 249.924639  [ 1167, epoch=291 finished!]\n",
            "batch_loss: 259.418068 [ 1168, epoch=292]\n",
            "batch_loss: 246.536742 [ 1169, epoch=292]\n",
            "batch_loss: 244.741164 [ 1170, epoch=292]\n",
            "batch_loss: 248.190792 [ 1171, epoch=292]\n",
            "Loss: 250.106053  [ 1171, epoch=292 finished!]\n",
            "batch_loss: 254.212748 [ 1172, epoch=293]\n",
            "batch_loss: 253.388911 [ 1173, epoch=293]\n",
            "batch_loss: 244.339441 [ 1174, epoch=293]\n",
            "batch_loss: 237.169046 [ 1175, epoch=293]\n",
            "Loss: 249.815465  [ 1175, epoch=293 finished!]\n",
            "batch_loss: 252.258302 [ 1176, epoch=294]\n",
            "batch_loss: 246.574479 [ 1177, epoch=294]\n",
            "batch_loss: 247.721180 [ 1178, epoch=294]\n",
            "batch_loss: 249.185233 [ 1179, epoch=294]\n",
            "Loss: 248.871922  [ 1179, epoch=294 finished!]\n",
            "batch_loss: 247.728449 [ 1180, epoch=295]\n",
            "batch_loss: 246.888833 [ 1181, epoch=295]\n",
            "batch_loss: 252.237941 [ 1182, epoch=295]\n",
            "batch_loss: 244.355304 [ 1183, epoch=295]\n",
            "Loss: 248.668149  [ 1183, epoch=295 finished!]\n",
            "batch_loss: 249.714433 [ 1184, epoch=296]\n",
            "batch_loss: 250.613645 [ 1185, epoch=296]\n",
            "batch_loss: 249.466767 [ 1186, epoch=296]\n",
            "batch_loss: 228.683249 [ 1187, epoch=296]\n",
            "Loss: 248.620629  [ 1187, epoch=296 finished!]\n",
            "batch_loss: 245.802616 [ 1188, epoch=297]\n",
            "batch_loss: 252.051552 [ 1189, epoch=297]\n",
            "batch_loss: 246.242593 [ 1190, epoch=297]\n",
            "batch_loss: 257.787111 [ 1191, epoch=297]\n",
            "Loss: 248.634111  [ 1191, epoch=297 finished!]\n",
            "batch_loss: 248.192156 [ 1192, epoch=298]\n",
            "batch_loss: 251.696768 [ 1193, epoch=298]\n",
            "batch_loss: 242.713190 [ 1194, epoch=298]\n",
            "batch_loss: 261.712774 [ 1195, epoch=298]\n",
            "Loss: 248.408841  [ 1195, epoch=298 finished!]\n",
            "batch_loss: 251.464987 [ 1196, epoch=299]\n",
            "batch_loss: 246.660061 [ 1197, epoch=299]\n",
            "batch_loss: 243.252200 [ 1198, epoch=299]\n",
            "batch_loss: 260.642858 [ 1199, epoch=299]\n",
            "Loss: 247.959731  [ 1199, epoch=299 finished!]\n",
            "batch_loss: 253.350801 [ 1200, epoch=300]\n",
            "batch_loss: 240.365370 [ 1201, epoch=300]\n",
            "batch_loss: 247.790247 [ 1202, epoch=300]\n",
            "batch_loss: 248.933720 [ 1203, epoch=300]\n",
            "Loss: 247.277698  [ 1203, epoch=300 finished!]\n",
            "Generated text 1: Harry couldn't help shoulder, she couldn't should have seemed that she couldn't should have seemed t\n",
            "Generated text 2: Harry couldn't help shoulder, she couldn't should have seemed that she couldn't help from the first \n",
            "Generated text 3: Harry couldn't help shoulder, she couldn't should have seemed that she couldn't help with the first \n",
            "batch_loss: 249.659778 [ 1204, epoch=301]\n",
            "batch_loss: 241.495616 [ 1205, epoch=301]\n",
            "batch_loss: 248.796443 [ 1206, epoch=301]\n",
            "batch_loss: 248.758260 [ 1207, epoch=301]\n",
            "Loss: 246.780651  [ 1207, epoch=301 finished!]\n",
            "batch_loss: 254.454344 [ 1208, epoch=302]\n",
            "batch_loss: 244.646825 [ 1209, epoch=302]\n",
            "batch_loss: 239.736131 [ 1210, epoch=302]\n",
            "batch_loss: 249.111076 [ 1211, epoch=302]\n",
            "Loss: 246.453828  [ 1211, epoch=302 finished!]\n",
            "batch_loss: 248.621603 [ 1212, epoch=303]\n",
            "batch_loss: 252.851472 [ 1213, epoch=303]\n",
            "batch_loss: 238.556431 [ 1214, epoch=303]\n",
            "batch_loss: 243.847455 [ 1215, epoch=303]\n",
            "Loss: 246.501955  [ 1215, epoch=303 finished!]\n",
            "batch_loss: 246.320992 [ 1216, epoch=304]\n",
            "batch_loss: 251.138656 [ 1217, epoch=304]\n",
            "batch_loss: 242.739137 [ 1218, epoch=304]\n",
            "batch_loss: 241.434871 [ 1219, epoch=304]\n",
            "Loss: 246.406047  [ 1219, epoch=304 finished!]\n",
            "batch_loss: 246.108663 [ 1220, epoch=305]\n",
            "batch_loss: 244.656767 [ 1221, epoch=305]\n",
            "batch_loss: 246.234887 [ 1222, epoch=305]\n",
            "batch_loss: 250.776432 [ 1223, epoch=305]\n",
            "Loss: 245.982029  [ 1223, epoch=305 finished!]\n",
            "batch_loss: 244.551500 [ 1224, epoch=306]\n",
            "batch_loss: 247.174176 [ 1225, epoch=306]\n",
            "batch_loss: 246.935128 [ 1226, epoch=306]\n",
            "batch_loss: 239.883172 [ 1227, epoch=306]\n",
            "Loss: 245.829280  [ 1227, epoch=306 finished!]\n",
            "batch_loss: 249.380704 [ 1228, epoch=307]\n",
            "batch_loss: 249.210743 [ 1229, epoch=307]\n",
            "batch_loss: 241.891909 [ 1230, epoch=307]\n",
            "batch_loss: 233.345391 [ 1231, epoch=307]\n",
            "Loss: 245.995946  [ 1231, epoch=307 finished!]\n",
            "batch_loss: 247.541144 [ 1232, epoch=308]\n",
            "batch_loss: 246.622333 [ 1233, epoch=308]\n",
            "batch_loss: 246.448869 [ 1234, epoch=308]\n",
            "batch_loss: 242.330658 [ 1235, epoch=308]\n",
            "Loss: 246.590664  [ 1235, epoch=308 finished!]\n",
            "batch_loss: 249.861037 [ 1236, epoch=309]\n",
            "batch_loss: 246.540257 [ 1237, epoch=309]\n",
            "batch_loss: 245.767442 [ 1238, epoch=309]\n",
            "batch_loss: 250.012907 [ 1239, epoch=309]\n",
            "Loss: 247.551433  [ 1239, epoch=309 finished!]\n",
            "batch_loss: 253.869520 [ 1240, epoch=310]\n",
            "batch_loss: 252.443740 [ 1241, epoch=310]\n",
            "batch_loss: 243.590995 [ 1242, epoch=310]\n",
            "batch_loss: 232.106410 [ 1243, epoch=310]\n",
            "Loss: 248.866052  [ 1243, epoch=310 finished!]\n",
            "batch_loss: 254.316116 [ 1244, epoch=311]\n",
            "batch_loss: 246.213035 [ 1245, epoch=311]\n",
            "batch_loss: 246.425545 [ 1246, epoch=311]\n",
            "batch_loss: 241.327427 [ 1247, epoch=311]\n",
            "Loss: 248.512446  [ 1247, epoch=311 finished!]\n",
            "batch_loss: 248.449272 [ 1248, epoch=312]\n",
            "batch_loss: 247.289138 [ 1249, epoch=312]\n",
            "batch_loss: 247.644642 [ 1250, epoch=312]\n",
            "batch_loss: 238.643335 [ 1251, epoch=312]\n",
            "Loss: 247.229749  [ 1251, epoch=312 finished!]\n",
            "batch_loss: 246.523246 [ 1252, epoch=313]\n",
            "batch_loss: 247.191489 [ 1253, epoch=313]\n",
            "batch_loss: 244.991949 [ 1254, epoch=313]\n",
            "batch_loss: 245.463296 [ 1255, epoch=313]\n",
            "Loss: 246.187913  [ 1255, epoch=313 finished!]\n",
            "batch_loss: 253.419135 [ 1256, epoch=314]\n",
            "batch_loss: 247.467308 [ 1257, epoch=314]\n",
            "batch_loss: 238.765946 [ 1258, epoch=314]\n",
            "batch_loss: 243.573338 [ 1259, epoch=314]\n",
            "Loss: 246.367092  [ 1259, epoch=314 finished!]\n",
            "batch_loss: 249.461563 [ 1260, epoch=315]\n",
            "batch_loss: 246.122140 [ 1261, epoch=315]\n",
            "batch_loss: 243.853616 [ 1262, epoch=315]\n",
            "batch_loss: 235.732864 [ 1263, epoch=315]\n",
            "Loss: 245.816082  [ 1263, epoch=315 finished!]\n",
            "Generated text 1: Harry looked his grandfather shoulder. 'I'm sure you didn't even though.' Hermione looked at himself\n",
            "Generated text 2: Harry looked his grandfather shoulder. 'I'm sure you didn't even though.' Hermione looked himself. '\n",
            "Generated text 3: Harry looked his grandfather shoulder. 'I'm sure you didn't even though.' Hermione looked his eyes. \n",
            "batch_loss: 242.338734 [ 1264, epoch=316]\n",
            "batch_loss: 249.563699 [ 1265, epoch=316]\n",
            "batch_loss: 246.079978 [ 1266, epoch=316]\n",
            "batch_loss: 238.281260 [ 1267, epoch=316]\n",
            "Loss: 245.518266  [ 1267, epoch=316 finished!]\n",
            "batch_loss: 248.248157 [ 1268, epoch=317]\n",
            "batch_loss: 248.614391 [ 1269, epoch=317]\n",
            "batch_loss: 241.434673 [ 1270, epoch=317]\n",
            "batch_loss: 232.775098 [ 1271, epoch=317]\n",
            "Loss: 245.277008  [ 1271, epoch=317 finished!]\n",
            "batch_loss: 244.264849 [ 1272, epoch=318]\n",
            "batch_loss: 244.542350 [ 1273, epoch=318]\n",
            "batch_loss: 245.654129 [ 1274, epoch=318]\n",
            "batch_loss: 258.240346 [ 1275, epoch=318]\n",
            "Loss: 245.648427  [ 1275, epoch=318 finished!]\n",
            "batch_loss: 255.130392 [ 1276, epoch=319]\n",
            "batch_loss: 241.719229 [ 1277, epoch=319]\n",
            "batch_loss: 242.527677 [ 1278, epoch=319]\n",
            "batch_loss: 245.529220 [ 1279, epoch=319]\n",
            "Loss: 246.401727  [ 1279, epoch=319 finished!]\n",
            "batch_loss: 250.767830 [ 1280, epoch=320]\n",
            "batch_loss: 242.340154 [ 1281, epoch=320]\n",
            "batch_loss: 247.818510 [ 1282, epoch=320]\n",
            "batch_loss: 242.383709 [ 1283, epoch=320]\n",
            "Loss: 246.692193  [ 1283, epoch=320 finished!]\n",
            "batch_loss: 247.968461 [ 1284, epoch=321]\n",
            "batch_loss: 243.258941 [ 1285, epoch=321]\n",
            "batch_loss: 246.183021 [ 1286, epoch=321]\n",
            "batch_loss: 246.981434 [ 1287, epoch=321]\n",
            "Loss: 245.876152  [ 1287, epoch=321 finished!]\n",
            "batch_loss: 245.611386 [ 1288, epoch=322]\n",
            "batch_loss: 246.682100 [ 1289, epoch=322]\n",
            "batch_loss: 244.522924 [ 1290, epoch=322]\n",
            "batch_loss: 239.751381 [ 1291, epoch=322]\n",
            "Loss: 245.244283  [ 1291, epoch=322 finished!]\n",
            "batch_loss: 247.845324 [ 1292, epoch=323]\n",
            "batch_loss: 243.758912 [ 1293, epoch=323]\n",
            "batch_loss: 246.953965 [ 1294, epoch=323]\n",
            "batch_loss: 233.422967 [ 1295, epoch=323]\n",
            "Loss: 245.398606  [ 1295, epoch=323 finished!]\n",
            "batch_loss: 245.614514 [ 1296, epoch=324]\n",
            "batch_loss: 247.653611 [ 1297, epoch=324]\n",
            "batch_loss: 242.879812 [ 1298, epoch=324]\n",
            "batch_loss: 246.587187 [ 1299, epoch=324]\n",
            "Loss: 245.456964  [ 1299, epoch=324 finished!]\n",
            "batch_loss: 242.611592 [ 1300, epoch=325]\n",
            "batch_loss: 247.210167 [ 1301, epoch=325]\n",
            "batch_loss: 247.595581 [ 1302, epoch=325]\n",
            "batch_loss: 240.884761 [ 1303, epoch=325]\n",
            "Loss: 245.502162  [ 1303, epoch=325 finished!]\n",
            "batch_loss: 247.544429 [ 1304, epoch=326]\n",
            "batch_loss: 248.322196 [ 1305, epoch=326]\n",
            "batch_loss: 243.695853 [ 1306, epoch=326]\n",
            "batch_loss: 232.857843 [ 1307, epoch=326]\n",
            "Loss: 245.677844  [ 1307, epoch=326 finished!]\n",
            "batch_loss: 247.354441 [ 1308, epoch=327]\n",
            "batch_loss: 245.145109 [ 1309, epoch=327]\n",
            "batch_loss: 247.103594 [ 1310, epoch=327]\n",
            "batch_loss: 233.377670 [ 1311, epoch=327]\n",
            "Loss: 245.722636  [ 1311, epoch=327 finished!]\n",
            "batch_loss: 245.801397 [ 1312, epoch=328]\n",
            "batch_loss: 248.691648 [ 1313, epoch=328]\n",
            "batch_loss: 242.708359 [ 1314, epoch=328]\n",
            "batch_loss: 243.224568 [ 1315, epoch=328]\n",
            "Loss: 245.578986  [ 1315, epoch=328 finished!]\n",
            "batch_loss: 248.282778 [ 1316, epoch=329]\n",
            "batch_loss: 242.619927 [ 1317, epoch=329]\n",
            "batch_loss: 243.505062 [ 1318, epoch=329]\n",
            "batch_loss: 250.003127 [ 1319, epoch=329]\n",
            "Loss: 245.123453  [ 1319, epoch=329 finished!]\n",
            "batch_loss: 244.790222 [ 1320, epoch=330]\n",
            "batch_loss: 246.592243 [ 1321, epoch=330]\n",
            "batch_loss: 247.192942 [ 1322, epoch=330]\n",
            "batch_loss: 233.802016 [ 1323, epoch=330]\n",
            "Loss: 245.427374  [ 1323, epoch=330 finished!]\n",
            "Generated text 1: Harry raised his grandfather's grandfather's grandfather's grandfather's grandfather's grandfather's\n",
            "Generated text 2: Harry raised his grandfather's grandfather's grandfather's grandfather's grandfather shouldn't have \n",
            "Generated text 3: Harry raised his grandfather's grandfather's grandfather's grandfather's grandfather shouldn't help \n",
            "batch_loss: 248.959603 [ 1324, epoch=331]\n",
            "batch_loss: 244.897734 [ 1325, epoch=331]\n",
            "batch_loss: 242.336423 [ 1326, epoch=331]\n",
            "batch_loss: 246.532783 [ 1327, epoch=331]\n",
            "Loss: 245.467939  [ 1327, epoch=331 finished!]\n",
            "batch_loss: 250.105678 [ 1328, epoch=332]\n",
            "batch_loss: 240.512532 [ 1329, epoch=332]\n",
            "batch_loss: 245.367122 [ 1330, epoch=332]\n",
            "batch_loss: 243.843574 [ 1331, epoch=332]\n",
            "Loss: 245.236830  [ 1331, epoch=332 finished!]\n",
            "batch_loss: 246.508237 [ 1332, epoch=333]\n",
            "batch_loss: 244.288247 [ 1333, epoch=333]\n",
            "batch_loss: 243.375799 [ 1334, epoch=333]\n",
            "batch_loss: 242.875714 [ 1335, epoch=333]\n",
            "Loss: 244.610052  [ 1335, epoch=333 finished!]\n",
            "batch_loss: 251.309397 [ 1336, epoch=334]\n",
            "batch_loss: 239.296270 [ 1337, epoch=334]\n",
            "batch_loss: 239.541170 [ 1338, epoch=334]\n",
            "batch_loss: 259.949991 [ 1339, epoch=334]\n",
            "Loss: 244.404478  [ 1339, epoch=334 finished!]\n",
            "batch_loss: 247.553371 [ 1340, epoch=335]\n",
            "batch_loss: 245.335274 [ 1341, epoch=335]\n",
            "batch_loss: 242.445859 [ 1342, epoch=335]\n",
            "batch_loss: 233.902069 [ 1343, epoch=335]\n",
            "Loss: 244.419899  [ 1343, epoch=335 finished!]\n",
            "batch_loss: 250.271780 [ 1344, epoch=336]\n",
            "batch_loss: 244.010891 [ 1345, epoch=336]\n",
            "batch_loss: 238.921770 [ 1346, epoch=336]\n",
            "batch_loss: 245.862996 [ 1347, epoch=336]\n",
            "Loss: 244.491653  [ 1347, epoch=336 finished!]\n",
            "batch_loss: 245.209306 [ 1348, epoch=337]\n",
            "batch_loss: 245.903167 [ 1349, epoch=337]\n",
            "batch_loss: 243.271085 [ 1350, epoch=337]\n",
            "batch_loss: 228.076144 [ 1351, epoch=337]\n",
            "Loss: 243.763025  [ 1351, epoch=337 finished!]\n",
            "batch_loss: 243.465398 [ 1352, epoch=338]\n",
            "batch_loss: 245.055832 [ 1353, epoch=338]\n",
            "batch_loss: 243.444991 [ 1354, epoch=338]\n",
            "batch_loss: 239.475495 [ 1355, epoch=338]\n",
            "Loss: 243.710281  [ 1355, epoch=338 finished!]\n",
            "batch_loss: 246.737838 [ 1356, epoch=339]\n",
            "batch_loss: 246.975567 [ 1357, epoch=339]\n",
            "batch_loss: 241.101218 [ 1358, epoch=339]\n",
            "batch_loss: 231.889550 [ 1359, epoch=339]\n",
            "Loss: 244.133128  [ 1359, epoch=339 finished!]\n",
            "batch_loss: 247.994654 [ 1360, epoch=340]\n",
            "batch_loss: 244.075606 [ 1361, epoch=340]\n",
            "batch_loss: 241.792730 [ 1362, epoch=340]\n",
            "batch_loss: 245.147430 [ 1363, epoch=340]\n",
            "Loss: 244.653476  [ 1363, epoch=340 finished!]\n",
            "batch_loss: 244.880300 [ 1364, epoch=341]\n",
            "batch_loss: 241.951738 [ 1365, epoch=341]\n",
            "batch_loss: 248.704596 [ 1366, epoch=341]\n",
            "batch_loss: 248.243168 [ 1367, epoch=341]\n",
            "Loss: 245.367939  [ 1367, epoch=341 finished!]\n",
            "batch_loss: 252.150661 [ 1368, epoch=342]\n",
            "batch_loss: 242.004665 [ 1369, epoch=342]\n",
            "batch_loss: 244.417308 [ 1370, epoch=342]\n",
            "batch_loss: 232.623098 [ 1371, epoch=342]\n",
            "Loss: 245.353770  [ 1371, epoch=342 finished!]\n",
            "batch_loss: 241.440411 [ 1372, epoch=343]\n",
            "batch_loss: 246.552215 [ 1373, epoch=343]\n",
            "batch_loss: 246.505333 [ 1374, epoch=343]\n",
            "batch_loss: 239.425621 [ 1375, epoch=343]\n",
            "Loss: 244.499049  [ 1375, epoch=343 finished!]\n",
            "batch_loss: 243.432026 [ 1376, epoch=344]\n",
            "batch_loss: 243.033190 [ 1377, epoch=344]\n",
            "batch_loss: 245.721721 [ 1378, epoch=344]\n",
            "batch_loss: 237.715341 [ 1379, epoch=344]\n",
            "Loss: 243.670715  [ 1379, epoch=344 finished!]\n",
            "batch_loss: 243.371605 [ 1380, epoch=345]\n",
            "batch_loss: 242.666204 [ 1381, epoch=345]\n",
            "batch_loss: 241.668854 [ 1382, epoch=345]\n",
            "batch_loss: 252.165785 [ 1383, epoch=345]\n",
            "Loss: 243.160999  [ 1383, epoch=345 finished!]\n",
            "Generated text 1: Harry couldn't help with his eyes. 'I'm sure you think you would have been something that you would \n",
            "Generated text 2: Harry couldn't help with his eyes. 'I'm sure you think you would have been something you would have \n",
            "Generated text 3: Harry couldn't help with his eyes. 'I'm sure you think you would have been something you would be th\n",
            "batch_loss: 241.303399 [ 1384, epoch=346]\n",
            "batch_loss: 245.672141 [ 1385, epoch=346]\n",
            "batch_loss: 240.292222 [ 1386, epoch=346]\n",
            "batch_loss: 248.152896 [ 1387, epoch=346]\n",
            "Loss: 242.776137  [ 1387, epoch=346 finished!]\n",
            "batch_loss: 247.488023 [ 1388, epoch=347]\n",
            "batch_loss: 239.449190 [ 1389, epoch=347]\n",
            "batch_loss: 242.378345 [ 1390, epoch=347]\n",
            "batch_loss: 236.226029 [ 1391, epoch=347]\n",
            "Loss: 242.680754  [ 1391, epoch=347 finished!]\n",
            "batch_loss: 247.580749 [ 1392, epoch=348]\n",
            "batch_loss: 245.640311 [ 1393, epoch=348]\n",
            "batch_loss: 236.931226 [ 1394, epoch=348]\n",
            "batch_loss: 232.261959 [ 1395, epoch=348]\n",
            "Loss: 242.697879  [ 1395, epoch=348 finished!]\n",
            "batch_loss: 249.929501 [ 1396, epoch=349]\n",
            "batch_loss: 234.702443 [ 1397, epoch=349]\n",
            "batch_loss: 245.335599 [ 1398, epoch=349]\n",
            "batch_loss: 233.172482 [ 1399, epoch=349]\n",
            "Loss: 242.696275  [ 1399, epoch=349 finished!]\n",
            "batch_loss: 241.238744 [ 1400, epoch=350]\n",
            "batch_loss: 249.274452 [ 1401, epoch=350]\n",
            "batch_loss: 239.774195 [ 1402, epoch=350]\n",
            "batch_loss: 229.761979 [ 1403, epoch=350]\n",
            "Loss: 242.585891  [ 1403, epoch=350 finished!]\n",
            "batch_loss: 245.311566 [ 1404, epoch=351]\n",
            "batch_loss: 243.194783 [ 1405, epoch=351]\n",
            "batch_loss: 240.149177 [ 1406, epoch=351]\n",
            "batch_loss: 239.205459 [ 1407, epoch=351]\n",
            "Loss: 242.658143  [ 1407, epoch=351 finished!]\n",
            "batch_loss: 242.082027 [ 1408, epoch=352]\n",
            "batch_loss: 247.475844 [ 1409, epoch=352]\n",
            "batch_loss: 239.571597 [ 1410, epoch=352]\n",
            "batch_loss: 236.942794 [ 1411, epoch=352]\n",
            "Loss: 242.666775  [ 1411, epoch=352 finished!]\n",
            "batch_loss: 244.390040 [ 1412, epoch=353]\n",
            "batch_loss: 241.081208 [ 1413, epoch=353]\n",
            "batch_loss: 241.211969 [ 1414, epoch=353]\n",
            "batch_loss: 249.965183 [ 1415, epoch=353]\n",
            "Loss: 242.705126  [ 1415, epoch=353 finished!]\n",
            "batch_loss: 243.236046 [ 1416, epoch=354]\n",
            "batch_loss: 244.723538 [ 1417, epoch=354]\n",
            "batch_loss: 242.326315 [ 1418, epoch=354]\n",
            "batch_loss: 237.985411 [ 1419, epoch=354]\n",
            "Loss: 243.092796  [ 1419, epoch=354 finished!]\n",
            "batch_loss: 251.368804 [ 1420, epoch=355]\n",
            "batch_loss: 240.955141 [ 1421, epoch=355]\n",
            "batch_loss: 241.182710 [ 1422, epoch=355]\n",
            "batch_loss: 230.459547 [ 1423, epoch=355]\n",
            "Loss: 243.635810  [ 1423, epoch=355 finished!]\n",
            "batch_loss: 253.680958 [ 1424, epoch=356]\n",
            "batch_loss: 238.905624 [ 1425, epoch=356]\n",
            "batch_loss: 241.602894 [ 1426, epoch=356]\n",
            "batch_loss: 237.290020 [ 1427, epoch=356]\n",
            "Loss: 244.270802  [ 1427, epoch=356 finished!]\n",
            "batch_loss: 244.707709 [ 1428, epoch=357]\n",
            "batch_loss: 250.172739 [ 1429, epoch=357]\n",
            "batch_loss: 237.249838 [ 1430, epoch=357]\n",
            "batch_loss: 236.568969 [ 1431, epoch=357]\n",
            "Loss: 243.582268  [ 1431, epoch=357 finished!]\n",
            "batch_loss: 246.381912 [ 1432, epoch=358]\n",
            "batch_loss: 239.655232 [ 1433, epoch=358]\n",
            "batch_loss: 244.431333 [ 1434, epoch=358]\n",
            "batch_loss: 233.671419 [ 1435, epoch=358]\n",
            "Loss: 242.883735  [ 1435, epoch=358 finished!]\n",
            "batch_loss: 246.112861 [ 1436, epoch=359]\n",
            "batch_loss: 241.007068 [ 1437, epoch=359]\n",
            "batch_loss: 245.198791 [ 1438, epoch=359]\n",
            "batch_loss: 241.124839 [ 1439, epoch=359]\n",
            "Loss: 243.922293  [ 1439, epoch=359 finished!]\n",
            "batch_loss: 247.774068 [ 1440, epoch=360]\n",
            "batch_loss: 243.998086 [ 1441, epoch=360]\n",
            "batch_loss: 244.276043 [ 1442, epoch=360]\n",
            "batch_loss: 232.730685 [ 1443, epoch=360]\n",
            "Loss: 244.570847  [ 1443, epoch=360 finished!]\n",
            "Generated text 1: Harry looked towards the direction of his eyes. 'I don't think I'll think I'll think I'll think you \n",
            "Generated text 2: Harry looked towards the direction of his eyes. 'I don't think I'll think I'll think I'll think it's\n",
            "Generated text 3: Harry looked towards the direction of his eyes. 'I don't think I'll think you couldn't want to make \n",
            "batch_loss: 246.009377 [ 1444, epoch=361]\n",
            "batch_loss: 241.150617 [ 1445, epoch=361]\n",
            "batch_loss: 241.591540 [ 1446, epoch=361]\n",
            "batch_loss: 247.816044 [ 1447, epoch=361]\n",
            "Loss: 243.219429  [ 1447, epoch=361 finished!]\n",
            "batch_loss: 250.729909 [ 1448, epoch=362]\n",
            "batch_loss: 238.002795 [ 1449, epoch=362]\n",
            "batch_loss: 240.760159 [ 1450, epoch=362]\n",
            "batch_loss: 236.508344 [ 1451, epoch=362]\n",
            "Loss: 242.753628  [ 1451, epoch=362 finished!]\n",
            "batch_loss: 241.760567 [ 1452, epoch=363]\n",
            "batch_loss: 244.679734 [ 1453, epoch=363]\n",
            "batch_loss: 241.465488 [ 1454, epoch=363]\n",
            "batch_loss: 241.789661 [ 1455, epoch=363]\n",
            "Loss: 242.583091  [ 1455, epoch=363 finished!]\n",
            "batch_loss: 244.189349 [ 1456, epoch=364]\n",
            "batch_loss: 241.226045 [ 1457, epoch=364]\n",
            "batch_loss: 239.981534 [ 1458, epoch=364]\n",
            "batch_loss: 249.075470 [ 1459, epoch=364]\n",
            "Loss: 242.247923  [ 1459, epoch=364 finished!]\n",
            "batch_loss: 240.702178 [ 1460, epoch=365]\n",
            "batch_loss: 243.073829 [ 1461, epoch=365]\n",
            "batch_loss: 238.292284 [ 1462, epoch=365]\n",
            "batch_loss: 249.878668 [ 1463, epoch=365]\n",
            "Loss: 241.256390  [ 1463, epoch=365 finished!]\n",
            "batch_loss: 249.119877 [ 1464, epoch=366]\n",
            "batch_loss: 237.413594 [ 1465, epoch=366]\n",
            "batch_loss: 239.819472 [ 1466, epoch=366]\n",
            "batch_loss: 226.891479 [ 1467, epoch=366]\n",
            "Loss: 241.178220  [ 1467, epoch=366 finished!]\n",
            "batch_loss: 237.463313 [ 1468, epoch=367]\n",
            "batch_loss: 243.526332 [ 1469, epoch=367]\n",
            "batch_loss: 241.805012 [ 1470, epoch=367]\n",
            "batch_loss: 245.647737 [ 1471, epoch=367]\n",
            "Loss: 241.222532  [ 1471, epoch=367 finished!]\n",
            "batch_loss: 244.122905 [ 1472, epoch=368]\n",
            "batch_loss: 241.337701 [ 1473, epoch=368]\n",
            "batch_loss: 238.838348 [ 1474, epoch=368]\n",
            "batch_loss: 238.165844 [ 1475, epoch=368]\n",
            "Loss: 241.231408  [ 1475, epoch=368 finished!]\n",
            "batch_loss: 250.682262 [ 1476, epoch=369]\n",
            "batch_loss: 240.983040 [ 1477, epoch=369]\n",
            "batch_loss: 233.560678 [ 1478, epoch=369]\n",
            "batch_loss: 231.977299 [ 1479, epoch=369]\n",
            "Loss: 241.139529  [ 1479, epoch=369 finished!]\n",
            "batch_loss: 244.760582 [ 1480, epoch=370]\n",
            "batch_loss: 241.903318 [ 1481, epoch=370]\n",
            "batch_loss: 238.746260 [ 1482, epoch=370]\n",
            "batch_loss: 234.281315 [ 1483, epoch=370]\n",
            "Loss: 241.339288  [ 1483, epoch=370 finished!]\n",
            "batch_loss: 247.613138 [ 1484, epoch=371]\n",
            "batch_loss: 242.433147 [ 1485, epoch=371]\n",
            "batch_loss: 236.747184 [ 1486, epoch=371]\n",
            "batch_loss: 231.390931 [ 1487, epoch=371]\n",
            "Loss: 241.593611  [ 1487, epoch=371 finished!]\n",
            "batch_loss: 244.556470 [ 1488, epoch=372]\n",
            "batch_loss: 240.388984 [ 1489, epoch=372]\n",
            "batch_loss: 240.607259 [ 1490, epoch=372]\n",
            "batch_loss: 245.218986 [ 1491, epoch=372]\n",
            "Loss: 242.058709  [ 1491, epoch=372 finished!]\n",
            "batch_loss: 241.178388 [ 1492, epoch=373]\n",
            "batch_loss: 242.503501 [ 1493, epoch=373]\n",
            "batch_loss: 243.149458 [ 1494, epoch=373]\n",
            "batch_loss: 245.479001 [ 1495, epoch=373]\n",
            "Loss: 242.474667  [ 1495, epoch=373 finished!]\n",
            "batch_loss: 245.419738 [ 1496, epoch=374]\n",
            "batch_loss: 244.015931 [ 1497, epoch=374]\n",
            "batch_loss: 240.804042 [ 1498, epoch=374]\n",
            "batch_loss: 235.402108 [ 1499, epoch=374]\n",
            "Loss: 242.918965  [ 1499, epoch=374 finished!]\n",
            "batch_loss: 247.757290 [ 1500, epoch=375]\n",
            "batch_loss: 237.920722 [ 1501, epoch=375]\n",
            "batch_loss: 243.913871 [ 1502, epoch=375]\n",
            "batch_loss: 242.441118 [ 1503, epoch=375]\n",
            "Loss: 243.150640  [ 1503, epoch=375 finished!]\n",
            "Generated text 1: Harry continued towards the door that was something something something something something with the\n",
            "Generated text 2: Harry continued towards the door that was something something something something something somethin\n",
            "Generated text 3: Harry continued towards the door that was something something something something something for the \n",
            "batch_loss: 249.751251 [ 1504, epoch=376]\n",
            "batch_loss: 239.020556 [ 1505, epoch=376]\n",
            "batch_loss: 242.662802 [ 1506, epoch=376]\n",
            "batch_loss: 236.845340 [ 1507, epoch=376]\n",
            "Loss: 243.381734  [ 1507, epoch=376 finished!]\n",
            "batch_loss: 250.218250 [ 1508, epoch=377]\n",
            "batch_loss: 238.444000 [ 1509, epoch=377]\n",
            "batch_loss: 241.914258 [ 1510, epoch=377]\n",
            "batch_loss: 236.909919 [ 1511, epoch=377]\n",
            "Loss: 243.117333  [ 1511, epoch=377 finished!]\n",
            "batch_loss: 244.334511 [ 1512, epoch=378]\n",
            "batch_loss: 241.596471 [ 1513, epoch=378]\n",
            "batch_loss: 240.603088 [ 1514, epoch=378]\n",
            "batch_loss: 238.924296 [ 1515, epoch=378]\n",
            "Loss: 241.977274  [ 1515, epoch=378 finished!]\n",
            "batch_loss: 244.245838 [ 1516, epoch=379]\n",
            "batch_loss: 240.387689 [ 1517, epoch=379]\n",
            "batch_loss: 238.476629 [ 1518, epoch=379]\n",
            "batch_loss: 243.998700 [ 1519, epoch=379]\n",
            "Loss: 241.219468  [ 1519, epoch=379 finished!]\n",
            "batch_loss: 246.521681 [ 1520, epoch=380]\n",
            "batch_loss: 239.635006 [ 1521, epoch=380]\n",
            "batch_loss: 239.229816 [ 1522, epoch=380]\n",
            "batch_loss: 235.867967 [ 1523, epoch=380]\n",
            "Loss: 241.429782  [ 1523, epoch=380 finished!]\n",
            "batch_loss: 250.923965 [ 1524, epoch=381]\n",
            "batch_loss: 238.458608 [ 1525, epoch=381]\n",
            "batch_loss: 239.664192 [ 1526, epoch=381]\n",
            "batch_loss: 232.520124 [ 1527, epoch=381]\n",
            "Loss: 242.368037  [ 1527, epoch=381 finished!]\n",
            "batch_loss: 240.942117 [ 1528, epoch=382]\n",
            "batch_loss: 244.858815 [ 1529, epoch=382]\n",
            "batch_loss: 241.544364 [ 1530, epoch=382]\n",
            "batch_loss: 238.384563 [ 1531, epoch=382]\n",
            "Loss: 242.197698  [ 1531, epoch=382 finished!]\n",
            "batch_loss: 245.747564 [ 1532, epoch=383]\n",
            "batch_loss: 238.441750 [ 1533, epoch=383]\n",
            "batch_loss: 242.843359 [ 1534, epoch=383]\n",
            "batch_loss: 237.120600 [ 1535, epoch=383]\n",
            "Loss: 242.021936  [ 1535, epoch=383 finished!]\n",
            "batch_loss: 244.188951 [ 1536, epoch=384]\n",
            "batch_loss: 242.158142 [ 1537, epoch=384]\n",
            "batch_loss: 240.347993 [ 1538, epoch=384]\n",
            "batch_loss: 234.898956 [ 1539, epoch=384]\n",
            "Loss: 241.779278  [ 1539, epoch=384 finished!]\n",
            "batch_loss: 238.635631 [ 1540, epoch=385]\n",
            "batch_loss: 242.718407 [ 1541, epoch=385]\n",
            "batch_loss: 241.864135 [ 1542, epoch=385]\n",
            "batch_loss: 241.957642 [ 1543, epoch=385]\n",
            "Loss: 241.127322  [ 1543, epoch=385 finished!]\n",
            "batch_loss: 240.885248 [ 1544, epoch=386]\n",
            "batch_loss: 239.738719 [ 1545, epoch=386]\n",
            "batch_loss: 239.890418 [ 1546, epoch=386]\n",
            "batch_loss: 242.811262 [ 1547, epoch=386]\n",
            "Loss: 240.334333  [ 1547, epoch=386 finished!]\n",
            "batch_loss: 242.744004 [ 1548, epoch=387]\n",
            "batch_loss: 244.767450 [ 1549, epoch=387]\n",
            "batch_loss: 234.249381 [ 1550, epoch=387]\n",
            "batch_loss: 232.639388 [ 1551, epoch=387]\n",
            "Loss: 240.096595  [ 1551, epoch=387 finished!]\n",
            "batch_loss: 244.440291 [ 1552, epoch=388]\n",
            "batch_loss: 238.918841 [ 1553, epoch=388]\n",
            "batch_loss: 239.283362 [ 1554, epoch=388]\n",
            "batch_loss: 226.421635 [ 1555, epoch=388]\n",
            "Loss: 239.988725  [ 1555, epoch=388 finished!]\n",
            "batch_loss: 243.228146 [ 1556, epoch=389]\n",
            "batch_loss: 239.725395 [ 1557, epoch=389]\n",
            "batch_loss: 236.566066 [ 1558, epoch=389]\n",
            "batch_loss: 239.547387 [ 1559, epoch=389]\n",
            "Loss: 239.821823  [ 1559, epoch=389 finished!]\n",
            "batch_loss: 243.611382 [ 1560, epoch=390]\n",
            "batch_loss: 240.758597 [ 1561, epoch=390]\n",
            "batch_loss: 237.154119 [ 1562, epoch=390]\n",
            "batch_loss: 227.972543 [ 1563, epoch=390]\n",
            "Loss: 239.734615  [ 1563, epoch=390 finished!]\n",
            "Generated text 1: Harry looked his grandfather had been his grandfather had been his grandfather had been his grandfat\n",
            "Generated text 2: Harry looked his grandfather had been his grandfather had been expected his grandfather had been his\n",
            "Generated text 3: Harry looked his grandfather had been his grandfather had been expected his grandfather had been the\n",
            "batch_loss: 242.099931 [ 1564, epoch=391]\n",
            "batch_loss: 242.771966 [ 1565, epoch=391]\n",
            "batch_loss: 235.056608 [ 1566, epoch=391]\n",
            "batch_loss: 237.679001 [ 1567, epoch=391]\n",
            "Loss: 239.834437  [ 1567, epoch=391 finished!]\n",
            "batch_loss: 242.643519 [ 1568, epoch=392]\n",
            "batch_loss: 235.516304 [ 1569, epoch=392]\n",
            "batch_loss: 241.412415 [ 1570, epoch=392]\n",
            "batch_loss: 238.922157 [ 1571, epoch=392]\n",
            "Loss: 239.799709  [ 1571, epoch=392 finished!]\n",
            "batch_loss: 237.551397 [ 1572, epoch=393]\n",
            "batch_loss: 242.600748 [ 1573, epoch=393]\n",
            "batch_loss: 239.309695 [ 1574, epoch=393]\n",
            "batch_loss: 246.368233 [ 1575, epoch=393]\n",
            "Loss: 240.224590  [ 1575, epoch=393 finished!]\n",
            "batch_loss: 246.312256 [ 1576, epoch=394]\n",
            "batch_loss: 238.602231 [ 1577, epoch=394]\n",
            "batch_loss: 236.700366 [ 1578, epoch=394]\n",
            "batch_loss: 243.768616 [ 1579, epoch=394]\n",
            "Loss: 240.737590  [ 1579, epoch=394 finished!]\n",
            "batch_loss: 246.091069 [ 1580, epoch=395]\n",
            "batch_loss: 233.286886 [ 1581, epoch=395]\n",
            "batch_loss: 245.587444 [ 1582, epoch=395]\n",
            "batch_loss: 237.360444 [ 1583, epoch=395]\n",
            "Loss: 241.390158  [ 1583, epoch=395 finished!]\n",
            "batch_loss: 245.147999 [ 1584, epoch=396]\n",
            "batch_loss: 240.024875 [ 1585, epoch=396]\n",
            "batch_loss: 243.425848 [ 1586, epoch=396]\n",
            "batch_loss: 237.423039 [ 1587, epoch=396]\n",
            "Loss: 242.530405  [ 1587, epoch=396 finished!]\n",
            "batch_loss: 240.736971 [ 1588, epoch=397]\n",
            "batch_loss: 250.056992 [ 1589, epoch=397]\n",
            "batch_loss: 241.429220 [ 1590, epoch=397]\n",
            "batch_loss: 230.515119 [ 1591, epoch=397]\n",
            "Loss: 243.237811  [ 1591, epoch=397 finished!]\n",
            "batch_loss: 246.369284 [ 1592, epoch=398]\n",
            "batch_loss: 239.358583 [ 1593, epoch=398]\n",
            "batch_loss: 240.177993 [ 1594, epoch=398]\n",
            "batch_loss: 238.829343 [ 1595, epoch=398]\n",
            "Loss: 241.774932  [ 1595, epoch=398 finished!]\n",
            "batch_loss: 244.951491 [ 1596, epoch=399]\n",
            "batch_loss: 240.244214 [ 1597, epoch=399]\n",
            "batch_loss: 240.381121 [ 1598, epoch=399]\n",
            "batch_loss: 230.053778 [ 1599, epoch=399]\n",
            "Loss: 241.130584  [ 1599, epoch=399 finished!]\n"
          ]
        }
      ],
      "source": [
        "#: Training Loop\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "    non_blocking = True\n",
        "elif True:\n",
        "    device = 'cpu'\n",
        "    non_blocking = False\n",
        "else:\n",
        "    #: causes NaNs\n",
        "    device = 'mps'\n",
        "    non_blocking = False\n",
        "\n",
        "#: Feel free to edit these hyperparameters or the optimizer\n",
        "#: You might want to use a learning-rate scheduler, such as\n",
        "#: [ReduceLROnPlateau --- PyTorch 2.0 documentation](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html)\n",
        "\n",
        "epochs = 400\n",
        "batch_size = 4096\n",
        "learning_rate = 0.01\n",
        "max_len = 0\n",
        "trunc_size = 64\n",
        "\n",
        "m = Model().to(device=device, non_blocking=non_blocking)\n",
        "\n",
        "m.train()\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"sum\", ignore_index=0)\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    dt = dt.shuffle()\n",
        "    epoch_loss = 0 \n",
        "    batch_counter = 0\n",
        "\n",
        "    for i in range(0, len(dt), batch_size):\n",
        "\n",
        "        \n",
        "        batch = dt[i:i + batch_size]\n",
        "        inputs = batch['input']\n",
        "        current_batch_size = len(inputs)\n",
        "        batch_counter += 1\n",
        "\n",
        "        if max_len > 0:\n",
        "            inputs = list(map(lambda x: x[:max_len] if len(x) > max_len else x, inputs))\n",
        "\n",
        "        lens = [len(seq) for seq in inputs]\n",
        "        current_max_len = max(lens)\n",
        "        mean_len = statistics.mean(lens)\n",
        "\n",
        "        targets = shift_left(inputs)\n",
        "        inputs = nn.utils.rnn.pad_sequence(inputs, padding_value=0, batch_first=True)   \n",
        "        targets = nn.utils.rnn.pad_sequence(targets, padding_value=0, batch_first=True) \n",
        "\n",
        "        hidden = None\n",
        "        trunc_loss = 0\n",
        "        \n",
        "        n_sub = 0 \n",
        "        for trunc in range(0, inputs.size(0), trunc_size):\n",
        "          \n",
        "            trunc_out = inputs[:, trunc: trunc + trunc_size]\n",
        "            trunc_targets = targets[:, trunc: trunc + trunc_size]\n",
        "            current_trunc_size = trunc_out.size(1)\n",
        "            \n",
        "            if current_trunc_size < trunc_size:\n",
        "              break\n",
        "              \n",
        "            n_sub += 1\n",
        "            trunc_out = trunc_out.to(device)\n",
        "            trunc_targets = trunc_targets.to(device)\n",
        "            trunc_outputs, hidden = m(trunc_out, hidden)\n",
        "            \n",
        "          \n",
        "            trunc_outputs = trunc_outputs.contiguous().view(-1, 257) \n",
        "            trunc_targets = trunc_targets.contiguous().view(-1)\n",
        "            loss = criterion(trunc_outputs, trunc_targets)\n",
        "            trunc_loss += loss.item()\n",
        "            loss.backward() \n",
        "            \n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "            \n",
        "        epoch_loss += trunc_loss\n",
        "        batch_loss = trunc_loss / current_batch_size\n",
        "        \n",
        "        \n",
        "        print(f\"batch_loss: {batch_loss:>7f} [{counter:>5d}, epoch={epoch}]\")\n",
        "        counter += 1\n",
        "        \n",
        "    l = epoch_loss / len(dt)\n",
        "    \n",
        "    \n",
        "    print(f\"Loss: {l:>7f}  [{counter-1:>5d}, epoch={epoch} finished!]\")\n",
        "    if epoch % 15 == 0:\n",
        "        eval_gen(display=3, model=m, desired_length=100, starting_string=\"Harry \", k=32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JTIoWRkM9un",
        "outputId": "7d649dc1-3d41-4dfb-e3f1-cd4c94e1c9d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated text 1: Harry couldn't help his grandfather had allowed towards Hermione with his grandfather had allowed th\n",
            "Generated text 2: Harry couldn't help his grandfather had allowed towards Hermione with his grandfather had allowed to\n",
            "Generated text 3: Harry couldn't help his grandfather had allowed towards Hermione with his grandfather had seemed to \n"
          ]
        }
      ],
      "source": [
        "eval_gen(display=3, model=m, desired_length=100, starting_string=\"Harry \", k=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecXrWcqLM9uo",
        "outputId": "9164a67f-81dd-40d7-dd8a-c37d43a1f497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated text 1: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed through the \n",
            "Generated text 2: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed towards the \n",
            "Generated text 3: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather and Harry couldn't help \n",
            "Generated text 4: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had always couldn't help\n",
            "Generated text 5: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather. Harry couldn't help the\n",
            "Generated text 6: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather. Harry couldn't hel\n",
            "Generated text 7: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed that he was \n",
            "Generated text 8: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help all with his grandfather had allowed to \n",
            "Generated text 9: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed that he had \n",
            "Generated text 10: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed through his \n",
            "Generated text 11: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed towards his \n",
            "Generated text 12: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help all with his grandfather had allowed the\n",
            "Generated text 13: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather had always started \n",
            "Generated text 14: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather had allowed through\n",
            "Generated text 15: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather would have been started \n",
            "Generated text 16: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed that he coul\n",
            "Generated text 17: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather had allowed to his \n",
            "Generated text 18: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather had allowed that he\n",
            "Generated text 19: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather had always couldn't\n",
            "Generated text 20: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather had allowed to the \n",
            "Generated text 21: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather. Harry couldn't help his\n",
            "Generated text 22: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather. Harry couldn't help all\n",
            "Generated text 23: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had always really could \n",
            "Generated text 24: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed towards her \n",
            "Generated text 25: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had always really didn't\n",
            "Generated text 26: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed through her \n",
            "Generated text 27: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather. Harry couldn't help but\n",
            "Generated text 28: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed towards Harr\n",
            "Generated text 29: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather had allowed to have\n",
            "Generated text 30: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help all with his grandfather had always been\n",
            "Generated text 31: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather and Harry could have bee\n",
            "Generated text 32: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather. Harry could have t\n",
            "Generated text 33: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather and Harry could have to \n",
            "Generated text 34: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help all with his grandfather had allowed tha\n",
            "Generated text 35: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed through thei\n",
            "Generated text 36: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather. Harry couldn't help her\n",
            "Generated text 37: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed to have the \n",
            "Generated text 38: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather had allowed that th\n",
            "Generated text 39: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed towards thei\n",
            "Generated text 40: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather and Harry didn't have to\n",
            "Generated text 41: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather had always really s\n",
            "Generated text 42: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather. Harry couldn't help to \n",
            "Generated text 43: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed through she \n",
            "Generated text 44: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather had always been his\n",
            "Generated text 45: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather would have been his\n",
            "Generated text 46: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help all with his grandfather had allowed his\n",
            "Generated text 47: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather had always been the\n",
            "Generated text 48: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed that he didn\n",
            "Generated text 49: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help his grandfather had allowed the first th\n",
            "Generated text 50: Harry looked his grandfather had allowed towards Hermione with his grandfather had allowed that he couldn't help with his grandfather had allowed that he couldn't help with his grandfather. Harry couldn't help with his grandfather would have been the\n"
          ]
        }
      ],
      "source": [
        "eval_gen(display=50, model=m, desired_length=250, starting_string=\"Harry \", k=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r-PhNIMGeDL",
        "outputId": "b110b7a5-a328-4d31-b92e-6cd7c6520834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated text 1: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione with a\n",
            "Generated text 2: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'But \n",
            "Generated text 3: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione with a\n",
            "Generated text 4: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'But \n",
            "Generated text 5: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'The \n",
            "Generated text 6: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'The \n",
            "Generated text 7: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'That\n",
            "Generated text 8: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'That\n",
            "Generated text 9: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What\n",
            "Generated text 10: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione with h\n",
            "Generated text 11: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What\n",
            "Generated text 12: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione's face\n",
            "Generated text 13: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione with h\n",
            "Generated text 14: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'You \n",
            "Generated text 15: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione's face\n",
            "Generated text 16: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'You \n",
            "Generated text 17: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather and Harry couldn't help with his grandfather had allowed that he couldn't help all th\n",
            "Generated text 18: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather and Harry couldn't help with his grandfather had allowed that he couldn't help their \n",
            "Generated text 19: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione with t\n",
            "Generated text 20: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'And \n",
            "Generated text 21: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione with t\n",
            "Generated text 22: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'How \n",
            "Generated text 23: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'And \n",
            "Generated text 24: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather and Harry couldn't help with his grandfather had allowed that he couldn't help the co\n",
            "Generated text 25: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather and Harry couldn't help with his grandfather had allowed that he couldn't help all of\n",
            "Generated text 26: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'Well\n",
            "Generated text 27: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'How \n",
            "Generated text 28: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione's eyes\n",
            "Generated text 29: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather and Harry couldn't help with his grandfather had allowed that he couldn't help with a\n",
            "Generated text 30: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'Well\n",
            "Generated text 31: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather and Harry couldn't help with his grandfather had allowed that he couldn't help but he\n",
            "Generated text 32: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione's eyes\n",
            "Generated text 33: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Harry's face. '\n",
            "Generated text 34: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather and Harry couldn't help with his grandfather had allowed that he couldn't help but th\n",
            "Generated text 35: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione of the\n",
            "Generated text 36: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'It's\n",
            "Generated text 37: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards the first that \n",
            "Generated text 38: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Harry's face. '\n",
            "Generated text 39: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'I'm \n",
            "Generated text 40: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione of the\n",
            "Generated text 41: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'It's\n",
            "Generated text 42: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards the first that \n",
            "Generated text 43: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather and Harry couldn't help with his grandfather had allowed that he couldn't help the st\n",
            "Generated text 44: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'I'm \n",
            "Generated text 45: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'They\n",
            "Generated text 46: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione's own \n",
            "Generated text 47: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione's hand\n",
            "Generated text 48: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'They\n",
            "Generated text 49: Arcturus looked his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'Harr\n",
            "Generated text 50: Arcturus stared his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his grandfather had allowed towards Hermione's hand\n"
          ]
        }
      ],
      "source": [
        "eval_gen(display=50, model=m, desired_length=250, starting_string=\"Arcturus \", k=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAXUB8vvM9un",
        "outputId": "d7c7ad56-6fe5-41ad-8c49-5dedd723a3d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated text 1: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with the \n",
            "Generated text 2: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione, and Harry couldn't help with his grandfather had allowed t\n",
            "Generated text 3: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with his \n",
            "Generated text 4: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with her \n",
            "Generated text 5: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'That's \n",
            "Generated text 6: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed that he couldn't help with the \n",
            "Generated text 7: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed that he couldn't help with his \n",
            "Generated text 8: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you\n",
            "Generated text 9: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'Do you \n",
            "Generated text 10: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione's face. '\n",
            "Generated text 11: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'You're \n",
            "Generated text 12: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you have\n",
            "Generated text 13: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather and Harry couldn't help all with his eyes. \n",
            "Generated text 14: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione, and Harry couldn't help with his grandfather had been his \n",
            "Generated text 15: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed towards Hermione with his eyes \n",
            "Generated text 16: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed that he couldn't help the first\n",
            "Generated text 17: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards the corridor with \n",
            "Generated text 18: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione's eyes. '\n",
            "Generated text 19: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'They're\n",
            "Generated text 20: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione, and Harry couldn't help with his grandfather would have to\n",
            "Generated text 21: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'And you\n",
            "Generated text 22: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione, and Harry couldn't help with his grandfather had allowed h\n",
            "Generated text 23: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But the\n",
            "Generated text 24: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with all \n",
            "Generated text 25: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione, and Harry couldn't help with his grandfather would have be\n",
            "Generated text 26: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'Harry, \n",
            "Generated text 27: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed that he couldn't help his eyes \n",
            "Generated text 28: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed that he couldn't help with her \n",
            "Generated text 29: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'That wa\n",
            "Generated text 30: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed towards Hermione with his eyes.\n",
            "Generated text 31: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed that he couldn't help the room \n",
            "Generated text 32: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'That was all\n",
            "Generated text 33: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'Thank y\n",
            "Generated text 34: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed that he couldn't help the world\n",
            "Generated text 35: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed that he couldn't help all of th\n",
            "Generated text 36: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione with a fe\n",
            "Generated text 37: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed that he couldn't help all of hi\n",
            "Generated text 38: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed that he couldn't help the more \n",
            "Generated text 39: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione's started\n",
            "Generated text 40: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed that he couldn't help his face \n",
            "Generated text 41: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione, and Harry couldn't help with his grandfather had always st\n",
            "Generated text 42: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione, and Harry couldn't help with his grandfather had always be\n",
            "Generated text 43: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed that he couldn't help his heart\n",
            "Generated text 44: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed that he couldn't help all the s\n",
            "Generated text 45: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed towards Hermione with his face \n",
            "Generated text 46: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione's particu\n",
            "Generated text 47: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione, and Harry couldn't help with his grandfather had been the \n",
            "Generated text 48: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed towards Hermione with his heart\n",
            "Generated text 49: Draco looked his grandfather had allowed towards Hermione. 'What happened?' she asked with his grandfather had allowed towards Hermione with his head \n",
            "Generated text 50: Draco looked his grandfather had allowed towards Hermione. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'There's\n"
          ]
        }
      ],
      "source": [
        "eval_gen(display=50, model=m, desired_length=150, starting_string=\"Draco \", k=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QKfmToSM9uo",
        "outputId": "01d25bab-bd3c-497f-d410-e036caf28d6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated text 1: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione's \n",
            "Generated text 2: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione with the\n",
            "Generated text 3: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' she asked, looking her \n",
            "Generated text 4: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'What happened?' she asked with a \n",
            "Generated text 5: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione. '\n",
            "Generated text 6: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione wit\n",
            "Generated text 7: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' she asked, looking his \n",
            "Generated text 8: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione with his\n",
            "Generated text 9: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Tracey with \n",
            "Generated text 10: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione with a s\n",
            "Generated text 11: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione with her\n",
            "Generated text 12: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' she asked with the\n",
            "Generated text 13: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione without \n",
            "Generated text 14: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' she asked with his eyes\n",
            "Generated text 15: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione's s\n",
            "Generated text 16: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Daphne with \n",
            "Generated text 17: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' she asked with his\n",
            "Generated text 18: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' she asked, looking with\n",
            "Generated text 19: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione's f\n",
            "Generated text 20: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' she asked, looking the \n",
            "Generated text 21: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione's c\n",
            "Generated text 22: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' she asked her head\n",
            "Generated text 23: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione, and he \n",
            "Generated text 24: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione, he\n",
            "Generated text 25: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione's face. \n",
            "Generated text 26: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'What happened?' she asked with th\n",
            "Generated text 27: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione wi\n",
            "Generated text 28: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' she asked his eyes\n",
            "Generated text 29: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione with a f\n",
            "Generated text 30: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'What happened?' she asked her hea\n",
            "Generated text 31: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione. 'I\n",
            "Generated text 32: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione of \n",
            "Generated text 33: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' she asked with her\n",
            "Generated text 34: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' she asked with a s\n",
            "Generated text 35: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione and\n",
            "Generated text 36: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Tracey, her \n",
            "Generated text 37: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione's h\n",
            "Generated text 38: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Harry with a\n",
            "Generated text 39: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'What happened?' she asked with hi\n",
            "Generated text 40: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione, h\n",
            "Generated text 41: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'What happened?' she asked his eye\n",
            "Generated text 42: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione to \n",
            "Generated text 43: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'What happened?' asked Hermione, a\n",
            "Generated text 44: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione's a\n",
            "Generated text 45: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione's w\n",
            "Generated text 46: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione started \n",
            "Generated text 47: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' she asked her eyes\n",
            "Generated text 48: Harry looked at his grandfather. 'What happened?' asked Hermione with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione in \n",
            "Generated text 49: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione, and the\n",
            "Generated text 50: Harry looked at his grandfather. 'What happened?' she asked with his grandfather had allowed towards Hermione. 'But you know?' asked Hermione with a c\n"
          ]
        }
      ],
      "source": [
        "eval_gen(display=50, model=m, desired_length=150, starting_string=\"Harry looked at \", k=100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "fuFMb2_pM9ui"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "deep_learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3303dae8d55aa898ef35e11fa38c5e9f0ad39a311a3f4b3a2d2a7e531facda39"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c5116ffec5a423cb1bc620f8c4cf54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d5b4a2e36284638836c8edba5cb3b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e170546441d489a81ba23ab7d296165": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75eeb7679c7d447bbeded9c744ff770e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de0a7ce1638d4518a15758f5f24979e1",
            "placeholder": "​",
            "style": "IPY_MODEL_6c5116ffec5a423cb1bc620f8c4cf54f",
            "value": " 1/1 [00:00&lt;00:00, 57.61it/s]"
          }
        },
        "ce6f1bd69c844223b942467b9700beeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d62e1177f2444f9c9b1c23c04ee50e13",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d5b4a2e36284638836c8edba5cb3b47",
            "value": 1
          }
        },
        "d2e0657ceced4de689a644651f30baf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d62e1177f2444f9c9b1c23c04ee50e13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de0a7ce1638d4518a15758f5f24979e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e65584e961c24c0b9248c1342dd21b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f453c761a8a8474c8d23dc36a99b823e",
              "IPY_MODEL_ce6f1bd69c844223b942467b9700beeb",
              "IPY_MODEL_75eeb7679c7d447bbeded9c744ff770e"
            ],
            "layout": "IPY_MODEL_6e170546441d489a81ba23ab7d296165"
          }
        },
        "ee0528adca244e31827c4b23b310432d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f453c761a8a8474c8d23dc36a99b823e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee0528adca244e31827c4b23b310432d",
            "placeholder": "​",
            "style": "IPY_MODEL_d2e0657ceced4de689a644651f30baf4",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
