{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnKVArh_0qhm"
      },
      "source": [
        "# BYOL\n",
        "\n",
        "In this notebook we are going to implement [BYOL: Bootstrap Your Own Latent](https://arxiv.org/pdf/2006.07733.pdf) and compare the results of a classification task before and after pretraining the model with BYOL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E6nh_5Q2uIp"
      },
      "source": [
        "### Data Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B7vzr4sTnriT"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import Callable, Tuple\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn, Tensor\n",
        "from torchvision import transforms as T\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class RandomApply(nn.Module):\n",
        "    def __init__(self, fn: Callable, p: float):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        if random.random() > self.p:\n",
        "            return x\n",
        "        return self.fn(x)\n",
        "    \n",
        "\n",
        "def default_augmentation(image_size: Tuple[int, int] = (224, 224)) -> nn.Module:\n",
        "\n",
        "    \"\"\"\n",
        "        1. resize images to 'image_size'\n",
        "        2. RandomApply color jitter\n",
        "        3. RandomApply grayscale\n",
        "        4. RandomApply horizon flip\n",
        "        5. RandomApply gaussian blur with kernel_size(3, 3), sigma=(1.5, 1.5)\n",
        "        6. RandomApply ResizedCrop to 'image_size'\n",
        "        7. Normalize\n",
        "        choosing hyperparameters that are not mentioned is up to you\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "        # your code\n",
        "        RandomApply(T.ColorJitter(0.8, 0.8, 0.8, 0.2), p = 0.3),\n",
        "        T.RandomGrayscale(p=0.2),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        RandomApply(T.GaussianBlur((3, 3), (1.0, 2.0)), p = 0.2),\n",
        "        T.RandomResizedCrop((image_size)),\n",
        "        T.Normalize(\n",
        "            mean=torch.tensor([0.485, 0.456, 0.406]),\n",
        "            std=torch.tensor([0.229, 0.224, 0.225]),\n",
        "            )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q3h7292NSYF"
      },
      "source": [
        "# Model\n",
        "We will use ResNet18 as our representation model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YoU-3B4FmtrZ"
      },
      "outputs": [],
      "source": [
        "def get_encoder_model():\n",
        "    resnet = torchvision.models.resnet18()\n",
        "    # remove last fully-connected layer\n",
        "    # your code\n",
        "    modules = list(resnet.children())[:-1]\n",
        "    resnet = torch.nn.Sequential(*modules, nn.Flatten())\n",
        "    return resnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJDTGsElNSYH"
      },
      "source": [
        "### Loss Function\n",
        "We need to use NormalizedMSELoss as our loss function.\n",
        "$$NormalizedMSELoss(v_1, v_2) = \\Vert \\bar{v_1} - \\bar{v_2}\\Vert_2^2 = 2 - 2.\\frac{\\langle v_1, v_2 \\rangle}{\\Vert v_1\\Vert_2 \\Vert v_2\\Vert_2}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E1tNDzfKNSYH"
      },
      "outputs": [],
      "source": [
        "class NormalizedMSELoss(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(NormalizedMSELoss,self).__init__()\n",
        "        \n",
        "    def forward(self, view1: Tensor, view2: Tensor) -> Tensor:\n",
        "        view1 = F.normalize(view1, dim=-1, p=2)\n",
        "        view2 = F.normalize(view2, dim=-1, p=2)\n",
        "        return 2 - 2 * (view1 * view2).sum(dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DXsRWJ4NSYI"
      },
      "source": [
        "### MLP\n",
        "Here you will implement a simple MLP class with one hidden layer with BatchNorm and ReLU activation, and a linear output layer. This class will be used for both the projections and the prediction networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "36_maDbKNSYJ"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim: int, projection_dim: int = 256, hidden_dim: int = 4096) -> None:\n",
        "        super(MLP,self).__init__()\n",
        "\n",
        "        # your code\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, projection_dim),\n",
        "            )\n",
        "    \n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.net(x)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbcQCTwrNSYK"
      },
      "source": [
        "### Encoder + Projector Network\n",
        "This is the network structure that is shared between online and target networks. It consists of our encoder model, followed by a projection MLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bpdfns-QNSYK"
      },
      "outputs": [],
      "source": [
        "class EncoderProjecter(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder: nn.Module,\n",
        "                 hidden_dim: int = 4096,\n",
        "                 projection_out_dim: int = 256\n",
        "                 ) -> None:\n",
        "        super(EncoderProjecter, self).__init__()\n",
        "\n",
        "        # your code\n",
        "        self.encoder = encoder\n",
        "        self.projector = MLP(512) \n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        # your code\n",
        "        return self.projector(self.encoder(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opmwr3GxNSYL"
      },
      "source": [
        "## BYOL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PoQc83g2NSYL"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "class BYOL(nn.Module):\n",
        "    def __init__(self,\n",
        "                 model: nn.Module,\n",
        "                 hidden_dim: int = 4096,\n",
        "                 projection_out_dim: int = 256,\n",
        "                 target_decay: float = 0.99         \n",
        "                ) -> None:\n",
        "        super(BYOL, self).__init__()\n",
        "        \n",
        "        # your code\n",
        "\n",
        "        self.augment = default_augmentation((96,96))\n",
        "        self.beta = target_decay\n",
        "\n",
        "        self.online_network = EncoderProjecter(model, projection_out_dim, hidden_dim)  # encoder + projector\n",
        "        self.online_predictor = MLP(projection_out_dim)\n",
        "\n",
        "        self.target_network = copy.deepcopy(self.online_network)  # init with copy of parameters of online network\n",
        "        # set target_network's weights to be untrainable\n",
        "        for param in self.target_network.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.target_network.eval()\n",
        "                \n",
        "        self.loss_function = NormalizedMSELoss()\n",
        "        \n",
        "        \n",
        "    @torch.no_grad()    \n",
        "    def soft_update_target_network(self) -> None:\n",
        "        # your code\n",
        "        for online_params, target_params in zip(self.online_network.parameters(), self.target_network.parameters()) :\n",
        "            target_params.data = self.beta * target_params + (1 - self.beta) * online_params\n",
        "\n",
        "            \n",
        "\n",
        "    def forward(self, view) -> Tuple[Tensor]:\n",
        "        # return online projection and target projection of view\n",
        "        # your code\n",
        "        online_projection = self.online_network(view)\n",
        "        target_projection = self.target_network(view)\n",
        "\n",
        "        return online_projection, target_projection\n",
        "    \n",
        "    \n",
        "    def loss(self, view1, view2):\n",
        "        # compute loss once for (online_prediction1, target_projection2) and once for (online_prediction2, target_projection1). \n",
        "        # then return the mean.\n",
        "        # your code\n",
        "        online_projection1, target_projection1 = self.forward(view1)\n",
        "        online_projection2, target_projection2 = self.forward(view2)\n",
        "        online_prediction1 = self.online_predictor(online_projection1)\n",
        "        online_prediction2 = self.online_predictor(online_projection2)\n",
        "        loss = self.loss_function(online_prediction1, target_projection2) + self.loss_function(online_prediction2, target_projection1)\n",
        "        return torch.mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQzcP89G4L2u"
      },
      "source": [
        "# STL10 Datasets\n",
        "\n",
        "We need 3 separate datasets from STL10 for this experiment:\n",
        "1. `\"train\"` -- Contains only labeled training images. Used for supervised training.\n",
        "2. `\"train+unlabeled\"` -- Contains training images, plus a large number of unlabelled images.  Used for self-supervised learning with BYOL.\n",
        "3. `\"test\"` -- Labeled test images.  We use it both as a validation set, and for computing the final model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1lTVx52t9Kjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb966a3-a16e-4cc6-95f0-dc1df965ef74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2640397119/2640397119 [04:46<00:00, 9207428.30it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/stl10_binary.tar.gz to data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import STL10\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "\n",
        "TRAIN_DATASET = STL10(root=\"data\", split=\"train\", download=True, transform=ToTensor())\n",
        "TRAIN_UNLABELED_DATASET = STL10(root=\"data\", split=\"train+unlabeled\", download=True, transform=ToTensor())\n",
        "TEST_DATASET = STL10(root=\"data\", split=\"test\", download=True, transform=ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDqYVB35NSYM"
      },
      "source": [
        "Create dataloaders:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ElqEu1wwNSYM"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "TRAIN_dataloader = DataLoader(dataset=TRAIN_DATASET, batch_size=256, shuffle=True)\n",
        "TRAIN_UNLABELED_dataloader = DataLoader(dataset=TRAIN_UNLABELED_DATASET, batch_size=256, shuffle=True)\n",
        "TEST_dataloader = DataLoader(dataset=TEST_DATASET, batch_size=256, shuffle=True)\n",
        "classes = TRAIN_DATASET.classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdlrDnwR45bm"
      },
      "source": [
        "# Supervised Training without BYOL\n",
        "\n",
        "First create a classifier model by simply adding a linear layer on top of the encoder model. Then train the model using the labeled training set. Performance should be pretty good already. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "H2LG2XhZv-X0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "C2aXJ1auwbzN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ir4p5LhLNSYN"
      },
      "outputs": [],
      "source": [
        "encoder = get_encoder_model()\n",
        "classifier = nn.Sequential(encoder, nn.Linear(512, len(classes))).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FR5ruXB2NSYO"
      },
      "outputs": [],
      "source": [
        "n_epochs = 40\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "sup_optimizer = optim.SGD(classifier.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "def sup_train_model(model, train_dataloader, n_epochs, optimizer, criterion, device):\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        ####### Training Phase ########\n",
        "        model.train()\n",
        "        with tqdm(train_dataloader, unit=\"batch\") as batches:\n",
        "            running_loss = 0\n",
        "            epoch_loss = 0\n",
        "            for data, target in batches:\n",
        "                batches.set_description(f\"Epoch {epoch + 1}\")\n",
        "\n",
        "                # move to GPU\n",
        "                data = data.to(device)\n",
        "                target = target.to(device)\n",
        "\n",
        "            \n",
        "                # train \n",
        "                out = model(data)\n",
        "                train_loss = criterion(out, target)\n",
        "\n",
        "                # Backward and optimize\n",
        "                optimizer.zero_grad()\n",
        "                train_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                batches.set_postfix(train_loss = train_loss.item())\n",
        "\n",
        "                running_loss += train_loss.item() * data.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(TRAIN_DATASET)   \n",
        "        print(f\"loss for epoch {epoch+1} = {epoch_loss}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "V3wcpkGtpVSl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sup_model = sup_train_model(classifier, TRAIN_dataloader, n_epochs, sup_optimizer, criterion, device)"
      ],
      "metadata": {
        "id": "TxBFi3AlpZNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f500d67e-8f20-4218-86eb-0456aa3badb4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 20/20 [00:13<00:00,  1.49batch/s, train_loss=2.27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 1 = 2.319526119995117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 20/20 [00:05<00:00,  3.45batch/s, train_loss=2.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 2 = 2.16297726020813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 20/20 [00:05<00:00,  3.71batch/s, train_loss=2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 3 = 2.0153730031967165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 20/20 [00:05<00:00,  3.45batch/s, train_loss=1.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 4 = 1.8734141416549683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 20/20 [00:05<00:00,  3.71batch/s, train_loss=1.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 5 = 1.7611118068695069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 20/20 [00:05<00:00,  3.59batch/s, train_loss=1.67]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 6 = 1.6807172481536865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 20/20 [00:05<00:00,  3.61batch/s, train_loss=1.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 7 = 1.6113888906478882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 20/20 [00:05<00:00,  3.74batch/s, train_loss=1.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 8 = 1.5571433547973632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 20/20 [00:05<00:00,  3.46batch/s, train_loss=1.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 9 = 1.5004141241073607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 20/20 [00:05<00:00,  3.68batch/s, train_loss=1.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 10 = 1.4515578979492187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 20/20 [00:05<00:00,  3.48batch/s, train_loss=1.46]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 11 = 1.4098481840133668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 20/20 [00:05<00:00,  3.74batch/s, train_loss=1.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 12 = 1.3623339349746704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 20/20 [00:05<00:00,  3.47batch/s, train_loss=1.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 13 = 1.3284835964202881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 20/20 [00:05<00:00,  3.70batch/s, train_loss=1.22]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 14 = 1.2843469665527343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 20/20 [00:05<00:00,  3.44batch/s, train_loss=1.27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 15 = 1.2360808605194091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 20/20 [00:05<00:00,  3.68batch/s, train_loss=1.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 16 = 1.187850731086731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 20/20 [00:05<00:00,  3.53batch/s, train_loss=1.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 17 = 1.144682172012329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 20/20 [00:05<00:00,  3.53batch/s, train_loss=1.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 18 = 1.104270755004883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 20/20 [00:05<00:00,  3.63batch/s, train_loss=1.04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 19 = 1.0647072813034058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 20/20 [00:05<00:00,  3.38batch/s, train_loss=0.957]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 20 = 1.0100868553161622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 20/20 [00:05<00:00,  3.62batch/s, train_loss=1.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 21 = 0.9616181591033935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 20/20 [00:05<00:00,  3.40batch/s, train_loss=0.826]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 22 = 0.9083940101623535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 20/20 [00:05<00:00,  3.70batch/s, train_loss=0.832]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 23 = 0.8554403490066528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 20/20 [00:05<00:00,  3.42batch/s, train_loss=0.785]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 24 = 0.8065814290046692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 20/20 [00:05<00:00,  3.69batch/s, train_loss=0.766]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 25 = 0.7693659346580506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 20/20 [00:05<00:00,  3.42batch/s, train_loss=0.708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 26 = 0.7037437643051148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 20/20 [00:05<00:00,  3.64batch/s, train_loss=0.659]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 27 = 0.6492395677566528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 20/20 [00:05<00:00,  3.49batch/s, train_loss=0.588]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 28 = 0.5940336296081543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 20/20 [00:05<00:00,  3.58batch/s, train_loss=0.578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 29 = 0.542984739112854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 20/20 [00:05<00:00,  3.61batch/s, train_loss=0.556]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 30 = 0.492848752784729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31: 100%|██████████| 20/20 [00:05<00:00,  3.41batch/s, train_loss=0.481]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 31 = 0.447937020778656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32: 100%|██████████| 20/20 [00:05<00:00,  3.50batch/s, train_loss=0.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 32 = 0.3914671799659729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33: 100%|██████████| 20/20 [00:06<00:00,  3.32batch/s, train_loss=0.347]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 33 = 0.3432642992496491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34: 100%|██████████| 20/20 [00:05<00:00,  3.34batch/s, train_loss=0.31]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 34 = 0.3021245875835419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35: 100%|██████████| 20/20 [00:06<00:00,  3.32batch/s, train_loss=0.27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 35 = 0.26231801719665526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36: 100%|██████████| 20/20 [00:05<00:00,  3.59batch/s, train_loss=0.246]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 36 = 0.23142368609905242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37: 100%|██████████| 20/20 [00:06<00:00,  3.27batch/s, train_loss=0.214]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 37 = 0.20061892545223237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38: 100%|██████████| 20/20 [00:05<00:00,  3.54batch/s, train_loss=0.189]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 38 = 0.17092267065048217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39: 100%|██████████| 20/20 [00:06<00:00,  3.31batch/s, train_loss=0.189]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 39 = 0.15120679137706758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40: 100%|██████████| 20/20 [00:05<00:00,  3.59batch/s, train_loss=0.118]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 40 = 0.1275482924938202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_acc(y_pred, y_test):\n",
        "    _, y_pred_tags = torch.max(y_pred, dim = 1)    \n",
        "    correct_pred = (y_pred_tags == y_test).float()\n",
        "    acc = correct_pred.sum() / len(correct_pred)\n",
        "    acc = torch.round(acc * 100)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "k8KMwPKSpIxo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = 0\n",
        "for x,y in TEST_dataloader:\n",
        "    sup_model.eval()\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    accuracy += multi_acc(sup_model(x), y) / len(TEST_dataloader)\n",
        "print(f\"accuracy without BYOL = {accuracy}\")"
      ],
      "metadata": {
        "id": "uuV0eDdONG4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cbb3097-85eb-4d0c-ff52-bb6643a8abf8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy without BYOL = 48.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBTyX-f45Sgj"
      },
      "source": [
        "### Self-Supervised Training with BYOL\n",
        "\n",
        "Now perform the self-supervised training. This is the most computationally intensive part of the script."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 20\n",
        "byol = BYOL(get_encoder_model())\n",
        "ssl_optimizer = torch.optim.Adam(byol.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "9xck_aIg9rel"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MwaI8Sc6NSYO"
      },
      "outputs": [],
      "source": [
        "def SSL_train_model(model, train_unlabeled_dataloader, n_epochs, optimizer, criterion, device):\n",
        "    model.to(device)\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        ####### Training Phase ########\n",
        "        model.train()\n",
        "        with tqdm(train_unlabeled_dataloader, unit=\"batch\") as batches:\n",
        "            running_loss = 0\n",
        "            for data in batches:\n",
        "                batches.set_description(f\"Epoch {epoch + 1}\")\n",
        "\n",
        "                # move to GPU\n",
        "                data = data[0].to(device)\n",
        "\n",
        " \n",
        "                with torch.no_grad():\n",
        "                    data1, data2 = model.augment(data), model.augment(data)\n",
        "\n",
        "                train_loss = model.loss(data1, data2)\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                train_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                model.soft_update_target_network()\n",
        "\n",
        "\n",
        "                batches.set_postfix(train_loss = train_loss.item())\n",
        "\n",
        "                running_loss += train_loss.item() * data.size(0)\n",
        "      \n",
        "\n",
        "        epoch_loss = running_loss / len(TRAIN_DATASET)   \n",
        "        print(f\"loss for epoch {epoch+1} = {epoch_loss}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SSL_model = SSL_train_model(byol, TRAIN_UNLABELED_dataloader, n_epochs, ssl_optimizer, criterion, device)"
      ],
      "metadata": {
        "id": "8iPMg_3eGZ0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "118a7038-978c-4c1b-bb80-715d4e4660c8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   0%|          | 0/411 [00:00<?, ?batch/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Epoch 1: 100%|██████████| 411/411 [04:09<00:00,  1.65batch/s, train_loss=0.646]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 1 = 21.386822641944885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 411/411 [04:08<00:00,  1.66batch/s, train_loss=0.223]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 2 = 12.804969591498375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 411/411 [04:09<00:00,  1.65batch/s, train_loss=0.495]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 3 = 11.014533401966094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 411/411 [04:08<00:00,  1.66batch/s, train_loss=0.515]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 4 = 9.469083618927002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 411/411 [04:08<00:00,  1.66batch/s, train_loss=0.774]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 5 = 8.640660267353057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 411/411 [04:06<00:00,  1.67batch/s, train_loss=0.183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 6 = 7.605020485448837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 411/411 [04:07<00:00,  1.66batch/s, train_loss=0.211]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 7 = 7.453278600096702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 411/411 [04:07<00:00,  1.66batch/s, train_loss=0.334]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 8 = 7.097322121667862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 411/411 [04:08<00:00,  1.65batch/s, train_loss=0.396]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 9 = 6.69550075135231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 411/411 [04:08<00:00,  1.65batch/s, train_loss=0.402]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 10 = 6.54262501039505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 411/411 [04:08<00:00,  1.65batch/s, train_loss=0.304]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 11 = 6.101790420007705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 411/411 [04:08<00:00,  1.66batch/s, train_loss=0.298]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 12 = 6.305572372961044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 411/411 [04:09<00:00,  1.65batch/s, train_loss=0.172]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 13 = 5.387404637765885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 411/411 [04:09<00:00,  1.65batch/s, train_loss=0.234]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 14 = 5.887911245965958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 411/411 [04:08<00:00,  1.65batch/s, train_loss=0.563]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 15 = 5.93919371061325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 411/411 [04:09<00:00,  1.65batch/s, train_loss=0.985]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 16 = 6.002861955356598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 411/411 [04:07<00:00,  1.66batch/s, train_loss=0.333]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 17 = 6.156608871936798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 411/411 [04:11<00:00,  1.63batch/s, train_loss=0.837]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 18 = 5.653103424930572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 411/411 [04:08<00:00,  1.65batch/s, train_loss=0.28]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 19 = 5.777278143787384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 411/411 [04:08<00:00,  1.65batch/s, train_loss=0.539]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 20 = 5.904601030540467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjMmW9Tj5k-j"
      },
      "source": [
        "### Supervised Training Again\n",
        "\n",
        "Extract the encoder network's state dictionary from BYOL, and load it into our ResNet18 model before starting training.  Then run supervised training, and watch the accuracy improve from last time!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modules = list(SSL_model.online_network.children())[:-1]"
      ],
      "metadata": {
        "id": "CD664w3SKiqh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_encoder = torch.nn.Sequential(*modules)\n",
        "b_classifier = nn.Sequential(b_encoder, nn.Linear(512, len(classes))).to(device)"
      ],
      "metadata": {
        "id": "l6m_SPJnJjmW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 40\n",
        "b_criterion = nn.CrossEntropyLoss()\n",
        "b_sup_optimizer = optim.SGD(b_classifier.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "3AbC3n-dJvT3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "def b_sup_train_model(model, train_dataloader, n_epochs, optimizer, criterion, device):\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        ####### Training Phase ########\n",
        "        model.train()\n",
        "        with tqdm(train_dataloader, unit=\"batch\") as batches:\n",
        "            running_loss = 0\n",
        "            epoch_loss = 0\n",
        "            for data, target in batches:\n",
        "                batches.set_description(f\"Epoch {epoch + 1}\")\n",
        "\n",
        "                # move to GPU\n",
        "                data = data.to(device)\n",
        "                target = target.to(device)\n",
        "\n",
        "            \n",
        "                # train \n",
        "                out = model(data)\n",
        "                train_loss = criterion(out, target)\n",
        "\n",
        "                # Backward and optimize\n",
        "                optimizer.zero_grad()\n",
        "                train_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                batches.set_postfix(train_loss = train_loss.item())\n",
        "\n",
        "                running_loss += train_loss.item() * data.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(TRAIN_DATASET)   \n",
        "        print(f\"loss for epoch {epoch+1} = {epoch_loss}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "PUOLTsBQJ01Q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_sup_model = b_sup_train_model(b_classifier, TRAIN_dataloader, n_epochs, b_sup_optimizer, b_criterion, device)"
      ],
      "metadata": {
        "id": "DATt5ZaqJ3Do",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef00ba30-c0d5-4df2-b61f-be30ff2b37cb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 20/20 [00:05<00:00,  3.47batch/s, train_loss=2.02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 1 = 2.248141623687744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 20/20 [00:06<00:00,  3.26batch/s, train_loss=1.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 2 = 1.8876248138427734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 20/20 [00:05<00:00,  3.52batch/s, train_loss=1.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 3 = 1.6879217853546142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 20/20 [00:06<00:00,  3.30batch/s, train_loss=1.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 4 = 1.5709947483062745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 20/20 [00:05<00:00,  3.49batch/s, train_loss=1.46]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 5 = 1.488596364402771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 20/20 [00:05<00:00,  3.36batch/s, train_loss=1.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 6 = 1.4263654218673707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 20/20 [00:05<00:00,  3.43batch/s, train_loss=1.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 7 = 1.3773021192550658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 20/20 [00:05<00:00,  3.42batch/s, train_loss=1.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 8 = 1.3371961051940917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 20/20 [00:05<00:00,  3.39batch/s, train_loss=1.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 9 = 1.3049393882751466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 20/20 [00:05<00:00,  3.50batch/s, train_loss=1.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 10 = 1.2724446174621582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 20/20 [00:06<00:00,  3.33batch/s, train_loss=1.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 11 = 1.2503278528213502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 20/20 [00:05<00:00,  3.50batch/s, train_loss=1.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 12 = 1.2298801166534423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 20/20 [00:06<00:00,  3.25batch/s, train_loss=1.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 13 = 1.2089129018783569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 20/20 [00:05<00:00,  3.50batch/s, train_loss=1.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 14 = 1.1911247747421265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 20/20 [00:06<00:00,  3.30batch/s, train_loss=1.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 15 = 1.176486005783081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 20/20 [00:05<00:00,  3.50batch/s, train_loss=1.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 16 = 1.1640207962036133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 20/20 [00:06<00:00,  3.28batch/s, train_loss=1.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 17 = 1.1478514373779296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 20/20 [00:05<00:00,  3.49batch/s, train_loss=1.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 18 = 1.134900359916687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 20/20 [00:06<00:00,  3.27batch/s, train_loss=1.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 19 = 1.1247735124588012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 20/20 [00:05<00:00,  3.54batch/s, train_loss=1.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 20 = 1.1137183206558228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 20/20 [00:06<00:00,  3.28batch/s, train_loss=1.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 21 = 1.105375039291382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 20/20 [00:05<00:00,  3.50batch/s, train_loss=1.09]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 22 = 1.0904491165161132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 20/20 [00:06<00:00,  3.22batch/s, train_loss=1.06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 23 = 1.0832419496536254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 20/20 [00:05<00:00,  3.47batch/s, train_loss=1.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 24 = 1.0708614572525024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 20/20 [00:06<00:00,  3.01batch/s, train_loss=0.999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 25 = 1.0614239099502563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 20/20 [00:05<00:00,  3.52batch/s, train_loss=1.09]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 26 = 1.0562662368774414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 20/20 [00:06<00:00,  3.27batch/s, train_loss=1.04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 27 = 1.0478030960083007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 20/20 [00:05<00:00,  3.50batch/s, train_loss=1.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 28 = 1.040783090019226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 20/20 [00:06<00:00,  3.25batch/s, train_loss=1.06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 29 = 1.034704252243042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 20/20 [00:05<00:00,  3.43batch/s, train_loss=1.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 30 = 1.0224911287307739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31: 100%|██████████| 20/20 [00:06<00:00,  3.32batch/s, train_loss=1.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 31 = 1.0174109817504884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32: 100%|██████████| 20/20 [00:05<00:00,  3.45batch/s, train_loss=1.06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 32 = 1.0140555765151977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33: 100%|██████████| 20/20 [00:05<00:00,  3.38batch/s, train_loss=1.09]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 33 = 1.0065037279129028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34: 100%|██████████| 20/20 [00:05<00:00,  3.38batch/s, train_loss=0.851]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 34 = 1.0000760180473327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35: 100%|██████████| 20/20 [00:05<00:00,  3.47batch/s, train_loss=1.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 35 = 0.9942375047683716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36: 100%|██████████| 20/20 [00:06<00:00,  3.32batch/s, train_loss=1.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 36 = 0.9857145727157592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37: 100%|██████████| 20/20 [00:05<00:00,  3.49batch/s, train_loss=0.849]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 37 = 0.9792817165374755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38: 100%|██████████| 20/20 [00:06<00:00,  3.25batch/s, train_loss=1.09]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 38 = 0.9776198558807373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39: 100%|██████████| 20/20 [00:05<00:00,  3.51batch/s, train_loss=0.856]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 39 = 0.9675305804252624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40: 100%|██████████| 20/20 [00:06<00:00,  3.29batch/s, train_loss=0.842]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 40 = 0.9592639419555664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = 0\n",
        "for x,y in TEST_dataloader:\n",
        "    b_sup_model.eval()\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    accuracy += multi_acc(b_sup_model(x), y) / len(TEST_dataloader)\n",
        "print(f\"accuracy with BYOL = {accuracy}\")"
      ],
      "metadata": {
        "id": "PRLv6Ai0KX2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a657d5-f2ce-42f1-ce50-264ae779ad60"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy with BYOL = 60.71875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion:\n",
        "## The accuracy increased by 13 percent."
      ],
      "metadata": {
        "id": "LqTdfzdmqZiX"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}